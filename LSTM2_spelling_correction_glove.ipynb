{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T14:45:09.447952Z",
     "start_time": "2020-03-14T14:45:09.441971Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "gM5cAAOti60h"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.sparse import hstack\n",
    "import torch\n",
    "from sklearn import *\n",
    "import sklearn\n",
    "import re\n",
    "from torchtext import data\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 923,
     "status": "ok",
     "timestamp": 1584987910450,
     "user": {
      "displayName": "Carla Sendra Balcells",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhPZYP2cmKWdA5LesxTBVQPj-8LhB0pIXIfE_Efzw=s64",
      "userId": "01855518481907913222"
     },
     "user_tz": -60
    },
    "id": "yqC_yXBs4iZx",
    "outputId": "85e56f7e-53a4-4802-da76-371b39dac0b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(291088, 291088, 32344, 32344, 291088, 32344)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('q1_train_cleaned.txt') as f:\n",
    "    content = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "q1_train = [x.strip() for x in content] \n",
    "\n",
    "with open('q2_train_cleaned.txt') as f:\n",
    "    content = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "q2_train = [x.strip() for x in content] \n",
    "\n",
    "with open('q1_test_cleaned.txt') as f:\n",
    "    content = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "q1_test = [x.strip() for x in content] \n",
    "\n",
    "with open('q2_test_cleaned.txt') as f:\n",
    "    content = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "q2_test = [x.strip() for x in content] \n",
    "\n",
    "with open('test_labels.txt') as f:\n",
    "    content = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "labels_test = [x.strip() for x in content] \n",
    "\n",
    "with open('train_labels.txt') as f:\n",
    "    content = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "labels_train = [x.strip() for x in content] \n",
    "\n",
    "len(q1_train), len(q2_train), len(q1_test), len(q2_test), len(labels_train), len(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5619,
     "status": "ok",
     "timestamp": 1584987915632,
     "user": {
      "displayName": "Carla Sendra Balcells",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhPZYP2cmKWdA5LesxTBVQPj-8LhB0pIXIfE_Efzw=s64",
      "userId": "01855518481907913222"
     },
     "user_tz": -60
    },
    "id": "bG-1iTq15WTJ",
    "outputId": "7be0b298-0c7c-46d6-bee1-091afe9bf9a4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how do i get home tutor</td>\n",
       "      <td>how can i trust a home tutor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what be the difference between have be have be...</td>\n",
       "      <td>when should i use have be have be and have be</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>if my atm card be block for online transaction...</td>\n",
       "      <td>my credit card be use for fraud transaction i ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how do i add usb 3.0 port in a laptop without ...</td>\n",
       "      <td>can i use a usb 3.0 device in a usb 2.0 port</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what be the best advantage of use Quora</td>\n",
       "      <td>what be the benefit to Quora</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>where can i download the economist pdf</td>\n",
       "      <td>where can i download pdf of Gillian Glynn go girl</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>why do some people get everything</td>\n",
       "      <td>why be that some people get what they want ver...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>be an all out nuclear war survivable</td>\n",
       "      <td>would all out nuclear war destroy all life on ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>what be the advantage of ashless transaction</td>\n",
       "      <td>what could happen to ashless transaction after...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>what be the main problem of India</td>\n",
       "      <td>what be the main problem face by India</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  ... is_duplicate\n",
       "0                            how do i get home tutor  ...            0\n",
       "1  what be the difference between have be have be...  ...            0\n",
       "2  if my atm card be block for online transaction...  ...            0\n",
       "3  how do i add usb 3.0 port in a laptop without ...  ...            0\n",
       "4            what be the best advantage of use Quora  ...            1\n",
       "5             where can i download the economist pdf  ...            0\n",
       "6                  why do some people get everything  ...            1\n",
       "7               be an all out nuclear war survivable  ...            1\n",
       "8       what be the advantage of ashless transaction  ...            0\n",
       "9                  what be the main problem of India  ...            1\n",
       "\n",
       "[10 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(np.stack((q1_train, q2_train, labels_train), axis=-1), columns =['question1', 'question2', 'is_duplicate'])\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4979,
     "status": "ok",
     "timestamp": 1584987915633,
     "user": {
      "displayName": "Carla Sendra Balcells",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhPZYP2cmKWdA5LesxTBVQPj-8LhB0pIXIfE_Efzw=s64",
      "userId": "01855518481907913222"
     },
     "user_tz": -60
    },
    "id": "cxqj-MNN5mJp",
    "outputId": "a6fa6f24-a434-4fc9-9bee-42f9bda01497"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what be it like to travel in afghanistan</td>\n",
       "      <td>what be it like for a foreigner to travel in a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>do rapper really make a much money a they clai...</td>\n",
       "      <td>can i make money from lyric video on youtube</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>do mary give a natural vaginal birth to Jesus ...</td>\n",
       "      <td>how be the labour of mary and her birth give t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how can you determine the lewis structure for o2</td>\n",
       "      <td>how be the lewis structure for propane determine</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>where do plex get poster art thumbnail for tv ...</td>\n",
       "      <td>who design the ux and ui of plex medium center</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>be it possible to know if somebody else tumble...</td>\n",
       "      <td>can anyone see a list of my secondary blo i wr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>if you could have only money fame or love in y...</td>\n",
       "      <td>how do one define success be it the way one Ci...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>how do you say also in Japanese be there more ...</td>\n",
       "      <td>how do you say ocean in Japanese be there more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>how good bad will it be for India if trump win...</td>\n",
       "      <td>if Donald trump win the presidential election ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>why can not i see view on my instagram video</td>\n",
       "      <td>how can i see who view my instagram</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  ... is_duplicate\n",
       "0           what be it like to travel in afghanistan  ...            0\n",
       "1  do rapper really make a much money a they clai...  ...            0\n",
       "2  do mary give a natural vaginal birth to Jesus ...  ...            0\n",
       "3   how can you determine the lewis structure for o2  ...            0\n",
       "4  where do plex get poster art thumbnail for tv ...  ...            0\n",
       "5  be it possible to know if somebody else tumble...  ...            0\n",
       "6  if you could have only money fame or love in y...  ...            0\n",
       "7  how do you say also in Japanese be there more ...  ...            0\n",
       "8  how good bad will it be for India if trump win...  ...            1\n",
       "9       why can not i see view on my instagram video  ...            1\n",
       "\n",
       "[10 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.DataFrame(np.stack((q1_test, q2_test, labels_test), axis=-1), columns =['question1', 'question2', 'is_duplicate'])\n",
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Sdusl9D5sHu"
   },
   "outputs": [],
   "source": [
    "train_df.to_csv('train_df.csv', index=False)\n",
    "test_df.to_csv('test_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ppg1FIj69gjS"
   },
   "outputs": [],
   "source": [
    "#define fields\n",
    "question1 = data.Field(tokenize='spacy')\n",
    "question2 = data.Field(tokenize='spacy')\n",
    "label = data.LabelField(dtype=torch.float)\n",
    "\n",
    "fields = [('question1', question1), ('question2', question2), ('is_duplicate', label)]\n",
    "\n",
    "train_data, test_data = data.TabularDataset.splits(path ='.', train= 'train_df.csv', test= 'test_df.csv', format = 'csv', fields = fields, skip_header = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 438029,
     "status": "ok",
     "timestamp": 1584988781938,
     "user": {
      "displayName": "Carla Sendra Balcells",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhPZYP2cmKWdA5LesxTBVQPj-8LhB0pIXIfE_Efzw=s64",
      "userId": "01855518481907913222"
     },
     "user_tz": -60
    },
    "id": "eKLHWIxzA8F3",
    "outputId": "b6430223-e6bf-4a45-abaf-e90a49a38eed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [06:26, 2.23MB/s]                           \n",
      " 99%|█████████▉| 397926/400000 [00:14<00:00, 27843.88it/s]"
     ]
    }
   ],
   "source": [
    "#build vocabulary for training dataset using dictionary from torch text \n",
    "MAX_VOCAB_SIZE = 60000\n",
    "question1.build_vocab(train_data.question1, train_data.question2, max_size = MAX_VOCAB_SIZE, vectors = \"glove.6B.100d\", unk_init = torch.Tensor.normal_)\n",
    "question2.build_vocab(train_data.question1, train_data.question2, max_size = MAX_VOCAB_SIZE, vectors = \"glove.6B.100d\", unk_init = torch.Tensor.normal_)\n",
    "label.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 761,
     "status": "ok",
     "timestamp": 1584988782719,
     "user": {
      "displayName": "Carla Sendra Balcells",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhPZYP2cmKWdA5LesxTBVQPj-8LhB0pIXIfE_Efzw=s64",
      "userId": "01855518481907913222"
     },
     "user_tz": -60
    },
    "id": "mNui2_xcA0rv",
    "outputId": "9b845e93-facc-4cb1-f03a-699b3da09367"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58560, 58560)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#length of vocabulary for training dataset (words + 1(unk) + 1(pad))\n",
    "len(question1.vocab), len(question2.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 746,
     "status": "ok",
     "timestamp": 1584988782721,
     "user": {
      "displayName": "Carla Sendra Balcells",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhPZYP2cmKWdA5LesxTBVQPj-8LhB0pIXIfE_Efzw=s64",
      "userId": "01855518481907913222"
     },
     "user_tz": -60
    },
    "id": "FRzm0QQkBSEh",
    "outputId": "f39f948a-8483-455e-de2c-4e3c791e6470"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['<unk>', '<pad>', 'be', 'the', 'what', 'do', 'a', 'how', 'i', 'to'],\n",
       " ['<unk>', '<pad>', 'be', 'the', 'what', 'do', 'a', 'how', 'i', 'to'])"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10 first words of the vocabuary for training dataset\n",
    "question1.vocab.itos[:10], question2.vocab.itos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 736,
     "status": "ok",
     "timestamp": 1584988782723,
     "user": {
      "displayName": "Carla Sendra Balcells",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhPZYP2cmKWdA5LesxTBVQPj-8LhB0pIXIfE_Efzw=s64",
      "userId": "01855518481907913222"
     },
     "user_tz": -60
    },
    "id": "1IyvWOI9Be9d",
    "outputId": "9a8045cd-208f-4991-c88c-6fe3f7f6f54e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('be', 367533),\n",
       "  ('the', 271817),\n",
       "  ('what', 234474),\n",
       "  ('do', 174303),\n",
       "  ('a', 168740),\n",
       "  ('how', 158566),\n",
       "  ('i', 156106),\n",
       "  ('to', 148296),\n",
       "  ('in', 141992),\n",
       "  ('of', 115433)],\n",
       " [('be', 367533),\n",
       "  ('the', 271817),\n",
       "  ('what', 234474),\n",
       "  ('do', 174303),\n",
       "  ('a', 168740),\n",
       "  ('how', 158566),\n",
       "  ('i', 156106),\n",
       "  ('to', 148296),\n",
       "  ('in', 141992),\n",
       "  ('of', 115433)])"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the most common words of the vocabulary for training dataset \n",
    "question1.vocab.freqs.most_common(10), question2.vocab.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yGRMfXxP6Dep"
   },
   "outputs": [],
   "source": [
    "#build vocabulary for test dataset using dictionary from torch text \n",
    "MAX_VOCAB_SIZE = 60000\n",
    "question1.build_vocab(test_data.question1, test_data.question2, max_size = MAX_VOCAB_SIZE, vectors = \"glove.6B.100d\", unk_init = torch.Tensor.normal_)\n",
    "question2.build_vocab(test_data.question1, test_data.question2, max_size = MAX_VOCAB_SIZE, vectors = \"glove.6B.100d\", unk_init = torch.Tensor.normal_)\n",
    "label.build_vocab(test_data, max_size = MAX_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2313,
     "status": "ok",
     "timestamp": 1584988784314,
     "user": {
      "displayName": "Carla Sendra Balcells",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhPZYP2cmKWdA5LesxTBVQPj-8LhB0pIXIfE_Efzw=s64",
      "userId": "01855518481907913222"
     },
     "user_tz": -60
    },
    "id": "tk9yyrJq7bcQ",
    "outputId": "1d676e1b-5821-4386-f05f-038237f6bf59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21130, 21130)"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#length of vocabulary for test dataset (words + 1(unk) + 1(pad))\n",
    "len(question2.vocab), len(question1.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2304,
     "status": "ok",
     "timestamp": 1584988784315,
     "user": {
      "displayName": "Carla Sendra Balcells",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhPZYP2cmKWdA5LesxTBVQPj-8LhB0pIXIfE_Efzw=s64",
      "userId": "01855518481907913222"
     },
     "user_tz": -60
    },
    "id": "nvu6W6j177i5",
    "outputId": "8094a244-98a1-473b-ad90-6ca649cd927a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['<unk>', '<pad>', 'be', 'the', 'what', 'do', 'a', 'how', 'i', 'to'],\n",
       " ['<unk>', '<pad>', 'be', 'the', 'what', 'do', 'a', 'how', 'i', 'to'])"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10 first words of the vocabuary for test dataset\n",
    "question2.vocab.itos[:10], question1.vocab.itos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2283,
     "status": "ok",
     "timestamp": 1584988784315,
     "user": {
      "displayName": "Carla Sendra Balcells",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhPZYP2cmKWdA5LesxTBVQPj-8LhB0pIXIfE_Efzw=s64",
      "userId": "01855518481907913222"
     },
     "user_tz": -60
    },
    "id": "U3AX6kBq8AHh",
    "outputId": "82a89e6c-84f4-4f20-b002-451c7034d8f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('be', 40506),\n",
       "  ('the', 29996),\n",
       "  ('what', 25585),\n",
       "  ('do', 19402),\n",
       "  ('a', 18949),\n",
       "  ('how', 17900),\n",
       "  ('i', 17331),\n",
       "  ('to', 16598),\n",
       "  ('in', 15700),\n",
       "  ('of', 12726)],\n",
       " [('be', 40506),\n",
       "  ('the', 29996),\n",
       "  ('what', 25585),\n",
       "  ('do', 19402),\n",
       "  ('a', 18949),\n",
       "  ('how', 17900),\n",
       "  ('i', 17331),\n",
       "  ('to', 16598),\n",
       "  ('in', 15700),\n",
       "  ('of', 12726)])"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the most common words of the vocabulary for test dataset \n",
    "question2.vocab.freqs.most_common(10), question1.vocab.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L-SJLiI69i2n"
   },
   "outputs": [],
   "source": [
    "#create batches from train and test data\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, test_data),\n",
    "    sort = False, #don't sort test/validation data\n",
    "    batch_size = BATCH_SIZE,\n",
    "    device=device,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11686,
     "status": "ok",
     "timestamp": 1584988793733,
     "user": {
      "displayName": "Carla Sendra Balcells",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhPZYP2cmKWdA5LesxTBVQPj-8LhB0pIXIfE_Efzw=s64",
      "userId": "01855518481907913222"
     },
     "user_tz": -60
    },
    "id": "z1LaODXSClVA",
    "outputId": "0a261961-358a-4f5e-88ec-c8d4b54214ec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 397926/400000 [00:29<00:00, 27843.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.question1]:[torch.cuda.LongTensor of size 25x64 (GPU 0)]\n",
      "\t[.question2]:[torch.cuda.LongTensor of size 27x64 (GPU 0)]\n",
      "\t[.is_duplicate]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[   7,   40,   18,  ...,    4,   16,    7],\n",
       "        [  13,   30,  577,  ...,    2,    5, 1966],\n",
       "        [   8,    8,  210,  ...,   10,   91,   35],\n",
       "        ...,\n",
       "        [   1,    1,    8,  ...,    1,  158,    1],\n",
       "        [   1,    1,    5,  ...,    1, 1437,    1],\n",
       "        [   1,    1,  344,  ...,    1,    1,    1]], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check it works\n",
    "for batch in train_iterator:\n",
    "    print(batch)\n",
    "    break\n",
    "batch.question2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11662,
     "status": "ok",
     "timestamp": 1584988793733,
     "user": {
      "displayName": "Carla Sendra Balcells",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhPZYP2cmKWdA5LesxTBVQPj-8LhB0pIXIfE_Efzw=s64",
      "userId": "01855518481907913222"
     },
     "user_tz": -60
    },
    "id": "6RI31VuZ8aTa",
    "outputId": "32f07773-5cf5-42ff-f3a4-e20c7fce104d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.question1]:[torch.cuda.LongTensor of size 27x64 (GPU 0)]\n",
      "\t[.question2]:[torch.cuda.LongTensor of size 31x64 (GPU 0)]\n",
      "\t[.is_duplicate]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[   4,    5,    5,  ...,   39,   16,    4],\n",
       "        [   2, 3701, 3488,  ...,    5,    5,    2],\n",
       "        [  17,  142,  155,  ..., 7495,   41,    3],\n",
       "        ...,\n",
       "        [   1,    1,    1,  ...,    1,    1,    1],\n",
       "        [   1,    1,    1,  ...,    1,    1,    1],\n",
       "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check it works\n",
    "for batch in test_iterator:\n",
    "    print(batch)\n",
    "    break\n",
    "batch.question1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11626,
     "status": "ok",
     "timestamp": 1584988793734,
     "user": {
      "displayName": "Carla Sendra Balcells",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhPZYP2cmKWdA5LesxTBVQPj-8LhB0pIXIfE_Efzw=s64",
      "userId": "01855518481907913222"
     },
     "user_tz": -60
    },
    "id": "8ci9SY7ttoqO",
    "outputId": "62f67286-31da-4892-fb70-a760daf344ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([27, 64]), torch.Size([31, 64]))"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.question1.shape, batch.question2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1BJAcsonC-CY"
   },
   "outputs": [],
   "source": [
    "#model\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_dim, text, hidden_dim=180, output_dim=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        embedding_dim = 100\n",
    "        vocab = text.vocab\n",
    "        self.embedding = nn.Embedding(vocab_dim, embedding_dim)\n",
    "        self.embedding.weight.data.copy_(vocab.vectors)\n",
    "        self.rnn = torch.nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=2, dropout=dropout, bidirectional=True)\n",
    "        self.hidden_dim = hidden_dim        \n",
    "        self.input_dim = 5 * 2 * self.hidden_dim\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, int(self.input_dim/2)),\n",
    "            nn.Linear(int(self.input_dim/2), output_dim))        \n",
    "        \n",
    "    def forward(self, question1, question2):\n",
    "\n",
    "        #question = [sent len, batch size]        \n",
    "        embedded1 = self.embedding(question1) \n",
    "        embedded2 = self.embedding(question2)\n",
    "    \n",
    "        #embedded = [sent len, batch size, emb dim]        \n",
    "        output1, hidden1 = self.rnn(embedded1)   \n",
    "        output2, hidden2 = self.rnn(embedded2)\n",
    "        \n",
    "        #output = [sent len, batch size, hid dim]\n",
    "        features = torch.cat((output1[-1:,:,:],\n",
    "                              torch.abs(output1[-1:,:,:] - output2[-1:,:,:]),\n",
    "                              output2[-1:,:,:],\n",
    "                              output1[-1:,:,:]*output2[-1:,:,:],\n",
    "                              (output1[-1:,:,:]+output2[-1:,:,:])/2), 2)\n",
    "        \n",
    "        #output = [batch size, 5 * 2 * hidden dim]\n",
    "        y = self.classifier(features)    \n",
    "        return y.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lWAqKlcpjOKT"
   },
   "outputs": [],
   "source": [
    "#define gpu\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 717,
     "status": "ok",
     "timestamp": 1585001757918,
     "user": {
      "displayName": "Carla Sendra Balcells",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhPZYP2cmKWdA5LesxTBVQPj-8LhB0pIXIfE_Efzw=s64",
      "userId": "01855518481907913222"
     },
     "user_tz": -60
    },
    "id": "rnqLsdLqGZdu",
    "outputId": "bd12f7b1-8af6-4281-9e5d-754c4a93d919"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(21130, 100)\n",
       "  (rnn): LSTM(100, 180, num_layers=2, dropout=0.2, bidirectional=True)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=1800, out_features=900, bias=True)\n",
       "    (1): Linear(in_features=900, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 155,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model to gpu\n",
    "model = RNN(vocab_dim=len(question1.vocab), text=question1)\n",
    "model.to(device)\n",
    "#model.load_state_dict(torch.load('model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 393,
     "status": "ok",
     "timestamp": 1585001758290,
     "user": {
      "displayName": "Carla Sendra Balcells",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhPZYP2cmKWdA5LesxTBVQPj-8LhB0pIXIfE_Efzw=s64",
      "userId": "01855518481907913222"
     },
     "user_tz": -60
    },
    "id": "BU2NN9dpGdXk",
    "outputId": "a7584373-9bc3-497d-e8e0-5e329d4138c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2])"
      ]
     },
     "execution_count": 156,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check dimensions of output\n",
    "output = model(batch.question1.to(device), batch.question2.to(device))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1882994,
     "status": "ok",
     "timestamp": 1585003641338,
     "user": {
      "displayName": "Carla Sendra Balcells",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhPZYP2cmKWdA5LesxTBVQPj-8LhB0pIXIfE_Efzw=s64",
      "userId": "01855518481907913222"
     },
     "user_tz": -60
    },
    "id": "08ffiJmZG3ta",
    "outputId": "5aa80cdd-7582-43e3-ab70-e09e77ecbb16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.5000383206961522\n",
      "1 0.7705182225967359\n",
      "2 0.40913461094689807\n",
      "2 0.7963615116132099\n",
      "3 0.35817391190667236\n",
      "3 0.8025286910410337\n",
      "4 0.3147891534897332\n",
      "4 0.8062315251684032\n",
      "5 0.2752241421106832\n",
      "5 0.8057576422071361\n",
      "6 0.2402168107991901\n",
      "6 0.8034861022921398\n",
      "7 0.20881836901826895\n",
      "7 0.803354312562561\n",
      "8 0.18029428348125376\n",
      "8 0.7988636112566776\n",
      "9 0.1575569680628442\n",
      "9 0.8052161598931018\n",
      "10 0.1382584296491191\n",
      "10 0.7995738080693123\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "epochs = 10\n",
    "#criterion = torch.nn.BCEWithLogitsLoss()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1*10**(-3))\n",
    "softmax = torch.nn.Softmax()\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "  loss_values = []\n",
    "  auc_values = []\n",
    "  for batch in train_iterator:\n",
    "    output = model(batch.question1.to(device), batch.question2.to(device))\n",
    "    loss = criterion(output, batch.is_duplicate.long().to(device))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step() \n",
    "    loss_values.append(loss.item()) \n",
    "  print(epoch, np.mean(loss_values))\n",
    "  for batch in test_iterator: \n",
    "    output = model(batch.question1.to(device), batch.question2.to(device))\n",
    "    #output = torch.sigmoid(output)\n",
    "    #output = output > 0.5\n",
    "    output = torch.argmax(softmax(output), dim=1)\n",
    "    #accuracy = (output == batch.is_duplicate.to(device)).float().sum()\n",
    "    auc = metrics.roc_auc_score(output.cpu().detach().numpy(), batch.is_duplicate.cpu().detach().numpy())\n",
    "    auc_values.append(auc) \n",
    "  #print(epoch, torch.mean(torch.stack(auc_values)).item())\n",
    "  print(epoch, np.mean(auc_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5lrL4ok2HQ75"
   },
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(),\"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TRVOn8ihx8hq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM2_spelling_correction_glove.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
