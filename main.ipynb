{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T14:45:09.447952Z",
     "start_time": "2020-03-14T14:45:09.441971Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "from sklearn import *\n",
    "import numpy as np\n",
    "import collections\n",
    "from scipy import sparse\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from CountVectorizer_BagOfWords import CountVectorizer as cv\n",
    "from TfIdfVectorizer import TfIdfVectorizer as tf\n",
    "#from Spelling_Correction_c  import Spelling_Correction_c \n",
    "import xgboost as xgb\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are trying to solve the following problem: given a pair of different questions of Quora, decide if they are asking the same or not. In this notebook, we will discuss the process we have followed to solve the problem, the different models that we have used as well as the mistakes that each model makes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T14:44:22.900000Z",
     "start_time": "2020-03-14T14:44:22.131056Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>346692</td>\n",
       "      <td>38482</td>\n",
       "      <td>10706</td>\n",
       "      <td>Why do I get easily bored with everything?</td>\n",
       "      <td>Why do I get bored with things so quickly and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>327668</td>\n",
       "      <td>454117</td>\n",
       "      <td>345117</td>\n",
       "      <td>How do I study for Honeywell company recruitment?</td>\n",
       "      <td>How do I study for Honeywell company recruitme...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>272993</td>\n",
       "      <td>391373</td>\n",
       "      <td>391374</td>\n",
       "      <td>Which search engine algorithm is Quora using?</td>\n",
       "      <td>Why is Quora not using reliable search engine?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54070</td>\n",
       "      <td>82673</td>\n",
       "      <td>95496</td>\n",
       "      <td>How can I smartly cut myself?</td>\n",
       "      <td>Can someone who thinks about suicide for 7 yea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46450</td>\n",
       "      <td>38384</td>\n",
       "      <td>72436</td>\n",
       "      <td>How do I see who is viewing my Instagram videos?</td>\n",
       "      <td>Can one tell who viewed my Instagram videos?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    qid1    qid2                                          question1  \\\n",
       "0  346692   38482   10706         Why do I get easily bored with everything?   \n",
       "1  327668  454117  345117  How do I study for Honeywell company recruitment?   \n",
       "2  272993  391373  391374      Which search engine algorithm is Quora using?   \n",
       "3   54070   82673   95496                      How can I smartly cut myself?   \n",
       "4   46450   38384   72436   How do I see who is viewing my Instagram videos?   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  Why do I get bored with things so quickly and ...             1  \n",
       "1  How do I study for Honeywell company recruitme...             1  \n",
       "2     Why is Quora not using reliable search engine?             0  \n",
       "3  Can someone who thinks about suicide for 7 yea...             0  \n",
       "4       Can one tell who viewed my Instagram videos?             1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the data\n",
    "available_data = pd.read_csv(\"quora_train_data.csv\")\n",
    "available_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T14:44:23.479283Z",
     "start_time": "2020-03-14T14:44:23.388271Z"
    }
   },
   "outputs": [],
   "source": [
    "#Split data into train and test\n",
    "train_df, test_df = sklearn.model_selection.train_test_split(available_data, test_size=0.1, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUX FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following functions for some of the models.The first functions are meant to extract, given a vectorizer, the matrix of features for the classifier. The two last functions are used to identify the errors that a classifier is making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_list_as_strings(mylist):\n",
    "    \"\"\"\n",
    "    return a list of strings\n",
    "    \"\"\"\n",
    "    assert isinstance(mylist, list), f\"the input mylist should be a list it is {type(mylist)}\"\n",
    "    \n",
    "    mylist_aux = []\n",
    "    \n",
    "    for i in mylist:\n",
    "        mylist_aux.append(str(i))\n",
    "        \n",
    "    return mylist_aux\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "def get_features_from_list(q1,q2,count_vectorizer):\n",
    "    \"\"\"\n",
    "    returns a sparse matrix containing the features build by the count vectorizer.\n",
    "    \"\"\"\n",
    "    \n",
    "    q1_mat = count_vectorizer.transform(q1)\n",
    "    q2_mat = count_vectorizer.transform(q2)\n",
    "    X_q1q2 = hstack([q1_mat,q2_mat])\n",
    "            \n",
    "    return X_q1q2\n",
    "    \n",
    "\n",
    "def get_features_from_df(df, count_vectorizer):\n",
    "    \"\"\"\n",
    "    returns a sparse matrix containing the features build by the count vectorizer.\n",
    "    Each row should contain features from question1 and question2.\n",
    "    \"\"\"\n",
    "    \n",
    "    #list of questions where each element of the question is of type string\n",
    "    q1_casted =  cast_list_as_strings(list(df[\"question1\"]))\n",
    "    q2_casted =  cast_list_as_strings(list(df[\"question2\"]))    \n",
    "    \n",
    "    q1_mat = count_vectorizer.transform(q1_casted)\n",
    "    q2_mat = count_vectorizer.transform(q2_casted)\n",
    "    X_q1q2 = hstack([q1_mat,q2_mat])\n",
    "            \n",
    "    return X_q1q2\n",
    "\n",
    "def get_mistakes(clf, X_q1q2, y):\n",
    "    \"\"\"\n",
    "    Returns two lists: one containing the indices of the predictions that are not correct\n",
    "    and another one containing the predictions\n",
    "    \"\"\"\n",
    "    predictions        = clf.predict(X_q1q2).round(0).astype(int)\n",
    "    incorrect_preds    = predictions != y\n",
    "    incorrect_indices, = np.where(incorrect_preds)\n",
    "    incorrect_indices2 = [x for x in  range(len(incorrect_preds)) if incorrect_preds[x] ==True]\n",
    "    incorrect_indices3 = np.arange(len(incorrect_preds))[incorrect_preds]        \n",
    "    \n",
    "    if np.sum(incorrect_preds)==0:\n",
    "        print(\"no mistakes in this df\")\n",
    "    else:\n",
    "        return incorrect_indices, predictions\n",
    "    \n",
    "def print_mistake_k(k, dataset, mistake_indices, predictions):\n",
    "    \"\"\"\n",
    "    Auxiliar function to print the k-th mistake made in the prediction\n",
    "    \"\"\"\n",
    "    print(\"Original q1: \", train_df.iloc[mistake_indices[k]].question1, \" Treated q1: \", dataset[mistake_indices[k]])\n",
    "    print(\"Original q2: \", train_df.iloc[mistake_indices[k]].question2, \" Treated q2: \", dataset[mistake_indices[k]+train_df.shape[0]])\n",
    "    print(\"true class:\", train_df.iloc[mistake_indices[k]].is_duplicate)\n",
    "    print(\"prediction:\", predictions[mistake_indices[k]])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A first naive model was proposed in class: pass the text through the vectorizers and use the returned matrix as the matrix of features. We saw that the classifier wrongly classified some questions with spelling mistakes. For example, the classifiera would identify as different questions those who were written like \"whats\" from those who were written like \"what's\". \n",
    "\n",
    "We thought that this problem may be common with any model that we try to train, so the first thing we propose to do is correcting the spelling mistakes. We propose to remove \"'s\", change the negatives \"'t\" for \"not\" as well as the plurals \"'re\" for \"are\", remove symbols and points. Then, we implemented a spell checking function using the edit distance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell is necessary in order to obtain a list of documents. This is the structure we usually want, at least for the vectorizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert all elements of the documents into strings \n",
    "q1_train_raw =  cast_list_as_strings(list(train_df[\"question1\"]))\n",
    "q2_train_raw =  cast_list_as_strings(list(train_df[\"question2\"]))\n",
    "q1_test_raw  =  cast_list_as_strings(list(test_df[\"question1\"]))\n",
    "q2_test_raw  =  cast_list_as_strings(list(test_df[\"question2\"]))\n",
    "\n",
    "all_questions_raw = q1_train_raw + q2_train_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code takes a while to compute, so we write the result in a text file. We DON'T NEED TO RUN THE FOLLOWING CELLS, they are here to illustrate the process that we have done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Ignasi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Load the words of our corpus\n",
    "nltk.download('words')\n",
    "words = nltk.corpus.words.words()\n",
    "words.extend(['online', 'Quora'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Spelling_Correction_c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-e6a63c364db9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Create the spelling correction object (it will create the BK tree)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mspelling_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSpelling_Correction_c\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Spelling_Correction_c' is not defined"
     ]
    }
   ],
   "source": [
    "#Create the spelling correction object (it will create the BK tree)\n",
    "spelling_c = Spelling_Correction_c( words, tol = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'why do sasuke have only two car in ex girlfriend the movie'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def document_cleaner_spelling(spelling, text):\n",
    "    clean_doc_pattern = re.compile( r\"('\\w)|([^a-zA-Z0-9.])\") #Find words containing alphanumeric or points\n",
    "    q = re.sub('\\'s', '', text) #Remove 's\n",
    "    q = re.sub('\\'t', ' not', q) #Change 't for not'\n",
    "    q = re.sub('\\'re', ' are', q) #Change 're for are'\n",
    "    q = re.sub('[?%!@#$\\'\\\"\"]', '', q)#Remove symbols\n",
    "    q = re.sub('\\.\\s', ' ', q)#Remove points with a space afterwards\n",
    "    clean_q = clean_doc_pattern.sub(\" \", q)\n",
    "    correct_q = spelling_c.correct_text(clean_q)#Clean spelling mistakes\n",
    "    return correct_q\n",
    "\n",
    "document_cleaner_spelling(spelling_c, \"Why does Sasuke have only two cars in ex-girlfriend The Movie?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "print(len(q1_train))\n",
    "q1_train_cleaned = []\n",
    "for quest in q1_train:\n",
    "    #print(i)\n",
    "    quest_cl = document_cleaner_spelling(spelling_c,quest)\n",
    "    q1_train_cleaned.append(quest_cl)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('q1_train_cleaned.txt', 'w') as f:\n",
    "    for item in q1_train_cleaned:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "print(len(q2_train))\n",
    "q2_train_cleaned = []\n",
    "for quest in q2_train:\n",
    "    #print(i)\n",
    "    quest_cl = document_cleaner_spelling(spelling_c,quest)\n",
    "    q2_train_cleaned.append(quest_cl)\n",
    "    i+=1\n",
    "\n",
    "with open('q2_train_cleaned.txt', 'w') as f:\n",
    "    for item in q2_train_cleaned:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "print(len(q1_test))\n",
    "q1_test_cleaned = []\n",
    "for quest in q1_test:\n",
    "    #print(i)\n",
    "    quest_cl = document_cleaner_spelling(spelling_c,quest)\n",
    "    q1_test_cleaned.append(quest_cl)\n",
    "    i+=1\n",
    "\n",
    "with open('q1_test_cleaned.txt', 'w') as f:\n",
    "    for item in q1_test_cleaned:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "print(len(q2_test))\n",
    "q2_test_cleaned = []\n",
    "for quest in q2_test:\n",
    "    #print(i)\n",
    "    quest_cl = document_cleaner_spelling(spelling_c,quest)\n",
    "    q2_test_cleaned.append(quest_cl)\n",
    "    i+=1\n",
    "\n",
    "with open('q2_test_cleaned.txt', 'w') as f:\n",
    "    for item in q2_test_cleaned:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_labels.txt', 'w') as f:\n",
    "    for item in train_df['is_duplicate'].values:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "\n",
    "with open('test_labels.txt', 'w') as f:\n",
    "    for item in test_df['is_duplicate'].values:\n",
    "        f.write(\"%s\\n\" % item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run from here\n",
    "\n",
    "We run these cells to obtain the results of the  cleaned text fromthe txt files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('q1_train_cleaned.txt') as f:\n",
    "    content = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "q1_train = [x.strip() for x in content] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('q2_train_cleaned.txt') as f:\n",
    "    content = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "q2_train = [x.strip() for x in content] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('q1_test_cleaned.txt') as f:\n",
    "    content = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "q1_test = [x.strip() for x in content] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('q2_test_cleaned.txt') as f:\n",
    "    content = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "q2_test = [x.strip() for x in content] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_questions= q1_train + q2_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_labels.txt') as f:\n",
    "    content = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "train_labels = [int(x.strip()) for x in content] \n",
    "\n",
    "with open('test_labels.txt') as f:\n",
    "    content = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "test_labels = [int(x.strip()) for x in content] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIRST MODEL: NAIVE CLASSIFIER WITH SPELL CHECKING\n",
    "For the first model, we just wanted to see what difference did the spellchecking do. So, did we improve the results? Did we improve the results as expected? If so, what mistakes is our model doing now?\n",
    "\n",
    "We will do this checking for bot the CountVectorizer and the TfIdfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First model - with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T14:44:32.452092Z",
     "start_time": "2020-03-14T14:44:32.447068Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ignasi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Ignasi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer, LancasterStemmer, WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.corpus import stopwords \n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "#How to call such stemmers and lemmatizer in the CountVectorizer object:\n",
    "#PorterStemmer(): token_cleaner_func = PorterStemmer().stem\n",
    "#LancasterStemmer(): token_cleaner_func = LancasterStemmer().stem\n",
    "#SnowballStemmer(language='english'): token_cleaner_func = SnowballStemmer(language='english').stem\n",
    "#WordNetLemmatizer(): token_cleaner_func = lambda doc: WordNetLemmatizer().lemmatize(doc,pos=\"v\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T14:45:21.407870Z",
     "start_time": "2020-03-14T14:45:21.401885Z"
    }
   },
   "outputs": [],
   "source": [
    "#inicialize the CountVectorizer and define its parameters\n",
    "CountVectorizer = cv(stop_words = set(stopwords.words('english')),\n",
    "                     ngram_range=(1,3), max_df = 0.99, min_df = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T14:46:44.793780Z",
     "start_time": "2020-03-14T14:45:42.528916Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(doc_cleaner_pattern=\"('\\\\w+)\", document_cleaner_func=None,\n",
       "        dtype=<class 'numpy.float32'>, max_df=0.99, min_df=5,\n",
       "        min_word_counts=1, ngram_range=(1, 3),\n",
       "        stop_words={'them', 'an', 'herself', 'but', 'd', 'some', 'had', 'yours', \"isn't\", 'than', 'then', 'being', 'after', 'i', 'until', 'with', 'between', 'won', 'should', 'what', 'over', 'again', 'for', 'more', 'before', 'having', 'y', \"aren't\", 'just', 'other', 'wouldn', 'each', 'how', 'does', 'such', '...s', 'who', 'those', 'a', 'as', 'ourselves', \"mightn't\", 'yourself', 'ain', 'nor', 'needn', 'mightn'},\n",
       "        token_cleaner_func=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer_func=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the CountVectorizer\n",
    "CountVectorizer.fit(all_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.99, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 3), preprocessor=None,\n",
       "        stop_words={'them', 'an', 'herself', 'but', 'd', 'some', 'had', 'yours', \"isn't\", 'than', 'then', 'being', 'after', 'i', 'until', 'with', 'between', 'won', 'should', 'what', 'over', 'again', 'for', 'more', 'before', 'having', 'y', \"aren't\", 'just', 'other', 'wouldn', 'each', 'how', 'does', 'such', '...s', 'who', 'those', 'a', 'as', 'ourselves', \"mightn't\", 'yourself', 'ain', 'nor', 'needn', 'mightn'},\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countvect_sk = sklearn.feature_extraction.text.CountVectorizer(stop_words = set(stopwords.words('english')),ngram_range=(1, 3),\n",
    "                                                              max_df = 0.99, min_df = 5)\n",
    "countvect_sk.fit(all_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will the result obtained with our implementation of the CountVectorizer with the result obtained using the sklearn version of the CountVectorizer. One of the objectives of this deliverable was to implement and understend how the vectorizers worked, so we set as an objective to obtain the same as the sklearn vectorizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T14:50:00.712106Z",
     "start_time": "2020-03-14T14:48:57.854063Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With our CountVectorizer:  (291088, 285364) (291088, 6)\n",
      "With sklearn CountVectorizer:  (291088, 285364) (291088, 6)\n"
     ]
    }
   ],
   "source": [
    "X_tr_q1q2 = get_features_from_list(q1_train, q2_train,CountVectorizer)\n",
    "print(\"With our CountVectorizer: \", X_tr_q1q2.shape, train_df.shape)\n",
    "\n",
    "X_tr_q1q2_sk = get_features_from_list(q1_train, q2_train,countvect_sk)\n",
    "print(\"With sklearn CountVectorizer: \", X_tr_q1q2_sk.shape, train_df.shape)\n",
    "\n",
    "X_te_q1q2  = get_features_from_list(q1_test, q2_test, CountVectorizer)\n",
    "\n",
    "X_te_q1q2_sk  = get_features_from_list(q1_test, q2_test, countvect_sk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result using our implementation of CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result on train:  0.8873892706438838\n",
      "Result on test:  0.7564062563763118\n"
     ]
    }
   ],
   "source": [
    "logistic = sklearn.linear_model.LogisticRegression(solver=\"liblinear\")\n",
    "logistic.fit(X_tr_q1q2, train_labels)\n",
    "\n",
    "#train roc auc metrics\n",
    "print(\"Result on train: \", sklearn.metrics.roc_auc_score(y_true = train_labels, y_score = logistic.predict(X_tr_q1q2)))\n",
    "\n",
    "#test roc auc metrics\n",
    "print(\"Result on test: \", sklearn.metrics.roc_auc_score(y_true = test_labels, y_score = logistic.predict(X_te_q1q2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result using sklearn implementation of CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result on train:  0.8873667596649119\n",
      "Result on test:  0.7563817405636126\n"
     ]
    }
   ],
   "source": [
    "logistic_sk = sklearn.linear_model.LogisticRegression(solver=\"liblinear\")\n",
    "logistic_sk.fit(X_tr_q1q2_sk, train_labels)\n",
    "\n",
    "#train roc auc metrics\n",
    "print(\"Result on train: \", sklearn.metrics.roc_auc_score(y_true = train_labels, y_score = logistic_sk.predict(X_tr_q1q2_sk)))\n",
    "\n",
    "#test roc auc metrics\n",
    "print(\"Result on test: \", sklearn.metrics.roc_auc_score(y_true = test_labels, y_score = logistic_sk.predict(X_te_q1q2_sk)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualitative information about the mistakes\n",
    "\n",
    "We wanted to identify the mistakes that the classifier was doing in this case. We saw that the classifier was making mistages mainly for the following reasons:\n",
    "- The questions are the same, but the sentences have lots of different words.\n",
    "- The questions are the same, but one sentence is way larger than the other.\n",
    "- The questions are asking about the same thing but for different years, hence they must be classified as different.\n",
    "- One of the questions is a subset of the other. This mistake is the harder to solve because sometimes it is even debatable of the questions should be the same or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training:  0.9074094431924367\n",
      "Accuracy on test:  0.788647044274054\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on training: \", np.sum(train_labels==logistic.predict(X_tr_q1q2))/len(train_labels))\n",
    "print(\"Accuracy on test: \", np.sum(test_labels ==logistic.predict(X_te_q1q2))/len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original q1:  Why do men like women's feet?  Treated q1:  why do men like woman foot\n",
      "Original q2:  Why do men like womens feet?  Treated q2:  why do men like woman foot\n",
      "true class: 1\n",
      "prediction: 0\n"
     ]
    }
   ],
   "source": [
    "mistake_indices, predictions = get_mistakes(logistic, X_tr_q1q2, train_labels)\n",
    "print_mistake_k(4, all_questions, mistake_indices, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First model - with TfIdfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.99, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=False,\n",
       "        stop_words={'them', 'an', 'herself', 'but', 'd', 'some', 'had', 'yours', \"isn't\", 'than', 'then', 'being', 'after', 'i', 'until', 'with', 'between', 'won', 'should', 'what', 'over', 'again', 'for', 'more', 'before', 'having', 'y', \"aren't\", 'just', 'other', 'wouldn', 'each', 'how', 'does', 'such', '...s', 'who', 'those', 'a', 'as', 'ourselves', \"mightn't\", 'yourself', 'ain', 'nor', 'needn', 'mightn'},\n",
       "        strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=False,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = tf(stop_words = set(stopwords.words('english')), ngram_range=(1,3), max_df = 0.4, min_df = 5)\n",
    "tfidf_vectorizer.fit(all_questions)\n",
    "\n",
    "tfidf_sk = sklearn.feature_extraction.text.TfidfVectorizer(use_idf=False, smooth_idf=False, sublinear_tf=False,\n",
    "                                                          stop_words = set(stopwords.words('english')),\n",
    "                                                          ngram_range=(1,3), max_df = 0.99, min_df = 5)\n",
    "tfidf_sk.fit(all_questions) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, remember that additionally, we want to compare our result with that given by the implementation of sklearn of the TfIdfVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With our TfIdf Vectorizer: (291088, 285364) (291088, 6)\n",
      "With sklearn TfIdf Vectorizer: (291088, 285364) (291088, 6)\n"
     ]
    }
   ],
   "source": [
    "X_tr_q1q2 = get_features_from_list(q1_train, q2_train,tfidf_vectorizer)\n",
    "X_tr_q1q2_sk = get_features_from_list(q1_train, q2_train, tfidf_sk)\n",
    "X_te_q1q2  = get_features_from_list(q1_test, q2_test, tfidf_vectorizer)\n",
    "X_te_q1q2_sk  = get_features_from_list(q1_test, q2_test, tfidf_sk)\n",
    "\n",
    "print(\"With our TfIdf Vectorizer:\", X_tr_q1q2.shape, train_df.shape)\n",
    "print(\"With sklearn TfIdf Vectorizer:\", X_tr_q1q2_sk.shape, train_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result using our implementation of TfIdf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result on train:  0.8303725534934316\n",
      "Result on test:  0.7532320054109183\n"
     ]
    }
   ],
   "source": [
    "logistic = sklearn.linear_model.LogisticRegression(solver=\"liblinear\")\n",
    "logistic.fit(X_tr_q1q2, train_labels)\n",
    "\n",
    "print(\"Result on train: \", sklearn.metrics.roc_auc_score(y_true = train_labels, y_score = logistic.predict(X_tr_q1q2)))\n",
    "\n",
    "#test roc auc metrics\n",
    "print(\"Result on test: \", sklearn.metrics.roc_auc_score(y_true = test_labels, y_score = logistic.predict(X_te_q1q2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result using sklearn implementation of TfIdf Vectorizer. Note that the result is different because the formula that sklearn uses is different from ours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result on train:  0.8039907438250422\n",
      "Result on test:  0.7445016739956617\n"
     ]
    }
   ],
   "source": [
    "logistic_sk = sklearn.linear_model.LogisticRegression(solver=\"liblinear\")\n",
    "logistic_sk.fit(X_tr_q1q2_sk, train_labels)\n",
    "\n",
    "print(\"Result on train: \", sklearn.metrics.roc_auc_score(y_true = train_labels, y_score = logistic_sk.predict(X_tr_q1q2_sk)))\n",
    "\n",
    "#test roc auc metrics\n",
    "print(\"Result on test: \", sklearn.metrics.roc_auc_score(y_true = test_labels, y_score = logistic_sk.predict(X_te_q1q2_sk)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualitative information about the mistakes\n",
    "\n",
    "So, in this case, the mistakes are practically the same, hence:\n",
    "- The questions are the same, but the sentences have lots of different words.\n",
    "- The questions are the same, but one sentence is way larger than the other.\n",
    "- The questions are asking about the same thing but for different years, hence they must be classified as different.\n",
    "- One of the questions is a subset of the other. This mistake is the harder to solve because sometimes it is even debatable of the questions should be the same or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training:  0.8615642005166823\n",
      "Accuracy on test:  0.7928827603264902\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on training: \", np.sum(train_labels ==logistic.predict(X_tr_q1q2))/len(train_labels))\n",
    "print(\"Accuracy on test: \", np.sum(test_labels ==logistic.predict(X_te_q1q2))/len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original q1:  Are Persians considered Caucasian?  Treated q1:  be Persian consider Caucasian\n",
      "Original q2:  Are Persians White?  Treated q2:  be Persian white\n",
      "true class: 1\n",
      "prediction: 0\n"
     ]
    }
   ],
   "source": [
    "mistake_indices, predictions = get_mistakes(logistic, X_tr_q1q2, train_labels)\n",
    "print_mistake_k(4, all_questions, mistake_indices, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECOND MODEL: NAIVE CLASSIFIER WITH EXTRA FEATURES\n",
    "\n",
    "Given the mistakes encountered in the previous model, we tried to code some extra features to tackle with those problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to obtain the extra features.\n",
    "\n",
    "Here we give a list of extra features that we could add to the feature vector.\n",
    "\n",
    "1. Lenght of the question\n",
    "\n",
    "2. Is there a [math] tag? \n",
    "\n",
    "3. Is there a number in the question?\n",
    "\n",
    "4. Is it the same number in both questions? \n",
    "\n",
    "5. % of intersection words?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qlength(questions):\n",
    "    qlen = []\n",
    "    for quest in questions:\n",
    "        clean_doc_pattern = re.compile( r\"('\\w)|([^a-zA-Z0-9.])\") #Find words containing alphanumeric or points\n",
    "        q = re.sub('\\'s', '', quest) #Remove 's\n",
    "        q = re.sub('\\'t', ' not', q) #Change 't for not'\n",
    "        q = re.sub('\\'re', ' are', q) #Change 're for are'\n",
    "        q = re.sub('[?%!@#$\\'\\\"\"]', '', q)#Remove symbols\n",
    "        q = re.sub('\\.\\s', ' ', q)#Remove points with a space afterwards\n",
    "        clean_q = clean_doc_pattern.sub(\" \", q)\n",
    "        qlen.append(len(re.findall(r\"(?u)\\b[\\w.,]+\\b\",q)))\n",
    "        \n",
    "    return np.array(qlen).reshape(-1,1)\n",
    "\n",
    "def is_math(questions):\n",
    "    math=[]\n",
    "    for quest in questions:\n",
    "        if '[math]' in quest:\n",
    "            math.append(1)\n",
    "        else:\n",
    "            math.append(0)\n",
    "    return np.array(math).reshape(-1,1)\n",
    "    \n",
    "def is_number(word):\n",
    "    try :  \n",
    "        w = float(word) \n",
    "        if(np.isnan(w)):\n",
    "            return 0\n",
    "        if(np.isinf(w)):\n",
    "            return 0\n",
    "        res = 1\n",
    "    except : \n",
    "        res = 0\n",
    "    return res    \n",
    "\n",
    "def has_numbers(questions):\n",
    "    num=np.zeros((len(questions)))\n",
    "    which_num = np.zeros((len(questions)))\n",
    "    i=0\n",
    "    for quest in questions:\n",
    "        for w in re.findall(r\"(?u)\\b[\\w.,]+\\b\",quest):\n",
    "            is_num = is_number(w)\n",
    "            if is_num==1:\n",
    "                num[i]=1\n",
    "                which_num[i]=float(w)\n",
    "                if(np.isnan(which_num[i])):\n",
    "                    print(which_num[i])\n",
    "                    print(float(w))\n",
    "                break\n",
    "        i+=1\n",
    "    return num.reshape(-1,1), which_num.reshape(-1,1)\n",
    "\n",
    "\n",
    "def is_different_number(which_num1, which_num2):\n",
    "    dif = which_num1 - which_num2\n",
    "    dif[dif>0]=1\n",
    "    return np.array(dif).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1_q2_intersect(row, q1, q2, q_dict):\n",
    "    set1 = set(q_dict[q1[row]])\n",
    "    set2 = set(q_dict[q2[row]])\n",
    "    return(len(set1.intersection(set2))/len(set1.union(set2)))\n",
    "\n",
    "\n",
    "def intersection(q1_train, q2_train, q1_test, q2_test):\n",
    "    q1 = q1_train + q1_test\n",
    "    q2 = q2_train + q2_test\n",
    "    q_dict = defaultdict(set)\n",
    "    for i in range(len(q1)):\n",
    "            q_dict[q1[i]].add(q2[i])\n",
    "            q_dict[q2[i]].add(q1[i])\n",
    "\n",
    "    intersect_train = []\n",
    "    intersect_test = []\n",
    "    for row in range(len(q1_train)):\n",
    "        intersect_train.append(q1_q2_intersect(row, q1_train, q2_train, q_dict))\n",
    "    \n",
    "    for row in range(len(q1_test)):\n",
    "        intersect_test.append(q1_q2_intersect(row, q1_test, q2_test, q_dict))\n",
    "    \n",
    "    return np.array(intersect_train).reshape(-1,1), np.array(intersect_test).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect_train, intersect_test = intersection(q1_train, q2_train, q1_test, q2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "num1_train, which_num1_train=  has_numbers(q1_train_raw)\n",
    "num2_train, which_num2_train =  has_numbers(q2_train_raw)\n",
    "dif_number_train = is_different_number(which_num1_train,which_num2_train)\n",
    "\n",
    "num1_test, which_num1_test=  has_numbers(q1_test_raw)\n",
    "num2_test, which_num2_test =  has_numbers(q2_test_raw)\n",
    "dif_number_test = is_different_number(which_num1_test,which_num2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "math1_train = is_math(q1_train_raw)\n",
    "math2_train = is_math(q2_train_raw)\n",
    "\n",
    "math1_test = is_math(q1_test_raw)\n",
    "math2_test = is_math(q2_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "len1_train = get_qlength(q1_train_raw)\n",
    "len2_train = get_qlength(q2_train_raw)\n",
    "\n",
    "len1_test = get_qlength(q1_test_raw)\n",
    "len2_test = get_qlength(q2_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second model - with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T14:44:32.452092Z",
     "start_time": "2020-03-14T14:44:32.447068Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ignasi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Ignasi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.99, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 3), preprocessor=None,\n",
       "        stop_words={'them', 'an', 'herself', 'but', 'd', 'some', 'had', 'yours', \"isn't\", 'than', 'then', 'being', 'after', 'i', 'until', 'with', 'between', 'won', 'should', 'what', 'over', 'again', 'for', 'more', 'before', 'having', 'y', \"aren't\", 'just', 'other', 'wouldn', 'each', 'how', 'does', 'such', '...s', 'who', 'those', 'a', 'as', 'ourselves', \"mightn't\", 'yourself', 'ain', 'nor', 'needn', 'mightn'},\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer, LancasterStemmer, WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.corpus import stopwords \n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "#inicialize the CountVectorizer and define its parameters\n",
    "CountVectorizer = cv(stop_words = set(stopwords.words('english')),\n",
    "                     ngram_range=(1,3), max_df = 0.99, min_df = 5)\n",
    "#fit the CountVectorizer\n",
    "CountVectorizer.fit(all_questions)\n",
    "\n",
    "countvect_sk = sklearn.feature_extraction.text.CountVectorizer(stop_words = set(stopwords.words('english')),ngram_range=(1, 3),\n",
    "                                                              max_df = 0.99, min_df = 5)\n",
    "countvect_sk.fit(all_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, since we have already check that our CountVectorizer yields the same result as the sklearn one, we will only use ours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T14:50:00.712106Z",
     "start_time": "2020-03-14T14:48:57.854063Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_tr_q1q2 = get_features_from_list(q1_train, q2_train,CountVectorizer)\n",
    "X_te_q1q2  = get_features_from_list(q1_test, q2_test, CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial shape (291088, 285364)\n",
      "final shape (291088, 285372)\n"
     ]
    }
   ],
   "source": [
    "print('initial shape', X_tr_q1q2.shape)\n",
    "\n",
    "new_X_tr_q1q2 = sparse.hstack((X_tr_q1q2,intersect_train, num1_train, num2_train,\n",
    "                               dif_number_train,math1_train,math2_train,len1_train, len2_train))\n",
    "\n",
    "new_X_te_q1q2 = sparse.hstack((X_te_q1q2,intersect_test, num1_test, num2_test,\n",
    "                               dif_number_test, math1_test,math2_test,len1_test, len2_test))\n",
    "\n",
    "print('final shape', new_X_tr_q1q2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain the following result. We see that there is not much of an improvement. We think that this may be due to the imbalance of the values of the different features, i.e., we are not normalizing the values of any of the features. We thought that it would be necessary to change the model, then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result on train:  0.8873892706438838\n",
      "Result on test:  0.7564062563763118\n"
     ]
    }
   ],
   "source": [
    "logistic = sklearn.linear_model.LogisticRegression(solver=\"liblinear\")\n",
    "logistic.fit(X_tr_q1q2, train_labels)\n",
    "\n",
    "#train roc auc metrics\n",
    "print(\"Result on train: \", sklearn.metrics.roc_auc_score(y_true = train_labels, y_score = logistic.predict(X_tr_q1q2)))\n",
    "\n",
    "#test roc auc metrics\n",
    "print(\"Result on test: \", sklearn.metrics.roc_auc_score(y_true = test_labels, y_score = logistic.predict(X_te_q1q2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second model - with TfIdfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.99, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=False,\n",
       "        stop_words={'them', 'an', 'herself', 'but', 'd', 'some', 'had', 'yours', \"isn't\", 'than', 'then', 'being', 'after', 'i', 'until', 'with', 'between', 'won', 'should', 'what', 'over', 'again', 'for', 'more', 'before', 'having', 'y', \"aren't\", 'just', 'other', 'wouldn', 'each', 'how', 'does', 'such', '...s', 'who', 'those', 'a', 'as', 'ourselves', \"mightn't\", 'yourself', 'ain', 'nor', 'needn', 'mightn'},\n",
       "        strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=False,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = tf(stop_words = set(stopwords.words('english')), ngram_range=(1,3), max_df = 0.4, min_df = 5)\n",
    "tfidf_vectorizer.fit(all_questions)\n",
    "\n",
    "tfidf_sk = sklearn.feature_extraction.text.TfidfVectorizer(use_idf=False, smooth_idf=False, sublinear_tf=False,\n",
    "                                                          stop_words = set(stopwords.words('english')),\n",
    "                                                          ngram_range=(1,3), max_df = 0.99, min_df = 5)\n",
    "tfidf_sk.fit(all_questions) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we will only run the code for our TfIdfVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_q1q2 = get_features_from_list(q1_train, q2_train,tfidf_vectorizer)\n",
    "X_te_q1q2  = get_features_from_list(q1_test, q2_test, tfidf_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial shape (291088, 285364)\n",
      "final shape (291088, 285372)\n"
     ]
    }
   ],
   "source": [
    "print('initial shape', X_tr_q1q2.shape)\n",
    "\n",
    "new_X_tr_q1q2 = sparse.hstack((X_tr_q1q2,intersect_train, num1_train, num2_train,\n",
    "                               dif_number_train,math1_train,math2_train,len1_train, len2_train))\n",
    "\n",
    "new_X_te_q1q2 = sparse.hstack((X_te_q1q2,intersect_test, num1_test, num2_test,\n",
    "                               dif_number_test, math1_test,math2_test,len1_test, len2_test))\n",
    "\n",
    "print('final shape', new_X_tr_q1q2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very similar thing happens with the tfidfVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result on train:  0.8303725534934316\n",
      "Result on test:  0.7532320054109183\n"
     ]
    }
   ],
   "source": [
    "logistic = sklearn.linear_model.LogisticRegression(solver=\"liblinear\")\n",
    "logistic.fit(X_tr_q1q2, train_labels)\n",
    "\n",
    "print(\"Result on train: \", sklearn.metrics.roc_auc_score(y_true = train_labels, y_score = logistic.predict(X_tr_q1q2)))\n",
    "\n",
    "#test roc auc metrics\n",
    "print(\"Result on test: \", sklearn.metrics.roc_auc_score(y_true = test_labels, y_score = logistic.predict(X_te_q1q2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THIRD MODEL: XGBOOST\n",
    "\n",
    "Given all the previous results, a thing was clear: we needed to change the classifier. So our take was: combine everything we have done until now (text with the spell checking and the extra features) but with a more sophisticated model. We chose the XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third model - with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T14:44:32.452092Z",
     "start_time": "2020-03-14T14:44:32.447068Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ignasi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Ignasi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial shape (291088, 285364)\n",
      "final shape (291088, 285372)\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer, LancasterStemmer, WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.corpus import stopwords \n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "#inicialize the CountVectorizer and define its parameters\n",
    "CountVectorizer = cv(stop_words = set(stopwords.words('english')),\n",
    "                     ngram_range=(1,3), max_df = 0.99, min_df = 5)\n",
    "#fit the CountVectorizer\n",
    "CountVectorizer.fit(all_questions)\n",
    "\n",
    "countvect_sk = sklearn.feature_extraction.text.CountVectorizer(stop_words = set(stopwords.words('english')),ngram_range=(1, 3),\n",
    "                                                              max_df = 0.99, min_df = 5)\n",
    "countvect_sk.fit(all_questions)\n",
    "\n",
    "X_tr_q1q2 = get_features_from_list(q1_train, q2_train,CountVectorizer)\n",
    "X_te_q1q2  = get_features_from_list(q1_test, q2_test, CountVectorizer)\n",
    "\n",
    "print('initial shape', X_tr_q1q2.shape)\n",
    "new_X_tr_q1q2 = sparse.hstack((X_tr_q1q2,intersect_train, num1_train, num2_train,\n",
    "                               dif_number_train,math1_train,math2_train,len1_train, len2_train))\n",
    "new_X_te_q1q2 = sparse.hstack((X_te_q1q2,intersect_test, num1_test, num2_test,\n",
    "                               dif_number_test, math1_test,math2_test,len1_test, len2_test))\n",
    "print('final shape', new_X_tr_q1q2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.82769\ttest-auc:0.82534\n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 50 rounds.\n",
      "[10]\ttrain-auc:0.83285\ttest-auc:0.82989\n",
      "[20]\ttrain-auc:0.83325\ttest-auc:0.83053\n",
      "[30]\ttrain-auc:0.83574\ttest-auc:0.83320\n",
      "[40]\ttrain-auc:0.83592\ttest-auc:0.83329\n",
      "[50]\ttrain-auc:0.83727\ttest-auc:0.83427\n",
      "[60]\ttrain-auc:0.83765\ttest-auc:0.83447\n",
      "[70]\ttrain-auc:0.83845\ttest-auc:0.83486\n",
      "[80]\ttrain-auc:0.84003\ttest-auc:0.83675\n",
      "[90]\ttrain-auc:0.84034\ttest-auc:0.83716\n",
      "[100]\ttrain-auc:0.84131\ttest-auc:0.83839\n",
      "[110]\ttrain-auc:0.84167\ttest-auc:0.83879\n",
      "[120]\ttrain-auc:0.84227\ttest-auc:0.83951\n",
      "[130]\ttrain-auc:0.84266\ttest-auc:0.84011\n",
      "[140]\ttrain-auc:0.84382\ttest-auc:0.84161\n",
      "[150]\ttrain-auc:0.84432\ttest-auc:0.84220\n",
      "[160]\ttrain-auc:0.84494\ttest-auc:0.84270\n",
      "[170]\ttrain-auc:0.84575\ttest-auc:0.84347\n",
      "[180]\ttrain-auc:0.84652\ttest-auc:0.84402\n",
      "[190]\ttrain-auc:0.84688\ttest-auc:0.84453\n",
      "[200]\ttrain-auc:0.84757\ttest-auc:0.84494\n",
      "[210]\ttrain-auc:0.84943\ttest-auc:0.84651\n",
      "[220]\ttrain-auc:0.85099\ttest-auc:0.84789\n",
      "[230]\ttrain-auc:0.85184\ttest-auc:0.84892\n",
      "[240]\ttrain-auc:0.85260\ttest-auc:0.84977\n",
      "[250]\ttrain-auc:0.85312\ttest-auc:0.85023\n",
      "[260]\ttrain-auc:0.85362\ttest-auc:0.85084\n",
      "[270]\ttrain-auc:0.85404\ttest-auc:0.85113\n",
      "[280]\ttrain-auc:0.85459\ttest-auc:0.85172\n",
      "[290]\ttrain-auc:0.85501\ttest-auc:0.85214\n",
      "[300]\ttrain-auc:0.85529\ttest-auc:0.85245\n",
      "[310]\ttrain-auc:0.85573\ttest-auc:0.85269\n",
      "[320]\ttrain-auc:0.85603\ttest-auc:0.85296\n",
      "[330]\ttrain-auc:0.85630\ttest-auc:0.85334\n",
      "[340]\ttrain-auc:0.85664\ttest-auc:0.85360\n",
      "[350]\ttrain-auc:0.85697\ttest-auc:0.85398\n",
      "[360]\ttrain-auc:0.85732\ttest-auc:0.85423\n",
      "[370]\ttrain-auc:0.85753\ttest-auc:0.85442\n",
      "[380]\ttrain-auc:0.85787\ttest-auc:0.85469\n",
      "[390]\ttrain-auc:0.85835\ttest-auc:0.85528\n",
      "[400]\ttrain-auc:0.85866\ttest-auc:0.85560\n",
      "[410]\ttrain-auc:0.85894\ttest-auc:0.85593\n",
      "[420]\ttrain-auc:0.85924\ttest-auc:0.85608\n",
      "[430]\ttrain-auc:0.85953\ttest-auc:0.85635\n",
      "[440]\ttrain-auc:0.85977\ttest-auc:0.85660\n",
      "[450]\ttrain-auc:0.86003\ttest-auc:0.85691\n",
      "[460]\ttrain-auc:0.86021\ttest-auc:0.85709\n",
      "[470]\ttrain-auc:0.86042\ttest-auc:0.85724\n",
      "[480]\ttrain-auc:0.86061\ttest-auc:0.85743\n",
      "[490]\ttrain-auc:0.86086\ttest-auc:0.85759\n",
      "[500]\ttrain-auc:0.86106\ttest-auc:0.85780\n",
      "[510]\ttrain-auc:0.86135\ttest-auc:0.85809\n",
      "[520]\ttrain-auc:0.86162\ttest-auc:0.85821\n",
      "[530]\ttrain-auc:0.86193\ttest-auc:0.85860\n",
      "[540]\ttrain-auc:0.86214\ttest-auc:0.85867\n",
      "[550]\ttrain-auc:0.86244\ttest-auc:0.85893\n",
      "[560]\ttrain-auc:0.86271\ttest-auc:0.85916\n",
      "[570]\ttrain-auc:0.86293\ttest-auc:0.85934\n",
      "[580]\ttrain-auc:0.86323\ttest-auc:0.85956\n",
      "[590]\ttrain-auc:0.86341\ttest-auc:0.85971\n",
      "[600]\ttrain-auc:0.86364\ttest-auc:0.85995\n",
      "[610]\ttrain-auc:0.86379\ttest-auc:0.86008\n",
      "[620]\ttrain-auc:0.86388\ttest-auc:0.86014\n",
      "[630]\ttrain-auc:0.86413\ttest-auc:0.86038\n",
      "[640]\ttrain-auc:0.86438\ttest-auc:0.86059\n",
      "[650]\ttrain-auc:0.86458\ttest-auc:0.86074\n",
      "[660]\ttrain-auc:0.86476\ttest-auc:0.86090\n",
      "[670]\ttrain-auc:0.86493\ttest-auc:0.86099\n",
      "[680]\ttrain-auc:0.86514\ttest-auc:0.86119\n",
      "[690]\ttrain-auc:0.86539\ttest-auc:0.86133\n",
      "[700]\ttrain-auc:0.86557\ttest-auc:0.86149\n",
      "[710]\ttrain-auc:0.86571\ttest-auc:0.86160\n",
      "[720]\ttrain-auc:0.86590\ttest-auc:0.86172\n",
      "[730]\ttrain-auc:0.86604\ttest-auc:0.86183\n",
      "[740]\ttrain-auc:0.86622\ttest-auc:0.86194\n",
      "[750]\ttrain-auc:0.86641\ttest-auc:0.86217\n",
      "[760]\ttrain-auc:0.86659\ttest-auc:0.86232\n",
      "[770]\ttrain-auc:0.86674\ttest-auc:0.86239\n",
      "[780]\ttrain-auc:0.86689\ttest-auc:0.86253\n",
      "[790]\ttrain-auc:0.86704\ttest-auc:0.86265\n",
      "[800]\ttrain-auc:0.86719\ttest-auc:0.86275\n",
      "[810]\ttrain-auc:0.86739\ttest-auc:0.86295\n",
      "[820]\ttrain-auc:0.86756\ttest-auc:0.86303\n",
      "[830]\ttrain-auc:0.86773\ttest-auc:0.86321\n",
      "[840]\ttrain-auc:0.86790\ttest-auc:0.86332\n",
      "[850]\ttrain-auc:0.86804\ttest-auc:0.86341\n",
      "[860]\ttrain-auc:0.86819\ttest-auc:0.86350\n",
      "[870]\ttrain-auc:0.86830\ttest-auc:0.86360\n",
      "[880]\ttrain-auc:0.86861\ttest-auc:0.86389\n",
      "[890]\ttrain-auc:0.86872\ttest-auc:0.86398\n",
      "[900]\ttrain-auc:0.86885\ttest-auc:0.86406\n",
      "[910]\ttrain-auc:0.86898\ttest-auc:0.86417\n",
      "[920]\ttrain-auc:0.86917\ttest-auc:0.86429\n",
      "[930]\ttrain-auc:0.86935\ttest-auc:0.86441\n",
      "[940]\ttrain-auc:0.86949\ttest-auc:0.86452\n",
      "[950]\ttrain-auc:0.86960\ttest-auc:0.86460\n",
      "[960]\ttrain-auc:0.86969\ttest-auc:0.86465\n",
      "[970]\ttrain-auc:0.86985\ttest-auc:0.86479\n",
      "[980]\ttrain-auc:0.86995\ttest-auc:0.86484\n",
      "[990]\ttrain-auc:0.87005\ttest-auc:0.86496\n",
      "[1000]\ttrain-auc:0.87028\ttest-auc:0.86514\n",
      "[1010]\ttrain-auc:0.87037\ttest-auc:0.86523\n",
      "[1020]\ttrain-auc:0.87046\ttest-auc:0.86526\n",
      "[1030]\ttrain-auc:0.87061\ttest-auc:0.86547\n",
      "[1040]\ttrain-auc:0.87072\ttest-auc:0.86557\n",
      "[1050]\ttrain-auc:0.87081\ttest-auc:0.86562\n",
      "[1060]\ttrain-auc:0.87095\ttest-auc:0.86574\n",
      "[1070]\ttrain-auc:0.87107\ttest-auc:0.86581\n",
      "[1080]\ttrain-auc:0.87116\ttest-auc:0.86583\n",
      "[1090]\ttrain-auc:0.87130\ttest-auc:0.86596\n",
      "[1100]\ttrain-auc:0.87150\ttest-auc:0.86615\n",
      "[1110]\ttrain-auc:0.87163\ttest-auc:0.86625\n",
      "[1120]\ttrain-auc:0.87171\ttest-auc:0.86630\n",
      "[1130]\ttrain-auc:0.87181\ttest-auc:0.86637\n",
      "[1140]\ttrain-auc:0.87193\ttest-auc:0.86647\n",
      "[1150]\ttrain-auc:0.87199\ttest-auc:0.86654\n",
      "[1160]\ttrain-auc:0.87207\ttest-auc:0.86658\n",
      "[1170]\ttrain-auc:0.87216\ttest-auc:0.86662\n",
      "[1180]\ttrain-auc:0.87234\ttest-auc:0.86682\n",
      "[1190]\ttrain-auc:0.87240\ttest-auc:0.86688\n",
      "[1200]\ttrain-auc:0.87251\ttest-auc:0.86698\n",
      "[1210]\ttrain-auc:0.87267\ttest-auc:0.86712\n",
      "[1220]\ttrain-auc:0.87278\ttest-auc:0.86717\n",
      "[1230]\ttrain-auc:0.87286\ttest-auc:0.86720\n",
      "[1240]\ttrain-auc:0.87296\ttest-auc:0.86725\n",
      "[1250]\ttrain-auc:0.87304\ttest-auc:0.86733\n",
      "[1260]\ttrain-auc:0.87314\ttest-auc:0.86739\n",
      "[1270]\ttrain-auc:0.87327\ttest-auc:0.86749\n",
      "[1280]\ttrain-auc:0.87339\ttest-auc:0.86758\n",
      "[1290]\ttrain-auc:0.87347\ttest-auc:0.86765\n",
      "[1300]\ttrain-auc:0.87355\ttest-auc:0.86769\n",
      "[1310]\ttrain-auc:0.87366\ttest-auc:0.86773\n",
      "[1320]\ttrain-auc:0.87374\ttest-auc:0.86779\n",
      "[1330]\ttrain-auc:0.87383\ttest-auc:0.86785\n",
      "[1340]\ttrain-auc:0.87391\ttest-auc:0.86792\n",
      "[1350]\ttrain-auc:0.87400\ttest-auc:0.86796\n",
      "[1360]\ttrain-auc:0.87410\ttest-auc:0.86804\n",
      "[1370]\ttrain-auc:0.87420\ttest-auc:0.86810\n",
      "[1380]\ttrain-auc:0.87430\ttest-auc:0.86817\n",
      "[1390]\ttrain-auc:0.87438\ttest-auc:0.86824\n",
      "[1400]\ttrain-auc:0.87452\ttest-auc:0.86839\n",
      "[1410]\ttrain-auc:0.87461\ttest-auc:0.86844\n",
      "[1420]\ttrain-auc:0.87471\ttest-auc:0.86848\n",
      "[1430]\ttrain-auc:0.87481\ttest-auc:0.86856\n",
      "[1440]\ttrain-auc:0.87491\ttest-auc:0.86863\n",
      "[1450]\ttrain-auc:0.87498\ttest-auc:0.86867\n",
      "[1460]\ttrain-auc:0.87507\ttest-auc:0.86874\n",
      "[1470]\ttrain-auc:0.87514\ttest-auc:0.86879\n",
      "[1480]\ttrain-auc:0.87521\ttest-auc:0.86884\n",
      "[1490]\ttrain-auc:0.87531\ttest-auc:0.86892\n",
      "[1500]\ttrain-auc:0.87542\ttest-auc:0.86901\n",
      "[1510]\ttrain-auc:0.87550\ttest-auc:0.86908\n",
      "[1520]\ttrain-auc:0.87558\ttest-auc:0.86916\n",
      "[1530]\ttrain-auc:0.87568\ttest-auc:0.86920\n",
      "[1540]\ttrain-auc:0.87577\ttest-auc:0.86924\n",
      "[1550]\ttrain-auc:0.87590\ttest-auc:0.86933\n",
      "[1560]\ttrain-auc:0.87603\ttest-auc:0.86947\n",
      "[1570]\ttrain-auc:0.87610\ttest-auc:0.86948\n",
      "[1580]\ttrain-auc:0.87618\ttest-auc:0.86953\n",
      "[1590]\ttrain-auc:0.87625\ttest-auc:0.86955\n",
      "[1600]\ttrain-auc:0.87636\ttest-auc:0.86962\n",
      "[1610]\ttrain-auc:0.87643\ttest-auc:0.86966\n",
      "[1620]\ttrain-auc:0.87652\ttest-auc:0.86974\n",
      "[1630]\ttrain-auc:0.87662\ttest-auc:0.86982\n",
      "[1640]\ttrain-auc:0.87674\ttest-auc:0.86990\n",
      "[1650]\ttrain-auc:0.87682\ttest-auc:0.86994\n",
      "[1660]\ttrain-auc:0.87689\ttest-auc:0.86995\n",
      "[1670]\ttrain-auc:0.87699\ttest-auc:0.87000\n",
      "[1680]\ttrain-auc:0.87706\ttest-auc:0.87006\n",
      "[1690]\ttrain-auc:0.87712\ttest-auc:0.87011\n",
      "[1700]\ttrain-auc:0.87721\ttest-auc:0.87016\n",
      "[1710]\ttrain-auc:0.87728\ttest-auc:0.87021\n",
      "[1720]\ttrain-auc:0.87740\ttest-auc:0.87032\n",
      "[1730]\ttrain-auc:0.87745\ttest-auc:0.87035\n",
      "[1740]\ttrain-auc:0.87752\ttest-auc:0.87040\n",
      "[1750]\ttrain-auc:0.87760\ttest-auc:0.87044\n",
      "[1760]\ttrain-auc:0.87767\ttest-auc:0.87046\n",
      "[1770]\ttrain-auc:0.87774\ttest-auc:0.87052\n",
      "[1780]\ttrain-auc:0.87783\ttest-auc:0.87057\n",
      "[1790]\ttrain-auc:0.87792\ttest-auc:0.87061\n",
      "[1800]\ttrain-auc:0.87806\ttest-auc:0.87082\n",
      "[1810]\ttrain-auc:0.87813\ttest-auc:0.87084\n",
      "[1820]\ttrain-auc:0.87820\ttest-auc:0.87090\n",
      "[1830]\ttrain-auc:0.87828\ttest-auc:0.87093\n",
      "[1840]\ttrain-auc:0.87834\ttest-auc:0.87097\n",
      "[1850]\ttrain-auc:0.87841\ttest-auc:0.87102\n",
      "[1860]\ttrain-auc:0.87850\ttest-auc:0.87108\n",
      "[1870]\ttrain-auc:0.87859\ttest-auc:0.87113\n",
      "[1880]\ttrain-auc:0.87867\ttest-auc:0.87121\n",
      "[1890]\ttrain-auc:0.87874\ttest-auc:0.87126\n",
      "[1900]\ttrain-auc:0.87882\ttest-auc:0.87130\n",
      "[1910]\ttrain-auc:0.87888\ttest-auc:0.87133\n",
      "[1920]\ttrain-auc:0.87897\ttest-auc:0.87141\n",
      "[1930]\ttrain-auc:0.87905\ttest-auc:0.87147\n",
      "[1940]\ttrain-auc:0.87913\ttest-auc:0.87152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1950]\ttrain-auc:0.87919\ttest-auc:0.87157\n",
      "[1960]\ttrain-auc:0.87924\ttest-auc:0.87160\n",
      "[1970]\ttrain-auc:0.87930\ttest-auc:0.87163\n",
      "[1980]\ttrain-auc:0.87936\ttest-auc:0.87165\n",
      "[1990]\ttrain-auc:0.87943\ttest-auc:0.87169\n",
      "[2000]\ttrain-auc:0.87949\ttest-auc:0.87172\n",
      "[2010]\ttrain-auc:0.87958\ttest-auc:0.87183\n",
      "[2020]\ttrain-auc:0.87965\ttest-auc:0.87184\n",
      "[2030]\ttrain-auc:0.87972\ttest-auc:0.87187\n",
      "[2040]\ttrain-auc:0.87977\ttest-auc:0.87191\n",
      "[2050]\ttrain-auc:0.87984\ttest-auc:0.87196\n",
      "[2060]\ttrain-auc:0.87991\ttest-auc:0.87200\n",
      "[2070]\ttrain-auc:0.87996\ttest-auc:0.87205\n",
      "[2080]\ttrain-auc:0.88001\ttest-auc:0.87208\n",
      "[2090]\ttrain-auc:0.88007\ttest-auc:0.87210\n",
      "[2100]\ttrain-auc:0.88016\ttest-auc:0.87217\n",
      "[2110]\ttrain-auc:0.88022\ttest-auc:0.87221\n",
      "[2120]\ttrain-auc:0.88030\ttest-auc:0.87227\n",
      "[2130]\ttrain-auc:0.88038\ttest-auc:0.87230\n",
      "[2140]\ttrain-auc:0.88043\ttest-auc:0.87232\n",
      "[2150]\ttrain-auc:0.88049\ttest-auc:0.87238\n",
      "[2160]\ttrain-auc:0.88054\ttest-auc:0.87238\n",
      "[2170]\ttrain-auc:0.88060\ttest-auc:0.87242\n",
      "[2180]\ttrain-auc:0.88070\ttest-auc:0.87249\n",
      "[2190]\ttrain-auc:0.88077\ttest-auc:0.87254\n",
      "[2200]\ttrain-auc:0.88083\ttest-auc:0.87254\n",
      "[2210]\ttrain-auc:0.88092\ttest-auc:0.87262\n",
      "[2220]\ttrain-auc:0.88096\ttest-auc:0.87265\n",
      "[2230]\ttrain-auc:0.88102\ttest-auc:0.87269\n",
      "[2240]\ttrain-auc:0.88108\ttest-auc:0.87272\n",
      "[2250]\ttrain-auc:0.88115\ttest-auc:0.87274\n",
      "[2260]\ttrain-auc:0.88125\ttest-auc:0.87283\n",
      "[2270]\ttrain-auc:0.88130\ttest-auc:0.87287\n",
      "[2280]\ttrain-auc:0.88138\ttest-auc:0.87293\n",
      "[2290]\ttrain-auc:0.88143\ttest-auc:0.87296\n",
      "[2300]\ttrain-auc:0.88147\ttest-auc:0.87299\n",
      "[2310]\ttrain-auc:0.88152\ttest-auc:0.87302\n",
      "[2320]\ttrain-auc:0.88156\ttest-auc:0.87304\n",
      "[2330]\ttrain-auc:0.88161\ttest-auc:0.87304\n",
      "[2340]\ttrain-auc:0.88167\ttest-auc:0.87309\n",
      "[2350]\ttrain-auc:0.88177\ttest-auc:0.87316\n",
      "[2360]\ttrain-auc:0.88182\ttest-auc:0.87320\n",
      "[2370]\ttrain-auc:0.88187\ttest-auc:0.87324\n",
      "[2380]\ttrain-auc:0.88193\ttest-auc:0.87328\n",
      "[2390]\ttrain-auc:0.88199\ttest-auc:0.87331\n",
      "[2400]\ttrain-auc:0.88206\ttest-auc:0.87338\n",
      "[2410]\ttrain-auc:0.88213\ttest-auc:0.87343\n",
      "[2420]\ttrain-auc:0.88218\ttest-auc:0.87345\n",
      "[2430]\ttrain-auc:0.88224\ttest-auc:0.87349\n",
      "[2440]\ttrain-auc:0.88230\ttest-auc:0.87352\n",
      "[2450]\ttrain-auc:0.88236\ttest-auc:0.87357\n",
      "[2460]\ttrain-auc:0.88240\ttest-auc:0.87360\n",
      "[2470]\ttrain-auc:0.88246\ttest-auc:0.87363\n",
      "[2480]\ttrain-auc:0.88251\ttest-auc:0.87367\n",
      "[2490]\ttrain-auc:0.88257\ttest-auc:0.87369\n",
      "[2500]\ttrain-auc:0.88263\ttest-auc:0.87371\n",
      "[2510]\ttrain-auc:0.88268\ttest-auc:0.87374\n",
      "[2520]\ttrain-auc:0.88274\ttest-auc:0.87377\n",
      "[2530]\ttrain-auc:0.88281\ttest-auc:0.87382\n",
      "[2540]\ttrain-auc:0.88288\ttest-auc:0.87385\n",
      "[2550]\ttrain-auc:0.88292\ttest-auc:0.87389\n",
      "[2560]\ttrain-auc:0.88298\ttest-auc:0.87393\n",
      "[2570]\ttrain-auc:0.88302\ttest-auc:0.87396\n",
      "[2580]\ttrain-auc:0.88307\ttest-auc:0.87400\n",
      "[2590]\ttrain-auc:0.88314\ttest-auc:0.87405\n",
      "[2600]\ttrain-auc:0.88318\ttest-auc:0.87407\n",
      "[2610]\ttrain-auc:0.88323\ttest-auc:0.87410\n",
      "[2620]\ttrain-auc:0.88329\ttest-auc:0.87414\n",
      "[2630]\ttrain-auc:0.88335\ttest-auc:0.87419\n",
      "[2640]\ttrain-auc:0.88339\ttest-auc:0.87420\n",
      "[2650]\ttrain-auc:0.88343\ttest-auc:0.87423\n",
      "[2660]\ttrain-auc:0.88350\ttest-auc:0.87428\n",
      "[2670]\ttrain-auc:0.88355\ttest-auc:0.87432\n",
      "[2680]\ttrain-auc:0.88359\ttest-auc:0.87434\n",
      "[2690]\ttrain-auc:0.88364\ttest-auc:0.87436\n",
      "[2700]\ttrain-auc:0.88368\ttest-auc:0.87439\n",
      "[2710]\ttrain-auc:0.88374\ttest-auc:0.87443\n",
      "[2720]\ttrain-auc:0.88380\ttest-auc:0.87445\n",
      "[2730]\ttrain-auc:0.88384\ttest-auc:0.87448\n",
      "[2740]\ttrain-auc:0.88392\ttest-auc:0.87456\n",
      "[2750]\ttrain-auc:0.88397\ttest-auc:0.87458\n",
      "[2760]\ttrain-auc:0.88402\ttest-auc:0.87461\n",
      "[2770]\ttrain-auc:0.88408\ttest-auc:0.87463\n",
      "[2780]\ttrain-auc:0.88411\ttest-auc:0.87466\n",
      "[2790]\ttrain-auc:0.88415\ttest-auc:0.87469\n",
      "[2800]\ttrain-auc:0.88420\ttest-auc:0.87474\n",
      "[2810]\ttrain-auc:0.88425\ttest-auc:0.87477\n",
      "[2820]\ttrain-auc:0.88429\ttest-auc:0.87479\n",
      "[2830]\ttrain-auc:0.88434\ttest-auc:0.87482\n",
      "[2840]\ttrain-auc:0.88439\ttest-auc:0.87484\n",
      "[2850]\ttrain-auc:0.88444\ttest-auc:0.87485\n",
      "[2860]\ttrain-auc:0.88450\ttest-auc:0.87489\n",
      "[2870]\ttrain-auc:0.88453\ttest-auc:0.87491\n",
      "[2880]\ttrain-auc:0.88459\ttest-auc:0.87494\n",
      "[2890]\ttrain-auc:0.88463\ttest-auc:0.87498\n",
      "[2900]\ttrain-auc:0.88467\ttest-auc:0.87499\n",
      "[2910]\ttrain-auc:0.88474\ttest-auc:0.87501\n",
      "[2920]\ttrain-auc:0.88478\ttest-auc:0.87505\n",
      "[2930]\ttrain-auc:0.88484\ttest-auc:0.87509\n",
      "[2940]\ttrain-auc:0.88489\ttest-auc:0.87511\n",
      "[2950]\ttrain-auc:0.88494\ttest-auc:0.87514\n",
      "[2960]\ttrain-auc:0.88497\ttest-auc:0.87518\n",
      "[2970]\ttrain-auc:0.88504\ttest-auc:0.87523\n",
      "[2980]\ttrain-auc:0.88509\ttest-auc:0.87526\n",
      "[2990]\ttrain-auc:0.88514\ttest-auc:0.87530\n",
      "[3000]\ttrain-auc:0.88518\ttest-auc:0.87533\n",
      "[3010]\ttrain-auc:0.88524\ttest-auc:0.87535\n",
      "[3020]\ttrain-auc:0.88528\ttest-auc:0.87538\n",
      "[3030]\ttrain-auc:0.88532\ttest-auc:0.87540\n",
      "[3040]\ttrain-auc:0.88535\ttest-auc:0.87543\n",
      "[3050]\ttrain-auc:0.88539\ttest-auc:0.87544\n",
      "[3060]\ttrain-auc:0.88544\ttest-auc:0.87547\n",
      "[3070]\ttrain-auc:0.88549\ttest-auc:0.87551\n",
      "[3080]\ttrain-auc:0.88553\ttest-auc:0.87554\n",
      "[3090]\ttrain-auc:0.88557\ttest-auc:0.87556\n",
      "[3100]\ttrain-auc:0.88560\ttest-auc:0.87556\n",
      "[3110]\ttrain-auc:0.88565\ttest-auc:0.87557\n",
      "[3120]\ttrain-auc:0.88569\ttest-auc:0.87559\n",
      "[3130]\ttrain-auc:0.88573\ttest-auc:0.87560\n",
      "[3140]\ttrain-auc:0.88577\ttest-auc:0.87564\n",
      "[3150]\ttrain-auc:0.88581\ttest-auc:0.87567\n",
      "[3160]\ttrain-auc:0.88586\ttest-auc:0.87570\n",
      "[3170]\ttrain-auc:0.88591\ttest-auc:0.87574\n",
      "[3180]\ttrain-auc:0.88596\ttest-auc:0.87577\n",
      "[3190]\ttrain-auc:0.88599\ttest-auc:0.87578\n",
      "[3200]\ttrain-auc:0.88602\ttest-auc:0.87581\n",
      "[3210]\ttrain-auc:0.88606\ttest-auc:0.87584\n",
      "[3220]\ttrain-auc:0.88609\ttest-auc:0.87585\n",
      "[3230]\ttrain-auc:0.88615\ttest-auc:0.87589\n",
      "[3240]\ttrain-auc:0.88620\ttest-auc:0.87591\n",
      "[3250]\ttrain-auc:0.88623\ttest-auc:0.87592\n",
      "[3260]\ttrain-auc:0.88630\ttest-auc:0.87598\n",
      "[3270]\ttrain-auc:0.88633\ttest-auc:0.87600\n",
      "[3280]\ttrain-auc:0.88640\ttest-auc:0.87603\n",
      "[3290]\ttrain-auc:0.88644\ttest-auc:0.87605\n",
      "[3300]\ttrain-auc:0.88649\ttest-auc:0.87607\n",
      "[3310]\ttrain-auc:0.88653\ttest-auc:0.87611\n",
      "[3320]\ttrain-auc:0.88658\ttest-auc:0.87613\n",
      "[3330]\ttrain-auc:0.88661\ttest-auc:0.87615\n",
      "[3340]\ttrain-auc:0.88664\ttest-auc:0.87617\n",
      "[3350]\ttrain-auc:0.88667\ttest-auc:0.87618\n",
      "[3360]\ttrain-auc:0.88672\ttest-auc:0.87621\n",
      "[3370]\ttrain-auc:0.88677\ttest-auc:0.87624\n",
      "[3380]\ttrain-auc:0.88680\ttest-auc:0.87626\n",
      "[3390]\ttrain-auc:0.88686\ttest-auc:0.87630\n",
      "[3400]\ttrain-auc:0.88689\ttest-auc:0.87631\n",
      "[3410]\ttrain-auc:0.88694\ttest-auc:0.87633\n",
      "[3420]\ttrain-auc:0.88698\ttest-auc:0.87636\n",
      "[3430]\ttrain-auc:0.88702\ttest-auc:0.87637\n",
      "[3440]\ttrain-auc:0.88705\ttest-auc:0.87643\n",
      "[3450]\ttrain-auc:0.88709\ttest-auc:0.87645\n",
      "[3460]\ttrain-auc:0.88714\ttest-auc:0.87646\n",
      "[3470]\ttrain-auc:0.88717\ttest-auc:0.87648\n",
      "[3480]\ttrain-auc:0.88720\ttest-auc:0.87650\n",
      "[3490]\ttrain-auc:0.88724\ttest-auc:0.87652\n",
      "[3500]\ttrain-auc:0.88728\ttest-auc:0.87655\n",
      "[3510]\ttrain-auc:0.88732\ttest-auc:0.87657\n",
      "[3520]\ttrain-auc:0.88737\ttest-auc:0.87658\n",
      "[3530]\ttrain-auc:0.88740\ttest-auc:0.87660\n",
      "[3540]\ttrain-auc:0.88743\ttest-auc:0.87662\n",
      "[3550]\ttrain-auc:0.88747\ttest-auc:0.87664\n",
      "[3560]\ttrain-auc:0.88751\ttest-auc:0.87666\n",
      "[3570]\ttrain-auc:0.88755\ttest-auc:0.87669\n",
      "[3580]\ttrain-auc:0.88758\ttest-auc:0.87670\n",
      "[3590]\ttrain-auc:0.88762\ttest-auc:0.87672\n",
      "[3600]\ttrain-auc:0.88767\ttest-auc:0.87676\n",
      "[3610]\ttrain-auc:0.88771\ttest-auc:0.87679\n",
      "[3620]\ttrain-auc:0.88774\ttest-auc:0.87682\n",
      "[3630]\ttrain-auc:0.88777\ttest-auc:0.87684\n",
      "[3640]\ttrain-auc:0.88782\ttest-auc:0.87685\n",
      "[3650]\ttrain-auc:0.88785\ttest-auc:0.87687\n",
      "[3660]\ttrain-auc:0.88788\ttest-auc:0.87690\n",
      "[3670]\ttrain-auc:0.88793\ttest-auc:0.87692\n",
      "[3680]\ttrain-auc:0.88796\ttest-auc:0.87692\n",
      "[3690]\ttrain-auc:0.88800\ttest-auc:0.87695\n",
      "[3700]\ttrain-auc:0.88804\ttest-auc:0.87697\n",
      "[3710]\ttrain-auc:0.88807\ttest-auc:0.87699\n",
      "[3720]\ttrain-auc:0.88812\ttest-auc:0.87704\n",
      "[3730]\ttrain-auc:0.88815\ttest-auc:0.87706\n",
      "[3740]\ttrain-auc:0.88819\ttest-auc:0.87708\n",
      "[3750]\ttrain-auc:0.88824\ttest-auc:0.87712\n",
      "[3760]\ttrain-auc:0.88828\ttest-auc:0.87716\n",
      "[3770]\ttrain-auc:0.88832\ttest-auc:0.87719\n",
      "[3780]\ttrain-auc:0.88835\ttest-auc:0.87721\n",
      "[3790]\ttrain-auc:0.88838\ttest-auc:0.87723\n",
      "[3800]\ttrain-auc:0.88842\ttest-auc:0.87725\n",
      "[3810]\ttrain-auc:0.88846\ttest-auc:0.87729\n",
      "[3820]\ttrain-auc:0.88850\ttest-auc:0.87729\n",
      "[3830]\ttrain-auc:0.88854\ttest-auc:0.87731\n",
      "[3840]\ttrain-auc:0.88859\ttest-auc:0.87735\n",
      "[3850]\ttrain-auc:0.88863\ttest-auc:0.87738\n",
      "[3860]\ttrain-auc:0.88865\ttest-auc:0.87739\n",
      "[3870]\ttrain-auc:0.88869\ttest-auc:0.87741\n",
      "[3880]\ttrain-auc:0.88873\ttest-auc:0.87743\n",
      "[3890]\ttrain-auc:0.88877\ttest-auc:0.87746\n",
      "[3900]\ttrain-auc:0.88880\ttest-auc:0.87750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3910]\ttrain-auc:0.88883\ttest-auc:0.87752\n",
      "[3920]\ttrain-auc:0.88889\ttest-auc:0.87756\n",
      "[3930]\ttrain-auc:0.88893\ttest-auc:0.87758\n",
      "[3940]\ttrain-auc:0.88896\ttest-auc:0.87759\n",
      "[3950]\ttrain-auc:0.88900\ttest-auc:0.87761\n",
      "[3960]\ttrain-auc:0.88904\ttest-auc:0.87764\n",
      "[3970]\ttrain-auc:0.88908\ttest-auc:0.87766\n",
      "[3980]\ttrain-auc:0.88911\ttest-auc:0.87768\n",
      "[3990]\ttrain-auc:0.88915\ttest-auc:0.87770\n",
      "[4000]\ttrain-auc:0.88917\ttest-auc:0.87772\n",
      "[4010]\ttrain-auc:0.88921\ttest-auc:0.87772\n",
      "[4020]\ttrain-auc:0.88924\ttest-auc:0.87774\n",
      "[4030]\ttrain-auc:0.88928\ttest-auc:0.87775\n",
      "[4040]\ttrain-auc:0.88931\ttest-auc:0.87777\n",
      "[4050]\ttrain-auc:0.88938\ttest-auc:0.87784\n",
      "[4060]\ttrain-auc:0.88942\ttest-auc:0.87788\n",
      "[4070]\ttrain-auc:0.88946\ttest-auc:0.87791\n",
      "[4080]\ttrain-auc:0.88950\ttest-auc:0.87793\n",
      "[4090]\ttrain-auc:0.88953\ttest-auc:0.87796\n",
      "[4100]\ttrain-auc:0.88957\ttest-auc:0.87799\n",
      "[4110]\ttrain-auc:0.88961\ttest-auc:0.87800\n",
      "[4120]\ttrain-auc:0.88964\ttest-auc:0.87801\n",
      "[4130]\ttrain-auc:0.88968\ttest-auc:0.87802\n",
      "[4140]\ttrain-auc:0.88972\ttest-auc:0.87803\n",
      "[4150]\ttrain-auc:0.88976\ttest-auc:0.87804\n",
      "[4160]\ttrain-auc:0.88979\ttest-auc:0.87805\n",
      "[4170]\ttrain-auc:0.88982\ttest-auc:0.87807\n",
      "[4180]\ttrain-auc:0.88985\ttest-auc:0.87808\n",
      "[4190]\ttrain-auc:0.88989\ttest-auc:0.87809\n",
      "[4200]\ttrain-auc:0.88991\ttest-auc:0.87811\n",
      "[4210]\ttrain-auc:0.88995\ttest-auc:0.87813\n",
      "[4220]\ttrain-auc:0.88999\ttest-auc:0.87814\n",
      "[4230]\ttrain-auc:0.89002\ttest-auc:0.87817\n",
      "[4240]\ttrain-auc:0.89005\ttest-auc:0.87818\n",
      "[4250]\ttrain-auc:0.89008\ttest-auc:0.87820\n",
      "[4260]\ttrain-auc:0.89015\ttest-auc:0.87827\n",
      "[4270]\ttrain-auc:0.89018\ttest-auc:0.87828\n",
      "[4280]\ttrain-auc:0.89023\ttest-auc:0.87832\n",
      "[4290]\ttrain-auc:0.89027\ttest-auc:0.87835\n",
      "[4300]\ttrain-auc:0.89031\ttest-auc:0.87838\n",
      "[4310]\ttrain-auc:0.89033\ttest-auc:0.87840\n",
      "[4320]\ttrain-auc:0.89037\ttest-auc:0.87841\n",
      "[4330]\ttrain-auc:0.89040\ttest-auc:0.87841\n",
      "[4340]\ttrain-auc:0.89044\ttest-auc:0.87843\n",
      "[4350]\ttrain-auc:0.89047\ttest-auc:0.87844\n",
      "[4360]\ttrain-auc:0.89050\ttest-auc:0.87845\n",
      "[4370]\ttrain-auc:0.89052\ttest-auc:0.87848\n",
      "[4380]\ttrain-auc:0.89055\ttest-auc:0.87848\n",
      "[4390]\ttrain-auc:0.89058\ttest-auc:0.87850\n",
      "[4400]\ttrain-auc:0.89062\ttest-auc:0.87853\n",
      "[4410]\ttrain-auc:0.89065\ttest-auc:0.87854\n",
      "[4420]\ttrain-auc:0.89068\ttest-auc:0.87857\n",
      "[4430]\ttrain-auc:0.89072\ttest-auc:0.87858\n",
      "[4440]\ttrain-auc:0.89075\ttest-auc:0.87860\n",
      "[4450]\ttrain-auc:0.89079\ttest-auc:0.87863\n",
      "[4460]\ttrain-auc:0.89084\ttest-auc:0.87867\n",
      "[4470]\ttrain-auc:0.89087\ttest-auc:0.87867\n",
      "[4480]\ttrain-auc:0.89091\ttest-auc:0.87871\n",
      "[4490]\ttrain-auc:0.89095\ttest-auc:0.87874\n",
      "[4500]\ttrain-auc:0.89098\ttest-auc:0.87875\n",
      "[4510]\ttrain-auc:0.89101\ttest-auc:0.87878\n",
      "[4520]\ttrain-auc:0.89104\ttest-auc:0.87879\n",
      "[4530]\ttrain-auc:0.89108\ttest-auc:0.87881\n",
      "[4540]\ttrain-auc:0.89113\ttest-auc:0.87882\n",
      "[4550]\ttrain-auc:0.89117\ttest-auc:0.87886\n",
      "[4560]\ttrain-auc:0.89120\ttest-auc:0.87887\n",
      "[4570]\ttrain-auc:0.89124\ttest-auc:0.87889\n",
      "[4580]\ttrain-auc:0.89129\ttest-auc:0.87891\n",
      "[4590]\ttrain-auc:0.89133\ttest-auc:0.87893\n",
      "[4600]\ttrain-auc:0.89136\ttest-auc:0.87894\n",
      "[4610]\ttrain-auc:0.89139\ttest-auc:0.87896\n",
      "[4620]\ttrain-auc:0.89143\ttest-auc:0.87898\n",
      "[4630]\ttrain-auc:0.89146\ttest-auc:0.87900\n",
      "[4640]\ttrain-auc:0.89150\ttest-auc:0.87902\n",
      "[4650]\ttrain-auc:0.89153\ttest-auc:0.87902\n",
      "[4660]\ttrain-auc:0.89157\ttest-auc:0.87906\n",
      "[4670]\ttrain-auc:0.89160\ttest-auc:0.87908\n",
      "[4680]\ttrain-auc:0.89163\ttest-auc:0.87910\n",
      "[4690]\ttrain-auc:0.89166\ttest-auc:0.87911\n",
      "[4700]\ttrain-auc:0.89169\ttest-auc:0.87914\n",
      "[4710]\ttrain-auc:0.89172\ttest-auc:0.87915\n",
      "[4720]\ttrain-auc:0.89175\ttest-auc:0.87917\n",
      "[4730]\ttrain-auc:0.89178\ttest-auc:0.87918\n",
      "[4740]\ttrain-auc:0.89181\ttest-auc:0.87920\n",
      "[4750]\ttrain-auc:0.89183\ttest-auc:0.87921\n",
      "[4760]\ttrain-auc:0.89186\ttest-auc:0.87922\n",
      "[4770]\ttrain-auc:0.89189\ttest-auc:0.87925\n",
      "[4780]\ttrain-auc:0.89192\ttest-auc:0.87926\n",
      "[4790]\ttrain-auc:0.89194\ttest-auc:0.87927\n",
      "[4800]\ttrain-auc:0.89198\ttest-auc:0.87928\n",
      "[4810]\ttrain-auc:0.89201\ttest-auc:0.87929\n",
      "[4820]\ttrain-auc:0.89204\ttest-auc:0.87931\n",
      "[4830]\ttrain-auc:0.89207\ttest-auc:0.87932\n",
      "[4840]\ttrain-auc:0.89213\ttest-auc:0.87938\n",
      "[4850]\ttrain-auc:0.89215\ttest-auc:0.87938\n",
      "[4860]\ttrain-auc:0.89219\ttest-auc:0.87939\n",
      "[4870]\ttrain-auc:0.89221\ttest-auc:0.87940\n",
      "[4880]\ttrain-auc:0.89224\ttest-auc:0.87941\n",
      "[4890]\ttrain-auc:0.89226\ttest-auc:0.87942\n",
      "[4900]\ttrain-auc:0.89229\ttest-auc:0.87942\n",
      "[4910]\ttrain-auc:0.89231\ttest-auc:0.87944\n",
      "[4920]\ttrain-auc:0.89234\ttest-auc:0.87945\n",
      "[4930]\ttrain-auc:0.89238\ttest-auc:0.87946\n",
      "[4940]\ttrain-auc:0.89240\ttest-auc:0.87947\n",
      "[4950]\ttrain-auc:0.89244\ttest-auc:0.87948\n",
      "[4960]\ttrain-auc:0.89247\ttest-auc:0.87951\n",
      "[4970]\ttrain-auc:0.89251\ttest-auc:0.87955\n",
      "[4980]\ttrain-auc:0.89254\ttest-auc:0.87956\n",
      "[4990]\ttrain-auc:0.89258\ttest-auc:0.87957\n",
      "[5000]\ttrain-auc:0.89261\ttest-auc:0.87959\n",
      "[5010]\ttrain-auc:0.89264\ttest-auc:0.87961\n",
      "[5020]\ttrain-auc:0.89267\ttest-auc:0.87964\n",
      "[5030]\ttrain-auc:0.89272\ttest-auc:0.87967\n",
      "[5040]\ttrain-auc:0.89275\ttest-auc:0.87968\n",
      "[5050]\ttrain-auc:0.89278\ttest-auc:0.87969\n",
      "[5060]\ttrain-auc:0.89281\ttest-auc:0.87971\n",
      "[5070]\ttrain-auc:0.89284\ttest-auc:0.87971\n",
      "[5080]\ttrain-auc:0.89288\ttest-auc:0.87973\n",
      "[5090]\ttrain-auc:0.89291\ttest-auc:0.87973\n",
      "[5100]\ttrain-auc:0.89294\ttest-auc:0.87976\n",
      "[5110]\ttrain-auc:0.89300\ttest-auc:0.87982\n",
      "[5120]\ttrain-auc:0.89304\ttest-auc:0.87985\n",
      "[5130]\ttrain-auc:0.89308\ttest-auc:0.87986\n",
      "[5140]\ttrain-auc:0.89310\ttest-auc:0.87987\n",
      "[5150]\ttrain-auc:0.89313\ttest-auc:0.87988\n",
      "[5160]\ttrain-auc:0.89316\ttest-auc:0.87989\n",
      "[5170]\ttrain-auc:0.89319\ttest-auc:0.87989\n",
      "[5180]\ttrain-auc:0.89322\ttest-auc:0.87992\n",
      "[5190]\ttrain-auc:0.89326\ttest-auc:0.87992\n",
      "[5200]\ttrain-auc:0.89328\ttest-auc:0.87993\n",
      "[5210]\ttrain-auc:0.89331\ttest-auc:0.87993\n",
      "[5220]\ttrain-auc:0.89333\ttest-auc:0.87996\n",
      "[5230]\ttrain-auc:0.89337\ttest-auc:0.87999\n",
      "[5240]\ttrain-auc:0.89340\ttest-auc:0.88000\n",
      "[5250]\ttrain-auc:0.89344\ttest-auc:0.88003\n",
      "[5260]\ttrain-auc:0.89348\ttest-auc:0.88006\n",
      "[5270]\ttrain-auc:0.89351\ttest-auc:0.88007\n",
      "[5280]\ttrain-auc:0.89355\ttest-auc:0.88008\n",
      "[5290]\ttrain-auc:0.89357\ttest-auc:0.88009\n",
      "[5300]\ttrain-auc:0.89360\ttest-auc:0.88011\n",
      "[5310]\ttrain-auc:0.89362\ttest-auc:0.88011\n",
      "[5320]\ttrain-auc:0.89365\ttest-auc:0.88014\n",
      "[5330]\ttrain-auc:0.89367\ttest-auc:0.88014\n",
      "[5340]\ttrain-auc:0.89370\ttest-auc:0.88016\n",
      "[5350]\ttrain-auc:0.89372\ttest-auc:0.88017\n",
      "[5360]\ttrain-auc:0.89375\ttest-auc:0.88020\n",
      "[5370]\ttrain-auc:0.89377\ttest-auc:0.88021\n",
      "[5380]\ttrain-auc:0.89380\ttest-auc:0.88022\n",
      "[5390]\ttrain-auc:0.89383\ttest-auc:0.88023\n",
      "[5400]\ttrain-auc:0.89385\ttest-auc:0.88023\n",
      "[5410]\ttrain-auc:0.89388\ttest-auc:0.88025\n",
      "[5420]\ttrain-auc:0.89391\ttest-auc:0.88027\n",
      "[5430]\ttrain-auc:0.89394\ttest-auc:0.88028\n",
      "[5440]\ttrain-auc:0.89397\ttest-auc:0.88029\n",
      "[5450]\ttrain-auc:0.89399\ttest-auc:0.88031\n",
      "[5460]\ttrain-auc:0.89402\ttest-auc:0.88032\n",
      "[5470]\ttrain-auc:0.89404\ttest-auc:0.88034\n",
      "[5480]\ttrain-auc:0.89407\ttest-auc:0.88036\n",
      "[5490]\ttrain-auc:0.89410\ttest-auc:0.88038\n",
      "[5500]\ttrain-auc:0.89413\ttest-auc:0.88039\n",
      "[5510]\ttrain-auc:0.89415\ttest-auc:0.88040\n",
      "[5520]\ttrain-auc:0.89418\ttest-auc:0.88043\n",
      "[5530]\ttrain-auc:0.89421\ttest-auc:0.88045\n",
      "[5540]\ttrain-auc:0.89425\ttest-auc:0.88046\n",
      "[5550]\ttrain-auc:0.89429\ttest-auc:0.88050\n",
      "[5560]\ttrain-auc:0.89432\ttest-auc:0.88051\n",
      "[5570]\ttrain-auc:0.89435\ttest-auc:0.88053\n",
      "[5580]\ttrain-auc:0.89437\ttest-auc:0.88053\n",
      "[5590]\ttrain-auc:0.89441\ttest-auc:0.88055\n",
      "[5600]\ttrain-auc:0.89444\ttest-auc:0.88056\n",
      "[5610]\ttrain-auc:0.89446\ttest-auc:0.88056\n",
      "[5620]\ttrain-auc:0.89449\ttest-auc:0.88057\n",
      "[5630]\ttrain-auc:0.89452\ttest-auc:0.88062\n",
      "[5640]\ttrain-auc:0.89455\ttest-auc:0.88063\n",
      "[5650]\ttrain-auc:0.89458\ttest-auc:0.88063\n",
      "[5660]\ttrain-auc:0.89461\ttest-auc:0.88066\n",
      "[5670]\ttrain-auc:0.89464\ttest-auc:0.88067\n",
      "[5680]\ttrain-auc:0.89466\ttest-auc:0.88069\n",
      "[5690]\ttrain-auc:0.89469\ttest-auc:0.88071\n",
      "[5700]\ttrain-auc:0.89471\ttest-auc:0.88072\n",
      "[5710]\ttrain-auc:0.89474\ttest-auc:0.88074\n",
      "[5720]\ttrain-auc:0.89477\ttest-auc:0.88074\n",
      "[5730]\ttrain-auc:0.89479\ttest-auc:0.88076\n",
      "[5740]\ttrain-auc:0.89482\ttest-auc:0.88078\n",
      "[5750]\ttrain-auc:0.89485\ttest-auc:0.88079\n",
      "[5760]\ttrain-auc:0.89489\ttest-auc:0.88083\n",
      "[5770]\ttrain-auc:0.89492\ttest-auc:0.88084\n",
      "[5780]\ttrain-auc:0.89495\ttest-auc:0.88087\n",
      "[5790]\ttrain-auc:0.89498\ttest-auc:0.88088\n",
      "[5800]\ttrain-auc:0.89501\ttest-auc:0.88090\n",
      "[5810]\ttrain-auc:0.89505\ttest-auc:0.88092\n",
      "[5820]\ttrain-auc:0.89507\ttest-auc:0.88094\n",
      "[5830]\ttrain-auc:0.89510\ttest-auc:0.88094\n",
      "[5840]\ttrain-auc:0.89513\ttest-auc:0.88096\n",
      "[5850]\ttrain-auc:0.89515\ttest-auc:0.88098\n",
      "[5860]\ttrain-auc:0.89519\ttest-auc:0.88099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5870]\ttrain-auc:0.89522\ttest-auc:0.88101\n",
      "[5880]\ttrain-auc:0.89525\ttest-auc:0.88101\n",
      "[5890]\ttrain-auc:0.89528\ttest-auc:0.88103\n",
      "[5900]\ttrain-auc:0.89530\ttest-auc:0.88104\n",
      "[5910]\ttrain-auc:0.89533\ttest-auc:0.88105\n",
      "[5920]\ttrain-auc:0.89536\ttest-auc:0.88106\n",
      "[5930]\ttrain-auc:0.89538\ttest-auc:0.88107\n",
      "[5940]\ttrain-auc:0.89540\ttest-auc:0.88107\n",
      "[5950]\ttrain-auc:0.89542\ttest-auc:0.88109\n",
      "[5960]\ttrain-auc:0.89545\ttest-auc:0.88110\n",
      "[5970]\ttrain-auc:0.89548\ttest-auc:0.88112\n",
      "[5980]\ttrain-auc:0.89550\ttest-auc:0.88114\n",
      "[5990]\ttrain-auc:0.89553\ttest-auc:0.88115\n",
      "[6000]\ttrain-auc:0.89557\ttest-auc:0.88117\n",
      "[6010]\ttrain-auc:0.89559\ttest-auc:0.88117\n",
      "[6020]\ttrain-auc:0.89562\ttest-auc:0.88119\n",
      "[6030]\ttrain-auc:0.89564\ttest-auc:0.88121\n",
      "[6040]\ttrain-auc:0.89567\ttest-auc:0.88122\n",
      "[6050]\ttrain-auc:0.89569\ttest-auc:0.88122\n",
      "[6060]\ttrain-auc:0.89572\ttest-auc:0.88123\n",
      "[6070]\ttrain-auc:0.89574\ttest-auc:0.88124\n",
      "[6080]\ttrain-auc:0.89578\ttest-auc:0.88128\n",
      "[6090]\ttrain-auc:0.89580\ttest-auc:0.88129\n",
      "[6100]\ttrain-auc:0.89583\ttest-auc:0.88130\n",
      "[6110]\ttrain-auc:0.89586\ttest-auc:0.88131\n",
      "[6120]\ttrain-auc:0.89588\ttest-auc:0.88132\n",
      "[6130]\ttrain-auc:0.89590\ttest-auc:0.88135\n",
      "[6140]\ttrain-auc:0.89594\ttest-auc:0.88137\n",
      "[6150]\ttrain-auc:0.89597\ttest-auc:0.88138\n",
      "[6160]\ttrain-auc:0.89599\ttest-auc:0.88138\n",
      "[6170]\ttrain-auc:0.89601\ttest-auc:0.88139\n",
      "[6180]\ttrain-auc:0.89603\ttest-auc:0.88141\n",
      "[6190]\ttrain-auc:0.89606\ttest-auc:0.88143\n",
      "[6200]\ttrain-auc:0.89610\ttest-auc:0.88145\n",
      "[6210]\ttrain-auc:0.89612\ttest-auc:0.88146\n",
      "[6220]\ttrain-auc:0.89614\ttest-auc:0.88147\n",
      "[6230]\ttrain-auc:0.89616\ttest-auc:0.88147\n",
      "[6240]\ttrain-auc:0.89619\ttest-auc:0.88147\n",
      "[6250]\ttrain-auc:0.89623\ttest-auc:0.88149\n",
      "[6260]\ttrain-auc:0.89625\ttest-auc:0.88150\n",
      "[6270]\ttrain-auc:0.89627\ttest-auc:0.88150\n",
      "[6280]\ttrain-auc:0.89629\ttest-auc:0.88152\n",
      "[6290]\ttrain-auc:0.89632\ttest-auc:0.88154\n",
      "[6300]\ttrain-auc:0.89635\ttest-auc:0.88156\n",
      "[6310]\ttrain-auc:0.89638\ttest-auc:0.88159\n",
      "[6320]\ttrain-auc:0.89640\ttest-auc:0.88159\n",
      "[6330]\ttrain-auc:0.89642\ttest-auc:0.88161\n",
      "[6340]\ttrain-auc:0.89646\ttest-auc:0.88163\n",
      "[6350]\ttrain-auc:0.89648\ttest-auc:0.88164\n",
      "[6360]\ttrain-auc:0.89651\ttest-auc:0.88166\n",
      "[6370]\ttrain-auc:0.89653\ttest-auc:0.88166\n",
      "[6380]\ttrain-auc:0.89655\ttest-auc:0.88167\n",
      "[6390]\ttrain-auc:0.89658\ttest-auc:0.88170\n",
      "[6400]\ttrain-auc:0.89660\ttest-auc:0.88171\n",
      "[6410]\ttrain-auc:0.89661\ttest-auc:0.88171\n",
      "[6420]\ttrain-auc:0.89664\ttest-auc:0.88172\n",
      "[6430]\ttrain-auc:0.89667\ttest-auc:0.88173\n",
      "[6440]\ttrain-auc:0.89668\ttest-auc:0.88173\n",
      "[6450]\ttrain-auc:0.89672\ttest-auc:0.88175\n",
      "[6460]\ttrain-auc:0.89673\ttest-auc:0.88176\n",
      "[6470]\ttrain-auc:0.89676\ttest-auc:0.88178\n",
      "[6480]\ttrain-auc:0.89678\ttest-auc:0.88180\n",
      "[6490]\ttrain-auc:0.89681\ttest-auc:0.88181\n",
      "[6500]\ttrain-auc:0.89685\ttest-auc:0.88184\n",
      "[6510]\ttrain-auc:0.89687\ttest-auc:0.88184\n",
      "[6520]\ttrain-auc:0.89689\ttest-auc:0.88185\n",
      "[6530]\ttrain-auc:0.89693\ttest-auc:0.88186\n",
      "[6540]\ttrain-auc:0.89695\ttest-auc:0.88187\n",
      "[6550]\ttrain-auc:0.89697\ttest-auc:0.88188\n",
      "[6560]\ttrain-auc:0.89699\ttest-auc:0.88190\n",
      "[6570]\ttrain-auc:0.89701\ttest-auc:0.88191\n",
      "[6580]\ttrain-auc:0.89705\ttest-auc:0.88194\n",
      "[6590]\ttrain-auc:0.89710\ttest-auc:0.88199\n",
      "[6600]\ttrain-auc:0.89712\ttest-auc:0.88200\n",
      "[6610]\ttrain-auc:0.89714\ttest-auc:0.88200\n",
      "[6620]\ttrain-auc:0.89717\ttest-auc:0.88202\n",
      "[6630]\ttrain-auc:0.89719\ttest-auc:0.88203\n",
      "[6640]\ttrain-auc:0.89722\ttest-auc:0.88206\n",
      "[6650]\ttrain-auc:0.89724\ttest-auc:0.88207\n",
      "[6660]\ttrain-auc:0.89726\ttest-auc:0.88208\n",
      "[6670]\ttrain-auc:0.89728\ttest-auc:0.88209\n",
      "[6680]\ttrain-auc:0.89731\ttest-auc:0.88209\n",
      "[6690]\ttrain-auc:0.89733\ttest-auc:0.88210\n",
      "[6700]\ttrain-auc:0.89736\ttest-auc:0.88212\n",
      "[6710]\ttrain-auc:0.89739\ttest-auc:0.88213\n",
      "[6720]\ttrain-auc:0.89741\ttest-auc:0.88214\n",
      "[6730]\ttrain-auc:0.89743\ttest-auc:0.88214\n",
      "[6740]\ttrain-auc:0.89746\ttest-auc:0.88216\n",
      "[6750]\ttrain-auc:0.89749\ttest-auc:0.88219\n",
      "[6760]\ttrain-auc:0.89752\ttest-auc:0.88221\n",
      "[6770]\ttrain-auc:0.89755\ttest-auc:0.88222\n",
      "[6780]\ttrain-auc:0.89756\ttest-auc:0.88222\n",
      "[6790]\ttrain-auc:0.89760\ttest-auc:0.88223\n",
      "[6800]\ttrain-auc:0.89762\ttest-auc:0.88224\n",
      "[6810]\ttrain-auc:0.89764\ttest-auc:0.88225\n",
      "[6820]\ttrain-auc:0.89765\ttest-auc:0.88226\n",
      "[6830]\ttrain-auc:0.89767\ttest-auc:0.88227\n",
      "[6840]\ttrain-auc:0.89770\ttest-auc:0.88229\n",
      "[6850]\ttrain-auc:0.89773\ttest-auc:0.88231\n",
      "[6860]\ttrain-auc:0.89775\ttest-auc:0.88231\n",
      "[6870]\ttrain-auc:0.89778\ttest-auc:0.88234\n",
      "[6880]\ttrain-auc:0.89780\ttest-auc:0.88234\n",
      "[6890]\ttrain-auc:0.89784\ttest-auc:0.88237\n",
      "[6900]\ttrain-auc:0.89787\ttest-auc:0.88241\n",
      "[6910]\ttrain-auc:0.89789\ttest-auc:0.88243\n",
      "[6920]\ttrain-auc:0.89791\ttest-auc:0.88244\n",
      "[6930]\ttrain-auc:0.89794\ttest-auc:0.88246\n",
      "[6940]\ttrain-auc:0.89795\ttest-auc:0.88245\n",
      "[6950]\ttrain-auc:0.89798\ttest-auc:0.88247\n",
      "[6960]\ttrain-auc:0.89801\ttest-auc:0.88248\n",
      "[6970]\ttrain-auc:0.89803\ttest-auc:0.88249\n",
      "[6980]\ttrain-auc:0.89805\ttest-auc:0.88250\n",
      "[6990]\ttrain-auc:0.89808\ttest-auc:0.88251\n",
      "[7000]\ttrain-auc:0.89811\ttest-auc:0.88252\n",
      "[7010]\ttrain-auc:0.89814\ttest-auc:0.88252\n",
      "[7020]\ttrain-auc:0.89816\ttest-auc:0.88253\n",
      "[7030]\ttrain-auc:0.89818\ttest-auc:0.88255\n",
      "[7040]\ttrain-auc:0.89820\ttest-auc:0.88257\n",
      "[7050]\ttrain-auc:0.89822\ttest-auc:0.88256\n",
      "[7060]\ttrain-auc:0.89823\ttest-auc:0.88257\n",
      "[7070]\ttrain-auc:0.89827\ttest-auc:0.88259\n",
      "[7080]\ttrain-auc:0.89829\ttest-auc:0.88261\n",
      "[7090]\ttrain-auc:0.89831\ttest-auc:0.88262\n",
      "[7100]\ttrain-auc:0.89833\ttest-auc:0.88263\n",
      "[7110]\ttrain-auc:0.89835\ttest-auc:0.88263\n",
      "[7120]\ttrain-auc:0.89838\ttest-auc:0.88265\n",
      "[7130]\ttrain-auc:0.89840\ttest-auc:0.88267\n",
      "[7140]\ttrain-auc:0.89842\ttest-auc:0.88267\n",
      "[7150]\ttrain-auc:0.89844\ttest-auc:0.88268\n",
      "[7160]\ttrain-auc:0.89846\ttest-auc:0.88269\n",
      "[7170]\ttrain-auc:0.89848\ttest-auc:0.88270\n",
      "[7180]\ttrain-auc:0.89850\ttest-auc:0.88270\n",
      "[7190]\ttrain-auc:0.89854\ttest-auc:0.88273\n",
      "[7200]\ttrain-auc:0.89857\ttest-auc:0.88275\n",
      "[7210]\ttrain-auc:0.89859\ttest-auc:0.88276\n",
      "[7220]\ttrain-auc:0.89862\ttest-auc:0.88278\n",
      "[7230]\ttrain-auc:0.89865\ttest-auc:0.88279\n",
      "[7240]\ttrain-auc:0.89867\ttest-auc:0.88281\n",
      "[7250]\ttrain-auc:0.89869\ttest-auc:0.88281\n",
      "[7260]\ttrain-auc:0.89871\ttest-auc:0.88281\n",
      "[7270]\ttrain-auc:0.89873\ttest-auc:0.88282\n",
      "[7280]\ttrain-auc:0.89876\ttest-auc:0.88286\n",
      "[7290]\ttrain-auc:0.89879\ttest-auc:0.88288\n",
      "[7300]\ttrain-auc:0.89881\ttest-auc:0.88288\n",
      "[7310]\ttrain-auc:0.89884\ttest-auc:0.88291\n",
      "[7320]\ttrain-auc:0.89886\ttest-auc:0.88292\n",
      "[7330]\ttrain-auc:0.89889\ttest-auc:0.88295\n",
      "[7340]\ttrain-auc:0.89891\ttest-auc:0.88295\n",
      "[7350]\ttrain-auc:0.89893\ttest-auc:0.88296\n",
      "[7360]\ttrain-auc:0.89896\ttest-auc:0.88296\n",
      "[7370]\ttrain-auc:0.89898\ttest-auc:0.88298\n",
      "[7380]\ttrain-auc:0.89900\ttest-auc:0.88299\n",
      "[7390]\ttrain-auc:0.89902\ttest-auc:0.88300\n",
      "[7400]\ttrain-auc:0.89905\ttest-auc:0.88303\n",
      "[7410]\ttrain-auc:0.89908\ttest-auc:0.88305\n",
      "[7420]\ttrain-auc:0.89910\ttest-auc:0.88306\n",
      "[7430]\ttrain-auc:0.89912\ttest-auc:0.88306\n",
      "[7440]\ttrain-auc:0.89914\ttest-auc:0.88307\n",
      "[7450]\ttrain-auc:0.89916\ttest-auc:0.88308\n",
      "[7460]\ttrain-auc:0.89919\ttest-auc:0.88310\n",
      "[7470]\ttrain-auc:0.89921\ttest-auc:0.88312\n",
      "[7480]\ttrain-auc:0.89923\ttest-auc:0.88313\n",
      "[7490]\ttrain-auc:0.89926\ttest-auc:0.88314\n",
      "[7500]\ttrain-auc:0.89928\ttest-auc:0.88315\n",
      "[7510]\ttrain-auc:0.89929\ttest-auc:0.88315\n",
      "[7520]\ttrain-auc:0.89933\ttest-auc:0.88318\n",
      "[7530]\ttrain-auc:0.89935\ttest-auc:0.88319\n",
      "[7540]\ttrain-auc:0.89937\ttest-auc:0.88320\n",
      "[7550]\ttrain-auc:0.89939\ttest-auc:0.88321\n",
      "[7560]\ttrain-auc:0.89942\ttest-auc:0.88323\n",
      "[7570]\ttrain-auc:0.89944\ttest-auc:0.88324\n",
      "[7580]\ttrain-auc:0.89946\ttest-auc:0.88325\n",
      "[7590]\ttrain-auc:0.89949\ttest-auc:0.88328\n",
      "[7600]\ttrain-auc:0.89951\ttest-auc:0.88329\n",
      "[7610]\ttrain-auc:0.89957\ttest-auc:0.88334\n",
      "[7620]\ttrain-auc:0.89959\ttest-auc:0.88336\n",
      "[7630]\ttrain-auc:0.89961\ttest-auc:0.88337\n",
      "[7640]\ttrain-auc:0.89963\ttest-auc:0.88338\n",
      "[7650]\ttrain-auc:0.89965\ttest-auc:0.88340\n",
      "[7660]\ttrain-auc:0.89967\ttest-auc:0.88342\n",
      "[7670]\ttrain-auc:0.89970\ttest-auc:0.88343\n",
      "[7680]\ttrain-auc:0.89972\ttest-auc:0.88346\n",
      "[7690]\ttrain-auc:0.89975\ttest-auc:0.88349\n",
      "[7700]\ttrain-auc:0.89980\ttest-auc:0.88353\n",
      "[7710]\ttrain-auc:0.89984\ttest-auc:0.88355\n",
      "[7720]\ttrain-auc:0.89985\ttest-auc:0.88356\n",
      "[7730]\ttrain-auc:0.89987\ttest-auc:0.88356\n",
      "[7740]\ttrain-auc:0.89990\ttest-auc:0.88355\n",
      "[7750]\ttrain-auc:0.89992\ttest-auc:0.88356\n",
      "[7760]\ttrain-auc:0.89994\ttest-auc:0.88357\n",
      "[7770]\ttrain-auc:0.89996\ttest-auc:0.88358\n",
      "[7780]\ttrain-auc:0.89997\ttest-auc:0.88359\n",
      "[7790]\ttrain-auc:0.90000\ttest-auc:0.88360\n",
      "[7800]\ttrain-auc:0.90002\ttest-auc:0.88360\n",
      "[7810]\ttrain-auc:0.90004\ttest-auc:0.88360\n",
      "[7820]\ttrain-auc:0.90006\ttest-auc:0.88361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7830]\ttrain-auc:0.90009\ttest-auc:0.88364\n",
      "[7840]\ttrain-auc:0.90010\ttest-auc:0.88365\n",
      "[7850]\ttrain-auc:0.90014\ttest-auc:0.88367\n",
      "[7860]\ttrain-auc:0.90015\ttest-auc:0.88367\n",
      "[7870]\ttrain-auc:0.90017\ttest-auc:0.88369\n",
      "[7880]\ttrain-auc:0.90019\ttest-auc:0.88369\n",
      "[7890]\ttrain-auc:0.90020\ttest-auc:0.88370\n",
      "[7900]\ttrain-auc:0.90022\ttest-auc:0.88370\n",
      "[7910]\ttrain-auc:0.90024\ttest-auc:0.88371\n",
      "[7920]\ttrain-auc:0.90026\ttest-auc:0.88372\n",
      "[7930]\ttrain-auc:0.90028\ttest-auc:0.88374\n",
      "[7940]\ttrain-auc:0.90030\ttest-auc:0.88375\n",
      "[7950]\ttrain-auc:0.90033\ttest-auc:0.88377\n",
      "[7960]\ttrain-auc:0.90034\ttest-auc:0.88377\n",
      "[7970]\ttrain-auc:0.90037\ttest-auc:0.88378\n",
      "[7980]\ttrain-auc:0.90038\ttest-auc:0.88379\n",
      "[7990]\ttrain-auc:0.90040\ttest-auc:0.88379\n",
      "[8000]\ttrain-auc:0.90043\ttest-auc:0.88382\n",
      "[8010]\ttrain-auc:0.90046\ttest-auc:0.88383\n",
      "[8020]\ttrain-auc:0.90048\ttest-auc:0.88383\n",
      "[8030]\ttrain-auc:0.90050\ttest-auc:0.88384\n",
      "[8040]\ttrain-auc:0.90052\ttest-auc:0.88385\n",
      "[8050]\ttrain-auc:0.90054\ttest-auc:0.88388\n",
      "[8060]\ttrain-auc:0.90057\ttest-auc:0.88390\n",
      "[8070]\ttrain-auc:0.90059\ttest-auc:0.88391\n",
      "[8080]\ttrain-auc:0.90062\ttest-auc:0.88392\n",
      "[8090]\ttrain-auc:0.90064\ttest-auc:0.88394\n",
      "[8100]\ttrain-auc:0.90066\ttest-auc:0.88395\n",
      "[8110]\ttrain-auc:0.90068\ttest-auc:0.88396\n",
      "[8120]\ttrain-auc:0.90070\ttest-auc:0.88397\n",
      "[8130]\ttrain-auc:0.90073\ttest-auc:0.88399\n",
      "[8140]\ttrain-auc:0.90075\ttest-auc:0.88400\n",
      "[8150]\ttrain-auc:0.90077\ttest-auc:0.88402\n",
      "[8160]\ttrain-auc:0.90079\ttest-auc:0.88403\n",
      "[8170]\ttrain-auc:0.90081\ttest-auc:0.88404\n",
      "[8180]\ttrain-auc:0.90083\ttest-auc:0.88405\n",
      "[8190]\ttrain-auc:0.90085\ttest-auc:0.88406\n",
      "[8200]\ttrain-auc:0.90087\ttest-auc:0.88408\n",
      "[8210]\ttrain-auc:0.90089\ttest-auc:0.88409\n",
      "[8220]\ttrain-auc:0.90091\ttest-auc:0.88409\n",
      "[8230]\ttrain-auc:0.90093\ttest-auc:0.88410\n",
      "[8240]\ttrain-auc:0.90094\ttest-auc:0.88411\n",
      "[8250]\ttrain-auc:0.90097\ttest-auc:0.88412\n",
      "[8260]\ttrain-auc:0.90098\ttest-auc:0.88413\n",
      "[8270]\ttrain-auc:0.90100\ttest-auc:0.88414\n",
      "[8280]\ttrain-auc:0.90102\ttest-auc:0.88414\n",
      "[8290]\ttrain-auc:0.90104\ttest-auc:0.88415\n",
      "[8300]\ttrain-auc:0.90106\ttest-auc:0.88415\n",
      "[8310]\ttrain-auc:0.90108\ttest-auc:0.88417\n",
      "[8320]\ttrain-auc:0.90109\ttest-auc:0.88417\n",
      "[8330]\ttrain-auc:0.90111\ttest-auc:0.88418\n",
      "[8340]\ttrain-auc:0.90114\ttest-auc:0.88418\n",
      "[8350]\ttrain-auc:0.90116\ttest-auc:0.88420\n",
      "[8360]\ttrain-auc:0.90121\ttest-auc:0.88425\n",
      "[8370]\ttrain-auc:0.90123\ttest-auc:0.88426\n",
      "[8380]\ttrain-auc:0.90125\ttest-auc:0.88427\n",
      "[8390]\ttrain-auc:0.90127\ttest-auc:0.88427\n",
      "[8400]\ttrain-auc:0.90129\ttest-auc:0.88429\n",
      "[8410]\ttrain-auc:0.90130\ttest-auc:0.88430\n",
      "[8420]\ttrain-auc:0.90132\ttest-auc:0.88431\n",
      "[8430]\ttrain-auc:0.90134\ttest-auc:0.88432\n",
      "[8440]\ttrain-auc:0.90137\ttest-auc:0.88433\n",
      "[8450]\ttrain-auc:0.90139\ttest-auc:0.88434\n",
      "[8460]\ttrain-auc:0.90141\ttest-auc:0.88434\n",
      "[8470]\ttrain-auc:0.90145\ttest-auc:0.88439\n",
      "[8480]\ttrain-auc:0.90147\ttest-auc:0.88440\n",
      "[8490]\ttrain-auc:0.90149\ttest-auc:0.88442\n",
      "[8500]\ttrain-auc:0.90151\ttest-auc:0.88442\n",
      "[8510]\ttrain-auc:0.90153\ttest-auc:0.88443\n",
      "[8520]\ttrain-auc:0.90155\ttest-auc:0.88445\n",
      "[8530]\ttrain-auc:0.90157\ttest-auc:0.88445\n",
      "[8540]\ttrain-auc:0.90158\ttest-auc:0.88447\n",
      "[8550]\ttrain-auc:0.90160\ttest-auc:0.88448\n",
      "[8560]\ttrain-auc:0.90162\ttest-auc:0.88449\n",
      "[8570]\ttrain-auc:0.90164\ttest-auc:0.88450\n",
      "[8580]\ttrain-auc:0.90167\ttest-auc:0.88451\n",
      "[8590]\ttrain-auc:0.90168\ttest-auc:0.88453\n",
      "[8600]\ttrain-auc:0.90171\ttest-auc:0.88453\n",
      "[8610]\ttrain-auc:0.90173\ttest-auc:0.88454\n",
      "[8620]\ttrain-auc:0.90175\ttest-auc:0.88455\n",
      "[8630]\ttrain-auc:0.90177\ttest-auc:0.88457\n",
      "[8640]\ttrain-auc:0.90178\ttest-auc:0.88458\n",
      "[8650]\ttrain-auc:0.90182\ttest-auc:0.88460\n",
      "[8660]\ttrain-auc:0.90185\ttest-auc:0.88461\n",
      "[8670]\ttrain-auc:0.90187\ttest-auc:0.88464\n",
      "[8680]\ttrain-auc:0.90190\ttest-auc:0.88465\n",
      "[8690]\ttrain-auc:0.90192\ttest-auc:0.88466\n",
      "[8700]\ttrain-auc:0.90194\ttest-auc:0.88467\n",
      "[8710]\ttrain-auc:0.90196\ttest-auc:0.88468\n",
      "[8720]\ttrain-auc:0.90197\ttest-auc:0.88468\n",
      "[8730]\ttrain-auc:0.90199\ttest-auc:0.88469\n",
      "[8740]\ttrain-auc:0.90201\ttest-auc:0.88469\n",
      "[8750]\ttrain-auc:0.90203\ttest-auc:0.88470\n",
      "[8760]\ttrain-auc:0.90205\ttest-auc:0.88472\n",
      "[8770]\ttrain-auc:0.90207\ttest-auc:0.88473\n",
      "[8780]\ttrain-auc:0.90209\ttest-auc:0.88474\n",
      "[8790]\ttrain-auc:0.90212\ttest-auc:0.88475\n",
      "[8800]\ttrain-auc:0.90214\ttest-auc:0.88475\n",
      "[8810]\ttrain-auc:0.90216\ttest-auc:0.88477\n",
      "[8820]\ttrain-auc:0.90218\ttest-auc:0.88478\n",
      "[8830]\ttrain-auc:0.90220\ttest-auc:0.88479\n",
      "[8840]\ttrain-auc:0.90222\ttest-auc:0.88481\n",
      "[8850]\ttrain-auc:0.90223\ttest-auc:0.88482\n",
      "[8860]\ttrain-auc:0.90225\ttest-auc:0.88482\n",
      "[8870]\ttrain-auc:0.90226\ttest-auc:0.88482\n",
      "[8880]\ttrain-auc:0.90228\ttest-auc:0.88483\n",
      "[8890]\ttrain-auc:0.90230\ttest-auc:0.88483\n",
      "[8900]\ttrain-auc:0.90231\ttest-auc:0.88484\n",
      "[8910]\ttrain-auc:0.90233\ttest-auc:0.88487\n",
      "[8920]\ttrain-auc:0.90236\ttest-auc:0.88489\n",
      "[8930]\ttrain-auc:0.90240\ttest-auc:0.88493\n",
      "[8940]\ttrain-auc:0.90242\ttest-auc:0.88493\n",
      "[8950]\ttrain-auc:0.90243\ttest-auc:0.88494\n",
      "[8960]\ttrain-auc:0.90246\ttest-auc:0.88494\n",
      "[8970]\ttrain-auc:0.90247\ttest-auc:0.88495\n",
      "[8980]\ttrain-auc:0.90250\ttest-auc:0.88496\n",
      "[8990]\ttrain-auc:0.90252\ttest-auc:0.88498\n",
      "[9000]\ttrain-auc:0.90254\ttest-auc:0.88498\n",
      "[9010]\ttrain-auc:0.90255\ttest-auc:0.88499\n",
      "[9020]\ttrain-auc:0.90257\ttest-auc:0.88500\n",
      "[9030]\ttrain-auc:0.90260\ttest-auc:0.88501\n",
      "[9040]\ttrain-auc:0.90263\ttest-auc:0.88503\n",
      "[9050]\ttrain-auc:0.90264\ttest-auc:0.88503\n",
      "[9060]\ttrain-auc:0.90266\ttest-auc:0.88504\n",
      "[9070]\ttrain-auc:0.90268\ttest-auc:0.88505\n",
      "[9080]\ttrain-auc:0.90270\ttest-auc:0.88506\n",
      "[9090]\ttrain-auc:0.90272\ttest-auc:0.88508\n",
      "[9100]\ttrain-auc:0.90273\ttest-auc:0.88509\n",
      "[9110]\ttrain-auc:0.90275\ttest-auc:0.88511\n",
      "[9120]\ttrain-auc:0.90277\ttest-auc:0.88511\n",
      "[9130]\ttrain-auc:0.90279\ttest-auc:0.88512\n",
      "[9140]\ttrain-auc:0.90280\ttest-auc:0.88513\n",
      "[9150]\ttrain-auc:0.90282\ttest-auc:0.88515\n",
      "[9160]\ttrain-auc:0.90284\ttest-auc:0.88516\n",
      "[9170]\ttrain-auc:0.90286\ttest-auc:0.88517\n",
      "[9180]\ttrain-auc:0.90288\ttest-auc:0.88518\n",
      "[9190]\ttrain-auc:0.90291\ttest-auc:0.88520\n",
      "[9200]\ttrain-auc:0.90293\ttest-auc:0.88520\n",
      "[9210]\ttrain-auc:0.90295\ttest-auc:0.88522\n",
      "[9220]\ttrain-auc:0.90297\ttest-auc:0.88523\n",
      "[9230]\ttrain-auc:0.90298\ttest-auc:0.88524\n",
      "[9240]\ttrain-auc:0.90300\ttest-auc:0.88524\n",
      "[9250]\ttrain-auc:0.90302\ttest-auc:0.88526\n",
      "[9260]\ttrain-auc:0.90304\ttest-auc:0.88526\n",
      "[9270]\ttrain-auc:0.90306\ttest-auc:0.88528\n",
      "[9280]\ttrain-auc:0.90308\ttest-auc:0.88529\n",
      "[9290]\ttrain-auc:0.90309\ttest-auc:0.88529\n",
      "[9300]\ttrain-auc:0.90311\ttest-auc:0.88529\n",
      "[9310]\ttrain-auc:0.90312\ttest-auc:0.88530\n",
      "[9320]\ttrain-auc:0.90314\ttest-auc:0.88531\n",
      "[9330]\ttrain-auc:0.90316\ttest-auc:0.88531\n",
      "[9340]\ttrain-auc:0.90318\ttest-auc:0.88532\n",
      "[9350]\ttrain-auc:0.90320\ttest-auc:0.88535\n",
      "[9360]\ttrain-auc:0.90321\ttest-auc:0.88536\n",
      "[9370]\ttrain-auc:0.90323\ttest-auc:0.88536\n",
      "[9380]\ttrain-auc:0.90325\ttest-auc:0.88537\n",
      "[9390]\ttrain-auc:0.90326\ttest-auc:0.88537\n",
      "[9400]\ttrain-auc:0.90328\ttest-auc:0.88538\n",
      "[9410]\ttrain-auc:0.90330\ttest-auc:0.88540\n",
      "[9420]\ttrain-auc:0.90332\ttest-auc:0.88540\n",
      "[9430]\ttrain-auc:0.90333\ttest-auc:0.88542\n",
      "[9440]\ttrain-auc:0.90337\ttest-auc:0.88546\n",
      "[9450]\ttrain-auc:0.90339\ttest-auc:0.88546\n",
      "[9460]\ttrain-auc:0.90341\ttest-auc:0.88548\n",
      "[9470]\ttrain-auc:0.90343\ttest-auc:0.88550\n",
      "[9480]\ttrain-auc:0.90345\ttest-auc:0.88551\n",
      "[9490]\ttrain-auc:0.90347\ttest-auc:0.88551\n",
      "[9500]\ttrain-auc:0.90349\ttest-auc:0.88552\n",
      "[9510]\ttrain-auc:0.90351\ttest-auc:0.88553\n",
      "[9520]\ttrain-auc:0.90353\ttest-auc:0.88554\n",
      "[9530]\ttrain-auc:0.90356\ttest-auc:0.88556\n",
      "[9540]\ttrain-auc:0.90357\ttest-auc:0.88557\n",
      "[9550]\ttrain-auc:0.90361\ttest-auc:0.88560\n",
      "[9560]\ttrain-auc:0.90363\ttest-auc:0.88560\n",
      "[9570]\ttrain-auc:0.90364\ttest-auc:0.88560\n",
      "[9580]\ttrain-auc:0.90366\ttest-auc:0.88562\n",
      "[9590]\ttrain-auc:0.90368\ttest-auc:0.88563\n",
      "[9600]\ttrain-auc:0.90370\ttest-auc:0.88564\n",
      "[9610]\ttrain-auc:0.90371\ttest-auc:0.88565\n",
      "[9620]\ttrain-auc:0.90372\ttest-auc:0.88565\n",
      "[9630]\ttrain-auc:0.90375\ttest-auc:0.88566\n",
      "[9640]\ttrain-auc:0.90377\ttest-auc:0.88566\n",
      "[9650]\ttrain-auc:0.90378\ttest-auc:0.88567\n",
      "[9660]\ttrain-auc:0.90380\ttest-auc:0.88568\n",
      "[9670]\ttrain-auc:0.90381\ttest-auc:0.88568\n",
      "[9680]\ttrain-auc:0.90382\ttest-auc:0.88569\n",
      "[9690]\ttrain-auc:0.90384\ttest-auc:0.88570\n",
      "[9700]\ttrain-auc:0.90387\ttest-auc:0.88572\n",
      "[9710]\ttrain-auc:0.90389\ttest-auc:0.88573\n",
      "[9720]\ttrain-auc:0.90391\ttest-auc:0.88575\n",
      "[9730]\ttrain-auc:0.90392\ttest-auc:0.88575\n",
      "[9740]\ttrain-auc:0.90394\ttest-auc:0.88576\n",
      "[9750]\ttrain-auc:0.90396\ttest-auc:0.88578\n",
      "[9760]\ttrain-auc:0.90397\ttest-auc:0.88578\n",
      "[9770]\ttrain-auc:0.90399\ttest-auc:0.88579\n",
      "[9780]\ttrain-auc:0.90401\ttest-auc:0.88579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9790]\ttrain-auc:0.90404\ttest-auc:0.88582\n",
      "[9800]\ttrain-auc:0.90406\ttest-auc:0.88583\n",
      "[9810]\ttrain-auc:0.90408\ttest-auc:0.88584\n",
      "[9820]\ttrain-auc:0.90410\ttest-auc:0.88584\n",
      "[9830]\ttrain-auc:0.90413\ttest-auc:0.88587\n",
      "[9840]\ttrain-auc:0.90414\ttest-auc:0.88587\n",
      "[9850]\ttrain-auc:0.90416\ttest-auc:0.88588\n",
      "[9860]\ttrain-auc:0.90418\ttest-auc:0.88589\n",
      "[9870]\ttrain-auc:0.90420\ttest-auc:0.88589\n",
      "[9880]\ttrain-auc:0.90421\ttest-auc:0.88590\n",
      "[9890]\ttrain-auc:0.90424\ttest-auc:0.88591\n",
      "[9900]\ttrain-auc:0.90425\ttest-auc:0.88591\n",
      "[9910]\ttrain-auc:0.90427\ttest-auc:0.88592\n",
      "[9920]\ttrain-auc:0.90429\ttest-auc:0.88593\n",
      "[9930]\ttrain-auc:0.90431\ttest-auc:0.88594\n",
      "[9940]\ttrain-auc:0.90433\ttest-auc:0.88594\n",
      "[9950]\ttrain-auc:0.90435\ttest-auc:0.88596\n",
      "[9960]\ttrain-auc:0.90437\ttest-auc:0.88597\n",
      "[9970]\ttrain-auc:0.90439\ttest-auc:0.88597\n",
      "[9980]\ttrain-auc:0.90441\ttest-auc:0.88598\n",
      "[9990]\ttrain-auc:0.90444\ttest-auc:0.88600\n",
      "[10000]\ttrain-auc:0.90445\ttest-auc:0.88600\n",
      "[10010]\ttrain-auc:0.90447\ttest-auc:0.88601\n",
      "[10020]\ttrain-auc:0.90449\ttest-auc:0.88601\n",
      "[10030]\ttrain-auc:0.90450\ttest-auc:0.88601\n",
      "[10040]\ttrain-auc:0.90452\ttest-auc:0.88601\n",
      "[10050]\ttrain-auc:0.90454\ttest-auc:0.88603\n",
      "[10060]\ttrain-auc:0.90455\ttest-auc:0.88603\n",
      "[10070]\ttrain-auc:0.90456\ttest-auc:0.88604\n",
      "[10080]\ttrain-auc:0.90458\ttest-auc:0.88605\n",
      "[10090]\ttrain-auc:0.90460\ttest-auc:0.88606\n",
      "[10100]\ttrain-auc:0.90461\ttest-auc:0.88606\n",
      "[10110]\ttrain-auc:0.90463\ttest-auc:0.88607\n",
      "[10120]\ttrain-auc:0.90465\ttest-auc:0.88609\n",
      "[10130]\ttrain-auc:0.90468\ttest-auc:0.88612\n",
      "[10140]\ttrain-auc:0.90470\ttest-auc:0.88612\n",
      "[10150]\ttrain-auc:0.90472\ttest-auc:0.88614\n",
      "[10160]\ttrain-auc:0.90473\ttest-auc:0.88614\n",
      "[10170]\ttrain-auc:0.90474\ttest-auc:0.88614\n",
      "[10180]\ttrain-auc:0.90476\ttest-auc:0.88615\n",
      "[10190]\ttrain-auc:0.90478\ttest-auc:0.88615\n",
      "[10200]\ttrain-auc:0.90480\ttest-auc:0.88616\n",
      "[10210]\ttrain-auc:0.90481\ttest-auc:0.88617\n",
      "[10220]\ttrain-auc:0.90483\ttest-auc:0.88617\n",
      "[10230]\ttrain-auc:0.90484\ttest-auc:0.88618\n",
      "[10240]\ttrain-auc:0.90487\ttest-auc:0.88619\n",
      "[10250]\ttrain-auc:0.90488\ttest-auc:0.88620\n",
      "[10260]\ttrain-auc:0.90490\ttest-auc:0.88621\n",
      "[10270]\ttrain-auc:0.90492\ttest-auc:0.88622\n",
      "[10280]\ttrain-auc:0.90493\ttest-auc:0.88623\n",
      "[10290]\ttrain-auc:0.90495\ttest-auc:0.88624\n",
      "[10300]\ttrain-auc:0.90497\ttest-auc:0.88625\n",
      "[10310]\ttrain-auc:0.90500\ttest-auc:0.88627\n",
      "[10320]\ttrain-auc:0.90502\ttest-auc:0.88628\n",
      "[10330]\ttrain-auc:0.90503\ttest-auc:0.88629\n",
      "[10340]\ttrain-auc:0.90504\ttest-auc:0.88629\n",
      "[10350]\ttrain-auc:0.90506\ttest-auc:0.88629\n",
      "[10360]\ttrain-auc:0.90507\ttest-auc:0.88629\n",
      "[10370]\ttrain-auc:0.90509\ttest-auc:0.88631\n",
      "[10380]\ttrain-auc:0.90512\ttest-auc:0.88634\n",
      "[10390]\ttrain-auc:0.90514\ttest-auc:0.88634\n",
      "[10400]\ttrain-auc:0.90516\ttest-auc:0.88636\n",
      "[10410]\ttrain-auc:0.90518\ttest-auc:0.88636\n",
      "[10420]\ttrain-auc:0.90520\ttest-auc:0.88636\n",
      "[10430]\ttrain-auc:0.90522\ttest-auc:0.88638\n",
      "[10440]\ttrain-auc:0.90525\ttest-auc:0.88639\n",
      "[10450]\ttrain-auc:0.90527\ttest-auc:0.88641\n",
      "[10460]\ttrain-auc:0.90528\ttest-auc:0.88641\n",
      "[10470]\ttrain-auc:0.90529\ttest-auc:0.88642\n",
      "[10480]\ttrain-auc:0.90531\ttest-auc:0.88643\n",
      "[10490]\ttrain-auc:0.90534\ttest-auc:0.88644\n",
      "[10500]\ttrain-auc:0.90535\ttest-auc:0.88645\n",
      "[10510]\ttrain-auc:0.90537\ttest-auc:0.88645\n",
      "[10520]\ttrain-auc:0.90538\ttest-auc:0.88646\n",
      "[10530]\ttrain-auc:0.90540\ttest-auc:0.88647\n",
      "[10540]\ttrain-auc:0.90543\ttest-auc:0.88648\n",
      "[10550]\ttrain-auc:0.90544\ttest-auc:0.88649\n",
      "[10560]\ttrain-auc:0.90546\ttest-auc:0.88650\n",
      "[10570]\ttrain-auc:0.90548\ttest-auc:0.88650\n",
      "[10580]\ttrain-auc:0.90549\ttest-auc:0.88651\n",
      "[10590]\ttrain-auc:0.90551\ttest-auc:0.88652\n",
      "[10600]\ttrain-auc:0.90552\ttest-auc:0.88653\n",
      "[10610]\ttrain-auc:0.90553\ttest-auc:0.88653\n",
      "[10620]\ttrain-auc:0.90555\ttest-auc:0.88654\n",
      "[10630]\ttrain-auc:0.90557\ttest-auc:0.88655\n",
      "[10640]\ttrain-auc:0.90559\ttest-auc:0.88657\n",
      "[10650]\ttrain-auc:0.90561\ttest-auc:0.88658\n",
      "[10660]\ttrain-auc:0.90563\ttest-auc:0.88659\n",
      "[10670]\ttrain-auc:0.90564\ttest-auc:0.88659\n",
      "[10680]\ttrain-auc:0.90566\ttest-auc:0.88660\n",
      "[10690]\ttrain-auc:0.90568\ttest-auc:0.88660\n",
      "[10700]\ttrain-auc:0.90569\ttest-auc:0.88661\n",
      "[10710]\ttrain-auc:0.90570\ttest-auc:0.88662\n",
      "[10720]\ttrain-auc:0.90572\ttest-auc:0.88662\n",
      "[10730]\ttrain-auc:0.90573\ttest-auc:0.88663\n",
      "[10740]\ttrain-auc:0.90575\ttest-auc:0.88663\n",
      "[10750]\ttrain-auc:0.90577\ttest-auc:0.88663\n",
      "[10760]\ttrain-auc:0.90578\ttest-auc:0.88664\n",
      "[10770]\ttrain-auc:0.90579\ttest-auc:0.88664\n",
      "[10780]\ttrain-auc:0.90581\ttest-auc:0.88665\n",
      "[10790]\ttrain-auc:0.90583\ttest-auc:0.88665\n",
      "[10800]\ttrain-auc:0.90586\ttest-auc:0.88667\n",
      "[10810]\ttrain-auc:0.90587\ttest-auc:0.88668\n",
      "[10820]\ttrain-auc:0.90588\ttest-auc:0.88669\n",
      "[10830]\ttrain-auc:0.90590\ttest-auc:0.88669\n",
      "[10840]\ttrain-auc:0.90591\ttest-auc:0.88669\n",
      "[10850]\ttrain-auc:0.90592\ttest-auc:0.88670\n",
      "[10860]\ttrain-auc:0.90595\ttest-auc:0.88671\n",
      "[10870]\ttrain-auc:0.90597\ttest-auc:0.88671\n",
      "[10880]\ttrain-auc:0.90599\ttest-auc:0.88673\n",
      "[10890]\ttrain-auc:0.90600\ttest-auc:0.88674\n",
      "[10900]\ttrain-auc:0.90602\ttest-auc:0.88674\n",
      "[10910]\ttrain-auc:0.90605\ttest-auc:0.88676\n",
      "[10920]\ttrain-auc:0.90606\ttest-auc:0.88676\n",
      "[10930]\ttrain-auc:0.90608\ttest-auc:0.88678\n",
      "[10940]\ttrain-auc:0.90610\ttest-auc:0.88679\n",
      "[10950]\ttrain-auc:0.90611\ttest-auc:0.88679\n",
      "[10960]\ttrain-auc:0.90613\ttest-auc:0.88680\n",
      "[10970]\ttrain-auc:0.90614\ttest-auc:0.88680\n",
      "[10980]\ttrain-auc:0.90616\ttest-auc:0.88681\n",
      "[10990]\ttrain-auc:0.90617\ttest-auc:0.88682\n",
      "[11000]\ttrain-auc:0.90619\ttest-auc:0.88682\n",
      "[11010]\ttrain-auc:0.90620\ttest-auc:0.88683\n",
      "[11020]\ttrain-auc:0.90622\ttest-auc:0.88684\n",
      "[11030]\ttrain-auc:0.90623\ttest-auc:0.88684\n",
      "[11040]\ttrain-auc:0.90625\ttest-auc:0.88684\n",
      "[11050]\ttrain-auc:0.90627\ttest-auc:0.88685\n",
      "[11060]\ttrain-auc:0.90628\ttest-auc:0.88685\n",
      "[11070]\ttrain-auc:0.90629\ttest-auc:0.88686\n",
      "[11080]\ttrain-auc:0.90631\ttest-auc:0.88687\n",
      "[11090]\ttrain-auc:0.90632\ttest-auc:0.88688\n",
      "[11100]\ttrain-auc:0.90634\ttest-auc:0.88689\n",
      "[11110]\ttrain-auc:0.90636\ttest-auc:0.88690\n",
      "[11120]\ttrain-auc:0.90637\ttest-auc:0.88691\n",
      "[11130]\ttrain-auc:0.90638\ttest-auc:0.88691\n",
      "[11140]\ttrain-auc:0.90640\ttest-auc:0.88691\n",
      "[11150]\ttrain-auc:0.90642\ttest-auc:0.88693\n",
      "[11160]\ttrain-auc:0.90644\ttest-auc:0.88694\n",
      "[11170]\ttrain-auc:0.90646\ttest-auc:0.88695\n",
      "[11180]\ttrain-auc:0.90647\ttest-auc:0.88696\n",
      "[11190]\ttrain-auc:0.90649\ttest-auc:0.88697\n",
      "[11200]\ttrain-auc:0.90651\ttest-auc:0.88697\n",
      "[11210]\ttrain-auc:0.90652\ttest-auc:0.88698\n",
      "[11220]\ttrain-auc:0.90653\ttest-auc:0.88699\n",
      "[11230]\ttrain-auc:0.90654\ttest-auc:0.88699\n",
      "[11240]\ttrain-auc:0.90656\ttest-auc:0.88700\n",
      "[11250]\ttrain-auc:0.90658\ttest-auc:0.88701\n",
      "[11260]\ttrain-auc:0.90659\ttest-auc:0.88701\n",
      "[11270]\ttrain-auc:0.90660\ttest-auc:0.88702\n",
      "[11280]\ttrain-auc:0.90661\ttest-auc:0.88702\n",
      "[11290]\ttrain-auc:0.90663\ttest-auc:0.88702\n",
      "[11300]\ttrain-auc:0.90665\ttest-auc:0.88702\n",
      "[11310]\ttrain-auc:0.90667\ttest-auc:0.88703\n",
      "[11320]\ttrain-auc:0.90669\ttest-auc:0.88703\n",
      "[11330]\ttrain-auc:0.90671\ttest-auc:0.88706\n",
      "[11340]\ttrain-auc:0.90674\ttest-auc:0.88708\n",
      "[11350]\ttrain-auc:0.90675\ttest-auc:0.88708\n",
      "[11360]\ttrain-auc:0.90678\ttest-auc:0.88711\n",
      "[11370]\ttrain-auc:0.90680\ttest-auc:0.88711\n",
      "[11380]\ttrain-auc:0.90681\ttest-auc:0.88713\n",
      "[11390]\ttrain-auc:0.90683\ttest-auc:0.88712\n",
      "[11400]\ttrain-auc:0.90684\ttest-auc:0.88713\n",
      "[11410]\ttrain-auc:0.90687\ttest-auc:0.88715\n",
      "[11420]\ttrain-auc:0.90689\ttest-auc:0.88717\n",
      "[11430]\ttrain-auc:0.90691\ttest-auc:0.88719\n",
      "[11440]\ttrain-auc:0.90692\ttest-auc:0.88720\n",
      "[11450]\ttrain-auc:0.90694\ttest-auc:0.88720\n",
      "[11460]\ttrain-auc:0.90696\ttest-auc:0.88722\n",
      "[11470]\ttrain-auc:0.90697\ttest-auc:0.88723\n",
      "[11480]\ttrain-auc:0.90699\ttest-auc:0.88723\n",
      "[11490]\ttrain-auc:0.90700\ttest-auc:0.88724\n",
      "[11500]\ttrain-auc:0.90702\ttest-auc:0.88724\n",
      "[11510]\ttrain-auc:0.90704\ttest-auc:0.88725\n",
      "[11520]\ttrain-auc:0.90705\ttest-auc:0.88726\n",
      "[11530]\ttrain-auc:0.90707\ttest-auc:0.88727\n",
      "[11540]\ttrain-auc:0.90709\ttest-auc:0.88727\n",
      "[11550]\ttrain-auc:0.90711\ttest-auc:0.88729\n",
      "[11560]\ttrain-auc:0.90712\ttest-auc:0.88729\n",
      "[11570]\ttrain-auc:0.90713\ttest-auc:0.88730\n",
      "[11580]\ttrain-auc:0.90714\ttest-auc:0.88731\n",
      "[11590]\ttrain-auc:0.90716\ttest-auc:0.88731\n",
      "[11600]\ttrain-auc:0.90718\ttest-auc:0.88732\n",
      "[11610]\ttrain-auc:0.90719\ttest-auc:0.88732\n",
      "[11620]\ttrain-auc:0.90721\ttest-auc:0.88733\n",
      "[11630]\ttrain-auc:0.90722\ttest-auc:0.88733\n",
      "[11640]\ttrain-auc:0.90723\ttest-auc:0.88733\n",
      "[11650]\ttrain-auc:0.90725\ttest-auc:0.88735\n",
      "[11660]\ttrain-auc:0.90727\ttest-auc:0.88736\n",
      "[11670]\ttrain-auc:0.90728\ttest-auc:0.88736\n",
      "[11680]\ttrain-auc:0.90730\ttest-auc:0.88737\n",
      "[11690]\ttrain-auc:0.90732\ttest-auc:0.88737\n",
      "[11700]\ttrain-auc:0.90733\ttest-auc:0.88738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11710]\ttrain-auc:0.90734\ttest-auc:0.88738\n",
      "[11720]\ttrain-auc:0.90736\ttest-auc:0.88738\n",
      "[11730]\ttrain-auc:0.90737\ttest-auc:0.88738\n",
      "[11740]\ttrain-auc:0.90738\ttest-auc:0.88738\n",
      "[11750]\ttrain-auc:0.90739\ttest-auc:0.88739\n",
      "[11760]\ttrain-auc:0.90742\ttest-auc:0.88739\n",
      "[11770]\ttrain-auc:0.90743\ttest-auc:0.88740\n",
      "[11780]\ttrain-auc:0.90744\ttest-auc:0.88741\n",
      "[11790]\ttrain-auc:0.90746\ttest-auc:0.88743\n",
      "[11800]\ttrain-auc:0.90747\ttest-auc:0.88743\n",
      "[11810]\ttrain-auc:0.90749\ttest-auc:0.88744\n",
      "[11820]\ttrain-auc:0.90751\ttest-auc:0.88744\n",
      "[11830]\ttrain-auc:0.90752\ttest-auc:0.88745\n",
      "[11840]\ttrain-auc:0.90754\ttest-auc:0.88746\n",
      "[11850]\ttrain-auc:0.90755\ttest-auc:0.88747\n",
      "[11860]\ttrain-auc:0.90757\ttest-auc:0.88748\n",
      "[11870]\ttrain-auc:0.90758\ttest-auc:0.88748\n",
      "[11880]\ttrain-auc:0.90759\ttest-auc:0.88748\n",
      "[11890]\ttrain-auc:0.90760\ttest-auc:0.88749\n",
      "[11900]\ttrain-auc:0.90761\ttest-auc:0.88749\n",
      "[11910]\ttrain-auc:0.90763\ttest-auc:0.88750\n",
      "[11920]\ttrain-auc:0.90765\ttest-auc:0.88752\n",
      "[11930]\ttrain-auc:0.90767\ttest-auc:0.88753\n",
      "[11940]\ttrain-auc:0.90768\ttest-auc:0.88753\n",
      "[11950]\ttrain-auc:0.90770\ttest-auc:0.88753\n",
      "[11960]\ttrain-auc:0.90771\ttest-auc:0.88753\n",
      "[11970]\ttrain-auc:0.90772\ttest-auc:0.88754\n",
      "[11980]\ttrain-auc:0.90773\ttest-auc:0.88755\n",
      "[11990]\ttrain-auc:0.90775\ttest-auc:0.88756\n",
      "[12000]\ttrain-auc:0.90777\ttest-auc:0.88757\n",
      "[12010]\ttrain-auc:0.90779\ttest-auc:0.88758\n",
      "[12020]\ttrain-auc:0.90780\ttest-auc:0.88758\n",
      "[12030]\ttrain-auc:0.90782\ttest-auc:0.88759\n",
      "[12040]\ttrain-auc:0.90783\ttest-auc:0.88760\n",
      "[12050]\ttrain-auc:0.90785\ttest-auc:0.88760\n",
      "[12060]\ttrain-auc:0.90787\ttest-auc:0.88760\n",
      "[12070]\ttrain-auc:0.90788\ttest-auc:0.88761\n",
      "[12080]\ttrain-auc:0.90790\ttest-auc:0.88761\n",
      "[12090]\ttrain-auc:0.90791\ttest-auc:0.88762\n",
      "[12100]\ttrain-auc:0.90793\ttest-auc:0.88761\n",
      "[12110]\ttrain-auc:0.90794\ttest-auc:0.88762\n",
      "[12120]\ttrain-auc:0.90796\ttest-auc:0.88763\n",
      "[12130]\ttrain-auc:0.90798\ttest-auc:0.88763\n",
      "[12140]\ttrain-auc:0.90799\ttest-auc:0.88764\n",
      "[12150]\ttrain-auc:0.90801\ttest-auc:0.88766\n",
      "[12160]\ttrain-auc:0.90803\ttest-auc:0.88766\n",
      "[12170]\ttrain-auc:0.90804\ttest-auc:0.88767\n",
      "[12180]\ttrain-auc:0.90805\ttest-auc:0.88767\n",
      "[12190]\ttrain-auc:0.90807\ttest-auc:0.88769\n",
      "[12200]\ttrain-auc:0.90808\ttest-auc:0.88769\n",
      "[12210]\ttrain-auc:0.90810\ttest-auc:0.88769\n",
      "[12220]\ttrain-auc:0.90811\ttest-auc:0.88770\n",
      "[12230]\ttrain-auc:0.90813\ttest-auc:0.88771\n",
      "[12240]\ttrain-auc:0.90815\ttest-auc:0.88771\n",
      "[12250]\ttrain-auc:0.90817\ttest-auc:0.88772\n",
      "[12260]\ttrain-auc:0.90818\ttest-auc:0.88772\n",
      "[12270]\ttrain-auc:0.90820\ttest-auc:0.88773\n",
      "[12280]\ttrain-auc:0.90822\ttest-auc:0.88774\n",
      "[12290]\ttrain-auc:0.90823\ttest-auc:0.88774\n",
      "[12300]\ttrain-auc:0.90824\ttest-auc:0.88775\n",
      "[12310]\ttrain-auc:0.90826\ttest-auc:0.88774\n",
      "[12320]\ttrain-auc:0.90827\ttest-auc:0.88774\n",
      "[12330]\ttrain-auc:0.90828\ttest-auc:0.88775\n",
      "[12340]\ttrain-auc:0.90829\ttest-auc:0.88776\n",
      "[12350]\ttrain-auc:0.90830\ttest-auc:0.88777\n",
      "[12360]\ttrain-auc:0.90832\ttest-auc:0.88777\n",
      "[12370]\ttrain-auc:0.90834\ttest-auc:0.88778\n",
      "[12380]\ttrain-auc:0.90835\ttest-auc:0.88779\n",
      "[12390]\ttrain-auc:0.90836\ttest-auc:0.88779\n",
      "[12400]\ttrain-auc:0.90838\ttest-auc:0.88780\n",
      "[12410]\ttrain-auc:0.90839\ttest-auc:0.88780\n",
      "[12420]\ttrain-auc:0.90841\ttest-auc:0.88780\n",
      "[12430]\ttrain-auc:0.90842\ttest-auc:0.88780\n",
      "[12440]\ttrain-auc:0.90844\ttest-auc:0.88781\n",
      "[12450]\ttrain-auc:0.90845\ttest-auc:0.88782\n",
      "[12460]\ttrain-auc:0.90847\ttest-auc:0.88783\n",
      "[12470]\ttrain-auc:0.90848\ttest-auc:0.88783\n",
      "[12480]\ttrain-auc:0.90849\ttest-auc:0.88784\n",
      "[12490]\ttrain-auc:0.90851\ttest-auc:0.88784\n",
      "[12500]\ttrain-auc:0.90852\ttest-auc:0.88784\n",
      "[12510]\ttrain-auc:0.90853\ttest-auc:0.88784\n",
      "[12520]\ttrain-auc:0.90855\ttest-auc:0.88785\n",
      "[12530]\ttrain-auc:0.90856\ttest-auc:0.88786\n",
      "[12540]\ttrain-auc:0.90858\ttest-auc:0.88787\n",
      "[12550]\ttrain-auc:0.90859\ttest-auc:0.88788\n",
      "[12560]\ttrain-auc:0.90860\ttest-auc:0.88788\n",
      "[12570]\ttrain-auc:0.90862\ttest-auc:0.88788\n",
      "[12580]\ttrain-auc:0.90864\ttest-auc:0.88789\n",
      "[12590]\ttrain-auc:0.90865\ttest-auc:0.88789\n",
      "[12600]\ttrain-auc:0.90867\ttest-auc:0.88789\n",
      "[12610]\ttrain-auc:0.90868\ttest-auc:0.88790\n",
      "[12620]\ttrain-auc:0.90869\ttest-auc:0.88789\n",
      "[12630]\ttrain-auc:0.90871\ttest-auc:0.88790\n",
      "[12640]\ttrain-auc:0.90872\ttest-auc:0.88791\n",
      "[12650]\ttrain-auc:0.90873\ttest-auc:0.88790\n",
      "[12660]\ttrain-auc:0.90875\ttest-auc:0.88791\n",
      "[12670]\ttrain-auc:0.90876\ttest-auc:0.88792\n",
      "[12680]\ttrain-auc:0.90877\ttest-auc:0.88792\n",
      "[12690]\ttrain-auc:0.90880\ttest-auc:0.88794\n",
      "[12700]\ttrain-auc:0.90882\ttest-auc:0.88796\n",
      "[12710]\ttrain-auc:0.90883\ttest-auc:0.88797\n",
      "[12720]\ttrain-auc:0.90884\ttest-auc:0.88797\n",
      "[12730]\ttrain-auc:0.90885\ttest-auc:0.88798\n",
      "[12740]\ttrain-auc:0.90886\ttest-auc:0.88798\n",
      "[12750]\ttrain-auc:0.90887\ttest-auc:0.88797\n",
      "[12760]\ttrain-auc:0.90889\ttest-auc:0.88797\n",
      "[12770]\ttrain-auc:0.90890\ttest-auc:0.88799\n",
      "[12780]\ttrain-auc:0.90892\ttest-auc:0.88800\n",
      "[12790]\ttrain-auc:0.90893\ttest-auc:0.88800\n",
      "[12800]\ttrain-auc:0.90894\ttest-auc:0.88801\n",
      "[12810]\ttrain-auc:0.90895\ttest-auc:0.88800\n",
      "[12820]\ttrain-auc:0.90896\ttest-auc:0.88801\n",
      "[12830]\ttrain-auc:0.90897\ttest-auc:0.88801\n",
      "[12840]\ttrain-auc:0.90899\ttest-auc:0.88802\n",
      "[12850]\ttrain-auc:0.90900\ttest-auc:0.88803\n",
      "[12860]\ttrain-auc:0.90902\ttest-auc:0.88804\n",
      "[12870]\ttrain-auc:0.90905\ttest-auc:0.88807\n",
      "[12880]\ttrain-auc:0.90906\ttest-auc:0.88808\n",
      "[12890]\ttrain-auc:0.90908\ttest-auc:0.88809\n",
      "[12900]\ttrain-auc:0.90910\ttest-auc:0.88809\n",
      "[12910]\ttrain-auc:0.90911\ttest-auc:0.88809\n",
      "[12920]\ttrain-auc:0.90912\ttest-auc:0.88811\n",
      "[12930]\ttrain-auc:0.90916\ttest-auc:0.88814\n",
      "[12940]\ttrain-auc:0.90917\ttest-auc:0.88815\n",
      "[12950]\ttrain-auc:0.90919\ttest-auc:0.88816\n",
      "[12960]\ttrain-auc:0.90920\ttest-auc:0.88817\n",
      "[12970]\ttrain-auc:0.90922\ttest-auc:0.88817\n",
      "[12980]\ttrain-auc:0.90924\ttest-auc:0.88819\n",
      "[12990]\ttrain-auc:0.90925\ttest-auc:0.88820\n",
      "[13000]\ttrain-auc:0.90927\ttest-auc:0.88821\n",
      "[13010]\ttrain-auc:0.90928\ttest-auc:0.88821\n",
      "[13020]\ttrain-auc:0.90930\ttest-auc:0.88822\n",
      "[13030]\ttrain-auc:0.90932\ttest-auc:0.88823\n",
      "[13040]\ttrain-auc:0.90933\ttest-auc:0.88824\n",
      "[13050]\ttrain-auc:0.90935\ttest-auc:0.88825\n",
      "[13060]\ttrain-auc:0.90936\ttest-auc:0.88825\n",
      "[13070]\ttrain-auc:0.90938\ttest-auc:0.88826\n",
      "[13080]\ttrain-auc:0.90940\ttest-auc:0.88829\n",
      "[13090]\ttrain-auc:0.90941\ttest-auc:0.88829\n",
      "[13100]\ttrain-auc:0.90943\ttest-auc:0.88830\n",
      "[13110]\ttrain-auc:0.90945\ttest-auc:0.88831\n",
      "[13120]\ttrain-auc:0.90946\ttest-auc:0.88831\n",
      "[13130]\ttrain-auc:0.90948\ttest-auc:0.88832\n",
      "[13140]\ttrain-auc:0.90949\ttest-auc:0.88833\n",
      "[13150]\ttrain-auc:0.90951\ttest-auc:0.88834\n",
      "[13160]\ttrain-auc:0.90953\ttest-auc:0.88836\n",
      "[13170]\ttrain-auc:0.90954\ttest-auc:0.88836\n",
      "[13180]\ttrain-auc:0.90955\ttest-auc:0.88836\n",
      "[13190]\ttrain-auc:0.90956\ttest-auc:0.88837\n",
      "[13200]\ttrain-auc:0.90957\ttest-auc:0.88838\n",
      "[13210]\ttrain-auc:0.90958\ttest-auc:0.88838\n",
      "[13220]\ttrain-auc:0.90960\ttest-auc:0.88839\n",
      "[13230]\ttrain-auc:0.90962\ttest-auc:0.88840\n",
      "[13240]\ttrain-auc:0.90963\ttest-auc:0.88841\n",
      "[13250]\ttrain-auc:0.90964\ttest-auc:0.88841\n",
      "[13260]\ttrain-auc:0.90965\ttest-auc:0.88841\n",
      "[13270]\ttrain-auc:0.90968\ttest-auc:0.88843\n",
      "[13280]\ttrain-auc:0.90970\ttest-auc:0.88845\n",
      "[13290]\ttrain-auc:0.90971\ttest-auc:0.88846\n"
     ]
    }
   ],
   "source": [
    "params = {}\n",
    "params['objective'] = 'binary:logistic'\n",
    "params['eval_metric'] = 'auc'\n",
    "params['eta'] = 0.02\n",
    "params['max_depth'] = 4\n",
    "\n",
    "d_train = xgb.DMatrix(new_X_tr_q1q2, label=train_labels)\n",
    "d_test = xgb.DMatrix(new_X_te_q1q2, label=test_labels)\n",
    "\n",
    "evallist = [(d_train, 'train'), (d_test, 'test')]\n",
    "\n",
    "num_iters = 50000\n",
    "\n",
    "xgb_count_new = xgb.train(params, d_train, num_iters, evallist, early_stopping_rounds=50, verbose_eval=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#store xgboost\n",
    "# open a file, where you ant to store the data\n",
    "file = open('xgb_countvectorizer_features', 'wb')\n",
    "# dump information to that file\n",
    "pickle.dump(xgb_count_new, file)\n",
    "# close the file\n",
    "file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[13:01:26] C:\\Jenkins\\workspace\\xgboost-win64_release_0.90\\src\\gbm\\gbm.cc:20: Unknown gbm type ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-6d967f09cd91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'xgb_tfidf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb+'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# dump information to that file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mxgb_count_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;31m# close the file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m__setstate__\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    979\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 981\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSTRING_TYPES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    982\u001b[0m                 \u001b[1;31m# single string will be applied to all columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m                 \u001b[0mfeature_types\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfeature_types\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_col\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[0m_LIB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_check_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \"\"\"Check the return value of C API call\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [13:01:26] C:\\Jenkins\\workspace\\xgboost-win64_release_0.90\\src\\gbm\\gbm.cc:20: Unknown gbm type "
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "#Code to load xgboost\n",
    "\n",
    "# open a file, where you stored the pickled data\n",
    "file = open('xgb_countvectorizer_features', 'rb+')\n",
    "# dump information to that file\n",
    "xgb_count_new = pickle.load(file)\n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = xgb.DMatrix(new_X_tr_q1q2, label=train_labels)\n",
    "d_test = xgb.DMatrix(new_X_te_q1q2, label=test_labels)\n",
    "\n",
    "pred_test = xgb_count_new.predict(d_test).round(0).astype(int)\n",
    "pred_train = xgb_count_new.predict(d_train).round(0).astype(int)\n",
    "\n",
    "print(\"Accuracy on training: \", np.sum(train_labels==pred_train)/len(train_labels))\n",
    "print(\"Accuracy on test: \", np.sum(test_labels ==pred_test)/len(test_labels))\n",
    "\n",
    "mistake_indices, predictions = get_mistakes(xgb_count_new, d_train, train_labels)\n",
    "print_mistake_k(4, mistake_indices, predictions)      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third model - with TfIdfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=0.99, max_features=None,\n",
       "                min_df=5, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
       "                smooth_idf=False,\n",
       "                stop_words={'a', 'about', 'above', 'after', 'again', 'against',\n",
       "                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',\n",
       "                            'aren', \"aren't\", 'as', 'at', 'be', 'because',\n",
       "                            'been', 'before', 'being', 'below', 'between',\n",
       "                            'both', 'but', 'by', 'can', 'couldn', \"couldn't\", ...},\n",
       "                strip_accents=None, sublinear_tf=False,\n",
       "                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None,\n",
       "                use_idf=False, vocabulary=None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = tf(stop_words = set(stopwords.words('english')), ngram_range=(1,3), max_df = 0.4, min_df = 5)\n",
    "tfidf_vectorizer.fit(all_questions)\n",
    "\n",
    "tfidf_sk = sklearn.feature_extraction.text.TfidfVectorizer(use_idf=False, smooth_idf=False, sublinear_tf=False,\n",
    "                                                          stop_words = set(stopwords.words('english')),\n",
    "                                                          ngram_range=(1,3), max_df = 0.99, min_df = 5)\n",
    "tfidf_sk.fit(all_questions)\n",
    "\n",
    "X_tr_q1q2 = get_features_from_list(q1_train, q2_train,tfidf_vectorizer)\n",
    "X_te_q1q2  = get_features_from_list(q1_test, q2_test, tfidf_vectorizer)\n",
    "\n",
    "print('initial shape', X_tr_q1q2.shape)\n",
    "new_X_tr_q1q2 = sparse.hstack((X_tr_q1q2,intersect_train, num1_train, num2_train,\n",
    "                               dif_number_train,math1_train,math2_train,len1_train, len2_train))\n",
    "\n",
    "new_X_te_q1q2 = sparse.hstack((X_te_q1q2,intersect_test, num1_test, num2_test,\n",
    "                               dif_number_test, math1_test,math2_test,len1_test, len2_test))\n",
    "print('final shape', new_X_tr_q1q2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.82767\ttest-auc:0.82525\n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 50 rounds.\n",
      "[10]\ttrain-auc:0.83268\ttest-auc:0.82966\n",
      "[20]\ttrain-auc:0.83330\ttest-auc:0.83053\n",
      "[30]\ttrain-auc:0.83577\ttest-auc:0.83323\n",
      "[40]\ttrain-auc:0.83597\ttest-auc:0.83334\n",
      "[50]\ttrain-auc:0.83647\ttest-auc:0.83373\n",
      "[60]\ttrain-auc:0.83780\ttest-auc:0.83457\n",
      "[70]\ttrain-auc:0.83905\ttest-auc:0.83555\n",
      "[80]\ttrain-auc:0.84052\ttest-auc:0.83766\n",
      "[90]\ttrain-auc:0.84091\ttest-auc:0.83806\n",
      "[100]\ttrain-auc:0.84164\ttest-auc:0.83865\n",
      "[110]\ttrain-auc:0.84204\ttest-auc:0.83923\n",
      "[120]\ttrain-auc:0.84267\ttest-auc:0.84007\n",
      "[130]\ttrain-auc:0.84326\ttest-auc:0.84091\n",
      "[140]\ttrain-auc:0.84421\ttest-auc:0.84192\n",
      "[150]\ttrain-auc:0.84487\ttest-auc:0.84274\n",
      "[160]\ttrain-auc:0.84544\ttest-auc:0.84320\n",
      "[170]\ttrain-auc:0.84620\ttest-auc:0.84408\n",
      "[180]\ttrain-auc:0.84685\ttest-auc:0.84444\n",
      "[190]\ttrain-auc:0.84742\ttest-auc:0.84471\n",
      "[200]\ttrain-auc:0.84806\ttest-auc:0.84544\n",
      "[210]\ttrain-auc:0.85020\ttest-auc:0.84734\n",
      "[220]\ttrain-auc:0.85077\ttest-auc:0.84795\n",
      "[230]\ttrain-auc:0.85178\ttest-auc:0.84883\n",
      "[240]\ttrain-auc:0.85257\ttest-auc:0.84962\n",
      "[250]\ttrain-auc:0.85318\ttest-auc:0.85009\n",
      "[260]\ttrain-auc:0.85354\ttest-auc:0.85028\n",
      "[270]\ttrain-auc:0.85395\ttest-auc:0.85065\n",
      "[280]\ttrain-auc:0.85431\ttest-auc:0.85095\n",
      "[290]\ttrain-auc:0.85493\ttest-auc:0.85143\n",
      "[300]\ttrain-auc:0.85535\ttest-auc:0.85171\n",
      "[310]\ttrain-auc:0.85572\ttest-auc:0.85217\n",
      "[320]\ttrain-auc:0.85604\ttest-auc:0.85242\n",
      "[330]\ttrain-auc:0.85628\ttest-auc:0.85274\n",
      "[340]\ttrain-auc:0.85660\ttest-auc:0.85303\n",
      "[350]\ttrain-auc:0.85685\ttest-auc:0.85317\n",
      "[360]\ttrain-auc:0.85738\ttest-auc:0.85378\n",
      "[370]\ttrain-auc:0.85769\ttest-auc:0.85416\n",
      "[380]\ttrain-auc:0.85790\ttest-auc:0.85432\n",
      "[390]\ttrain-auc:0.85817\ttest-auc:0.85468\n",
      "[400]\ttrain-auc:0.85841\ttest-auc:0.85482\n",
      "[410]\ttrain-auc:0.85863\ttest-auc:0.85502\n",
      "[420]\ttrain-auc:0.85892\ttest-auc:0.85527\n",
      "[430]\ttrain-auc:0.85913\ttest-auc:0.85534\n",
      "[440]\ttrain-auc:0.85945\ttest-auc:0.85553\n",
      "[450]\ttrain-auc:0.85963\ttest-auc:0.85564\n",
      "[460]\ttrain-auc:0.86005\ttest-auc:0.85591\n",
      "[470]\ttrain-auc:0.86031\ttest-auc:0.85615\n",
      "[480]\ttrain-auc:0.86044\ttest-auc:0.85623\n",
      "[490]\ttrain-auc:0.86065\ttest-auc:0.85639\n",
      "[500]\ttrain-auc:0.86102\ttest-auc:0.85674\n",
      "[510]\ttrain-auc:0.86125\ttest-auc:0.85684\n",
      "[520]\ttrain-auc:0.86144\ttest-auc:0.85701\n",
      "[530]\ttrain-auc:0.86174\ttest-auc:0.85731\n",
      "[540]\ttrain-auc:0.86198\ttest-auc:0.85745\n",
      "[550]\ttrain-auc:0.86225\ttest-auc:0.85776\n",
      "[560]\ttrain-auc:0.86252\ttest-auc:0.85793\n",
      "[570]\ttrain-auc:0.86275\ttest-auc:0.85813\n",
      "[580]\ttrain-auc:0.86302\ttest-auc:0.85844\n",
      "[590]\ttrain-auc:0.86322\ttest-auc:0.85850\n",
      "[600]\ttrain-auc:0.86349\ttest-auc:0.85864\n",
      "[610]\ttrain-auc:0.86372\ttest-auc:0.85879\n",
      "[620]\ttrain-auc:0.86399\ttest-auc:0.85893\n",
      "[630]\ttrain-auc:0.86415\ttest-auc:0.85910\n",
      "[640]\ttrain-auc:0.86441\ttest-auc:0.85926\n",
      "[650]\ttrain-auc:0.86462\ttest-auc:0.85942\n",
      "[660]\ttrain-auc:0.86482\ttest-auc:0.85959\n",
      "[670]\ttrain-auc:0.86500\ttest-auc:0.85976\n",
      "[680]\ttrain-auc:0.86517\ttest-auc:0.85993\n",
      "[690]\ttrain-auc:0.86534\ttest-auc:0.86005\n",
      "[700]\ttrain-auc:0.86557\ttest-auc:0.86011\n",
      "[710]\ttrain-auc:0.86582\ttest-auc:0.86034\n",
      "[720]\ttrain-auc:0.86597\ttest-auc:0.86040\n",
      "[730]\ttrain-auc:0.86612\ttest-auc:0.86054\n",
      "[740]\ttrain-auc:0.86640\ttest-auc:0.86072\n",
      "[750]\ttrain-auc:0.86656\ttest-auc:0.86087\n",
      "[760]\ttrain-auc:0.86675\ttest-auc:0.86108\n",
      "[770]\ttrain-auc:0.86697\ttest-auc:0.86119\n",
      "[780]\ttrain-auc:0.86711\ttest-auc:0.86125\n",
      "[790]\ttrain-auc:0.86727\ttest-auc:0.86133\n",
      "[800]\ttrain-auc:0.86764\ttest-auc:0.86160\n",
      "[810]\ttrain-auc:0.86788\ttest-auc:0.86177\n",
      "[820]\ttrain-auc:0.86807\ttest-auc:0.86185\n",
      "[830]\ttrain-auc:0.86822\ttest-auc:0.86195\n",
      "[840]\ttrain-auc:0.86840\ttest-auc:0.86207\n",
      "[850]\ttrain-auc:0.86858\ttest-auc:0.86226\n",
      "[860]\ttrain-auc:0.86871\ttest-auc:0.86237\n",
      "[870]\ttrain-auc:0.86888\ttest-auc:0.86244\n",
      "[880]\ttrain-auc:0.86904\ttest-auc:0.86251\n",
      "[890]\ttrain-auc:0.86925\ttest-auc:0.86266\n",
      "[900]\ttrain-auc:0.86938\ttest-auc:0.86279\n",
      "[910]\ttrain-auc:0.86955\ttest-auc:0.86294\n",
      "[920]\ttrain-auc:0.86975\ttest-auc:0.86314\n",
      "[930]\ttrain-auc:0.86992\ttest-auc:0.86325\n",
      "[940]\ttrain-auc:0.87008\ttest-auc:0.86328\n",
      "[950]\ttrain-auc:0.87019\ttest-auc:0.86331\n",
      "[960]\ttrain-auc:0.87042\ttest-auc:0.86353\n",
      "[970]\ttrain-auc:0.87062\ttest-auc:0.86377\n",
      "[980]\ttrain-auc:0.87083\ttest-auc:0.86391\n",
      "[990]\ttrain-auc:0.87095\ttest-auc:0.86396\n",
      "[1000]\ttrain-auc:0.87107\ttest-auc:0.86403\n",
      "[1010]\ttrain-auc:0.87121\ttest-auc:0.86413\n",
      "[1020]\ttrain-auc:0.87135\ttest-auc:0.86422\n",
      "[1030]\ttrain-auc:0.87149\ttest-auc:0.86431\n",
      "[1040]\ttrain-auc:0.87165\ttest-auc:0.86441\n",
      "[1050]\ttrain-auc:0.87180\ttest-auc:0.86455\n",
      "[1060]\ttrain-auc:0.87195\ttest-auc:0.86468\n",
      "[1070]\ttrain-auc:0.87204\ttest-auc:0.86476\n",
      "[1080]\ttrain-auc:0.87215\ttest-auc:0.86480\n",
      "[1090]\ttrain-auc:0.87227\ttest-auc:0.86483\n",
      "[1100]\ttrain-auc:0.87243\ttest-auc:0.86492\n",
      "[1110]\ttrain-auc:0.87258\ttest-auc:0.86506\n",
      "[1120]\ttrain-auc:0.87269\ttest-auc:0.86514\n",
      "[1130]\ttrain-auc:0.87282\ttest-auc:0.86524\n",
      "[1140]\ttrain-auc:0.87307\ttest-auc:0.86538\n",
      "[1150]\ttrain-auc:0.87318\ttest-auc:0.86546\n",
      "[1160]\ttrain-auc:0.87329\ttest-auc:0.86552\n",
      "[1170]\ttrain-auc:0.87340\ttest-auc:0.86560\n",
      "[1180]\ttrain-auc:0.87352\ttest-auc:0.86563\n",
      "[1190]\ttrain-auc:0.87362\ttest-auc:0.86570\n",
      "[1200]\ttrain-auc:0.87375\ttest-auc:0.86578\n",
      "[1210]\ttrain-auc:0.87381\ttest-auc:0.86584\n",
      "[1220]\ttrain-auc:0.87395\ttest-auc:0.86591\n",
      "[1230]\ttrain-auc:0.87405\ttest-auc:0.86596\n",
      "[1240]\ttrain-auc:0.87422\ttest-auc:0.86603\n",
      "[1250]\ttrain-auc:0.87433\ttest-auc:0.86611\n",
      "[1260]\ttrain-auc:0.87443\ttest-auc:0.86618\n",
      "[1270]\ttrain-auc:0.87466\ttest-auc:0.86640\n",
      "[1280]\ttrain-auc:0.87478\ttest-auc:0.86648\n",
      "[1290]\ttrain-auc:0.87489\ttest-auc:0.86654\n",
      "[1300]\ttrain-auc:0.87501\ttest-auc:0.86660\n",
      "[1310]\ttrain-auc:0.87512\ttest-auc:0.86665\n",
      "[1320]\ttrain-auc:0.87526\ttest-auc:0.86676\n",
      "[1330]\ttrain-auc:0.87534\ttest-auc:0.86682\n",
      "[1340]\ttrain-auc:0.87543\ttest-auc:0.86691\n",
      "[1350]\ttrain-auc:0.87555\ttest-auc:0.86697\n",
      "[1360]\ttrain-auc:0.87566\ttest-auc:0.86706\n",
      "[1370]\ttrain-auc:0.87576\ttest-auc:0.86710\n",
      "[1380]\ttrain-auc:0.87586\ttest-auc:0.86708\n",
      "[1390]\ttrain-auc:0.87594\ttest-auc:0.86713\n",
      "[1400]\ttrain-auc:0.87609\ttest-auc:0.86723\n",
      "[1410]\ttrain-auc:0.87618\ttest-auc:0.86728\n",
      "[1420]\ttrain-auc:0.87628\ttest-auc:0.86732\n",
      "[1430]\ttrain-auc:0.87640\ttest-auc:0.86743\n",
      "[1440]\ttrain-auc:0.87652\ttest-auc:0.86750\n",
      "[1450]\ttrain-auc:0.87660\ttest-auc:0.86753\n",
      "[1460]\ttrain-auc:0.87673\ttest-auc:0.86762\n",
      "[1470]\ttrain-auc:0.87683\ttest-auc:0.86770\n",
      "[1480]\ttrain-auc:0.87695\ttest-auc:0.86779\n",
      "[1490]\ttrain-auc:0.87703\ttest-auc:0.86783\n",
      "[1500]\ttrain-auc:0.87713\ttest-auc:0.86788\n",
      "[1510]\ttrain-auc:0.87718\ttest-auc:0.86794\n",
      "[1520]\ttrain-auc:0.87728\ttest-auc:0.86799\n",
      "[1530]\ttrain-auc:0.87736\ttest-auc:0.86802\n",
      "[1540]\ttrain-auc:0.87745\ttest-auc:0.86808\n",
      "[1550]\ttrain-auc:0.87761\ttest-auc:0.86818\n",
      "[1560]\ttrain-auc:0.87770\ttest-auc:0.86824\n",
      "[1570]\ttrain-auc:0.87780\ttest-auc:0.86828\n",
      "[1580]\ttrain-auc:0.87794\ttest-auc:0.86839\n",
      "[1590]\ttrain-auc:0.87804\ttest-auc:0.86847\n",
      "[1600]\ttrain-auc:0.87811\ttest-auc:0.86854\n",
      "[1610]\ttrain-auc:0.87822\ttest-auc:0.86859\n",
      "[1620]\ttrain-auc:0.87833\ttest-auc:0.86858\n",
      "[1630]\ttrain-auc:0.87843\ttest-auc:0.86864\n",
      "[1640]\ttrain-auc:0.87851\ttest-auc:0.86866\n",
      "[1650]\ttrain-auc:0.87862\ttest-auc:0.86874\n",
      "[1660]\ttrain-auc:0.87869\ttest-auc:0.86879\n",
      "[1670]\ttrain-auc:0.87878\ttest-auc:0.86881\n",
      "[1680]\ttrain-auc:0.87886\ttest-auc:0.86887\n",
      "[1690]\ttrain-auc:0.87896\ttest-auc:0.86890\n",
      "[1700]\ttrain-auc:0.87904\ttest-auc:0.86895\n",
      "[1710]\ttrain-auc:0.87914\ttest-auc:0.86899\n",
      "[1720]\ttrain-auc:0.87923\ttest-auc:0.86905\n",
      "[1730]\ttrain-auc:0.87931\ttest-auc:0.86911\n",
      "[1740]\ttrain-auc:0.87940\ttest-auc:0.86917\n",
      "[1750]\ttrain-auc:0.87949\ttest-auc:0.86920\n",
      "[1760]\ttrain-auc:0.87959\ttest-auc:0.86926\n",
      "[1770]\ttrain-auc:0.87972\ttest-auc:0.86933\n",
      "[1780]\ttrain-auc:0.87982\ttest-auc:0.86938\n",
      "[1790]\ttrain-auc:0.87990\ttest-auc:0.86944\n",
      "[1800]\ttrain-auc:0.87998\ttest-auc:0.86950\n",
      "[1810]\ttrain-auc:0.88005\ttest-auc:0.86954\n",
      "[1820]\ttrain-auc:0.88011\ttest-auc:0.86957\n",
      "[1830]\ttrain-auc:0.88019\ttest-auc:0.86960\n",
      "[1840]\ttrain-auc:0.88028\ttest-auc:0.86967\n",
      "[1850]\ttrain-auc:0.88036\ttest-auc:0.86970\n",
      "[1860]\ttrain-auc:0.88044\ttest-auc:0.86975\n",
      "[1870]\ttrain-auc:0.88053\ttest-auc:0.86981\n",
      "[1880]\ttrain-auc:0.88063\ttest-auc:0.86989\n",
      "[1890]\ttrain-auc:0.88072\ttest-auc:0.86992\n",
      "[1900]\ttrain-auc:0.88081\ttest-auc:0.86998\n",
      "[1910]\ttrain-auc:0.88090\ttest-auc:0.87004\n",
      "[1920]\ttrain-auc:0.88099\ttest-auc:0.87007\n",
      "[1930]\ttrain-auc:0.88114\ttest-auc:0.87013\n",
      "[1940]\ttrain-auc:0.88121\ttest-auc:0.87018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1950]\ttrain-auc:0.88132\ttest-auc:0.87026\n",
      "[1960]\ttrain-auc:0.88140\ttest-auc:0.87028\n",
      "[1970]\ttrain-auc:0.88146\ttest-auc:0.87030\n",
      "[1980]\ttrain-auc:0.88154\ttest-auc:0.87035\n",
      "[1990]\ttrain-auc:0.88163\ttest-auc:0.87038\n",
      "[2000]\ttrain-auc:0.88172\ttest-auc:0.87042\n",
      "[2010]\ttrain-auc:0.88182\ttest-auc:0.87048\n",
      "[2020]\ttrain-auc:0.88190\ttest-auc:0.87052\n",
      "[2030]\ttrain-auc:0.88197\ttest-auc:0.87055\n",
      "[2040]\ttrain-auc:0.88206\ttest-auc:0.87059\n",
      "[2050]\ttrain-auc:0.88213\ttest-auc:0.87064\n",
      "[2060]\ttrain-auc:0.88219\ttest-auc:0.87065\n",
      "[2070]\ttrain-auc:0.88228\ttest-auc:0.87070\n",
      "[2080]\ttrain-auc:0.88240\ttest-auc:0.87078\n",
      "[2090]\ttrain-auc:0.88252\ttest-auc:0.87086\n",
      "[2100]\ttrain-auc:0.88259\ttest-auc:0.87089\n",
      "[2110]\ttrain-auc:0.88267\ttest-auc:0.87091\n",
      "[2120]\ttrain-auc:0.88276\ttest-auc:0.87097\n",
      "[2130]\ttrain-auc:0.88282\ttest-auc:0.87098\n",
      "[2140]\ttrain-auc:0.88289\ttest-auc:0.87100\n",
      "[2150]\ttrain-auc:0.88295\ttest-auc:0.87100\n",
      "[2160]\ttrain-auc:0.88303\ttest-auc:0.87105\n",
      "[2170]\ttrain-auc:0.88312\ttest-auc:0.87111\n",
      "[2180]\ttrain-auc:0.88322\ttest-auc:0.87115\n",
      "[2190]\ttrain-auc:0.88329\ttest-auc:0.87118\n",
      "[2200]\ttrain-auc:0.88338\ttest-auc:0.87123\n",
      "[2210]\ttrain-auc:0.88346\ttest-auc:0.87127\n",
      "[2220]\ttrain-auc:0.88353\ttest-auc:0.87132\n",
      "[2230]\ttrain-auc:0.88361\ttest-auc:0.87137\n",
      "[2240]\ttrain-auc:0.88372\ttest-auc:0.87147\n",
      "[2250]\ttrain-auc:0.88381\ttest-auc:0.87152\n",
      "[2260]\ttrain-auc:0.88387\ttest-auc:0.87153\n",
      "[2270]\ttrain-auc:0.88394\ttest-auc:0.87157\n",
      "[2280]\ttrain-auc:0.88401\ttest-auc:0.87158\n",
      "[2290]\ttrain-auc:0.88409\ttest-auc:0.87165\n",
      "[2300]\ttrain-auc:0.88416\ttest-auc:0.87167\n",
      "[2310]\ttrain-auc:0.88423\ttest-auc:0.87171\n",
      "[2320]\ttrain-auc:0.88429\ttest-auc:0.87174\n",
      "[2330]\ttrain-auc:0.88439\ttest-auc:0.87178\n",
      "[2340]\ttrain-auc:0.88446\ttest-auc:0.87182\n",
      "[2350]\ttrain-auc:0.88454\ttest-auc:0.87186\n",
      "[2360]\ttrain-auc:0.88462\ttest-auc:0.87190\n",
      "[2370]\ttrain-auc:0.88474\ttest-auc:0.87196\n",
      "[2380]\ttrain-auc:0.88479\ttest-auc:0.87199\n",
      "[2390]\ttrain-auc:0.88487\ttest-auc:0.87204\n",
      "[2400]\ttrain-auc:0.88494\ttest-auc:0.87210\n",
      "[2410]\ttrain-auc:0.88501\ttest-auc:0.87213\n",
      "[2420]\ttrain-auc:0.88507\ttest-auc:0.87215\n",
      "[2430]\ttrain-auc:0.88514\ttest-auc:0.87219\n",
      "[2440]\ttrain-auc:0.88522\ttest-auc:0.87224\n",
      "[2450]\ttrain-auc:0.88530\ttest-auc:0.87229\n",
      "[2460]\ttrain-auc:0.88534\ttest-auc:0.87230\n",
      "[2470]\ttrain-auc:0.88543\ttest-auc:0.87232\n",
      "[2480]\ttrain-auc:0.88550\ttest-auc:0.87234\n",
      "[2490]\ttrain-auc:0.88556\ttest-auc:0.87238\n",
      "[2500]\ttrain-auc:0.88564\ttest-auc:0.87241\n",
      "[2510]\ttrain-auc:0.88570\ttest-auc:0.87244\n",
      "[2520]\ttrain-auc:0.88578\ttest-auc:0.87249\n",
      "[2530]\ttrain-auc:0.88586\ttest-auc:0.87253\n",
      "[2540]\ttrain-auc:0.88593\ttest-auc:0.87256\n",
      "[2550]\ttrain-auc:0.88598\ttest-auc:0.87258\n",
      "[2560]\ttrain-auc:0.88604\ttest-auc:0.87261\n",
      "[2570]\ttrain-auc:0.88610\ttest-auc:0.87260\n",
      "[2580]\ttrain-auc:0.88617\ttest-auc:0.87263\n",
      "[2590]\ttrain-auc:0.88624\ttest-auc:0.87266\n",
      "[2600]\ttrain-auc:0.88631\ttest-auc:0.87267\n",
      "[2610]\ttrain-auc:0.88636\ttest-auc:0.87269\n",
      "[2620]\ttrain-auc:0.88642\ttest-auc:0.87272\n",
      "[2630]\ttrain-auc:0.88648\ttest-auc:0.87274\n",
      "[2640]\ttrain-auc:0.88655\ttest-auc:0.87277\n",
      "[2650]\ttrain-auc:0.88662\ttest-auc:0.87279\n",
      "[2660]\ttrain-auc:0.88672\ttest-auc:0.87289\n",
      "[2670]\ttrain-auc:0.88679\ttest-auc:0.87292\n",
      "[2680]\ttrain-auc:0.88686\ttest-auc:0.87299\n",
      "[2690]\ttrain-auc:0.88693\ttest-auc:0.87301\n",
      "[2700]\ttrain-auc:0.88701\ttest-auc:0.87306\n",
      "[2710]\ttrain-auc:0.88707\ttest-auc:0.87306\n",
      "[2720]\ttrain-auc:0.88713\ttest-auc:0.87310\n",
      "[2730]\ttrain-auc:0.88719\ttest-auc:0.87311\n",
      "[2740]\ttrain-auc:0.88726\ttest-auc:0.87316\n",
      "[2750]\ttrain-auc:0.88732\ttest-auc:0.87317\n",
      "[2760]\ttrain-auc:0.88738\ttest-auc:0.87320\n",
      "[2770]\ttrain-auc:0.88744\ttest-auc:0.87323\n",
      "[2780]\ttrain-auc:0.88750\ttest-auc:0.87326\n",
      "[2790]\ttrain-auc:0.88759\ttest-auc:0.87331\n",
      "[2800]\ttrain-auc:0.88765\ttest-auc:0.87336\n",
      "[2810]\ttrain-auc:0.88772\ttest-auc:0.87338\n",
      "[2820]\ttrain-auc:0.88778\ttest-auc:0.87342\n",
      "[2830]\ttrain-auc:0.88787\ttest-auc:0.87347\n",
      "[2840]\ttrain-auc:0.88793\ttest-auc:0.87349\n",
      "[2850]\ttrain-auc:0.88798\ttest-auc:0.87351\n",
      "[2860]\ttrain-auc:0.88804\ttest-auc:0.87354\n",
      "[2870]\ttrain-auc:0.88811\ttest-auc:0.87358\n",
      "[2880]\ttrain-auc:0.88819\ttest-auc:0.87362\n",
      "[2890]\ttrain-auc:0.88824\ttest-auc:0.87365\n",
      "[2900]\ttrain-auc:0.88833\ttest-auc:0.87369\n",
      "[2910]\ttrain-auc:0.88841\ttest-auc:0.87375\n",
      "[2920]\ttrain-auc:0.88847\ttest-auc:0.87376\n",
      "[2930]\ttrain-auc:0.88852\ttest-auc:0.87379\n",
      "[2940]\ttrain-auc:0.88860\ttest-auc:0.87382\n",
      "[2950]\ttrain-auc:0.88865\ttest-auc:0.87385\n",
      "[2960]\ttrain-auc:0.88872\ttest-auc:0.87386\n",
      "[2970]\ttrain-auc:0.88877\ttest-auc:0.87390\n",
      "[2980]\ttrain-auc:0.88882\ttest-auc:0.87393\n",
      "[2990]\ttrain-auc:0.88887\ttest-auc:0.87394\n",
      "[3000]\ttrain-auc:0.88892\ttest-auc:0.87396\n",
      "[3010]\ttrain-auc:0.88899\ttest-auc:0.87398\n",
      "[3020]\ttrain-auc:0.88906\ttest-auc:0.87405\n",
      "[3030]\ttrain-auc:0.88914\ttest-auc:0.87410\n",
      "[3040]\ttrain-auc:0.88919\ttest-auc:0.87411\n",
      "[3050]\ttrain-auc:0.88926\ttest-auc:0.87416\n",
      "[3060]\ttrain-auc:0.88932\ttest-auc:0.87421\n",
      "[3070]\ttrain-auc:0.88938\ttest-auc:0.87424\n",
      "[3080]\ttrain-auc:0.88943\ttest-auc:0.87425\n",
      "[3090]\ttrain-auc:0.88948\ttest-auc:0.87425\n",
      "[3100]\ttrain-auc:0.88954\ttest-auc:0.87427\n",
      "[3110]\ttrain-auc:0.88960\ttest-auc:0.87429\n",
      "[3120]\ttrain-auc:0.88965\ttest-auc:0.87431\n",
      "[3130]\ttrain-auc:0.88971\ttest-auc:0.87433\n",
      "[3140]\ttrain-auc:0.88978\ttest-auc:0.87435\n",
      "[3150]\ttrain-auc:0.88984\ttest-auc:0.87440\n",
      "[3160]\ttrain-auc:0.88989\ttest-auc:0.87441\n",
      "[3170]\ttrain-auc:0.88996\ttest-auc:0.87443\n",
      "[3180]\ttrain-auc:0.89002\ttest-auc:0.87445\n",
      "[3190]\ttrain-auc:0.89009\ttest-auc:0.87446\n",
      "[3200]\ttrain-auc:0.89015\ttest-auc:0.87454\n",
      "[3210]\ttrain-auc:0.89023\ttest-auc:0.87455\n",
      "[3220]\ttrain-auc:0.89028\ttest-auc:0.87458\n",
      "[3230]\ttrain-auc:0.89033\ttest-auc:0.87461\n",
      "[3240]\ttrain-auc:0.89039\ttest-auc:0.87463\n",
      "[3250]\ttrain-auc:0.89044\ttest-auc:0.87464\n",
      "[3260]\ttrain-auc:0.89049\ttest-auc:0.87465\n",
      "[3270]\ttrain-auc:0.89055\ttest-auc:0.87469\n",
      "[3280]\ttrain-auc:0.89062\ttest-auc:0.87471\n",
      "[3290]\ttrain-auc:0.89069\ttest-auc:0.87472\n",
      "[3300]\ttrain-auc:0.89075\ttest-auc:0.87474\n",
      "[3310]\ttrain-auc:0.89079\ttest-auc:0.87476\n",
      "[3320]\ttrain-auc:0.89087\ttest-auc:0.87483\n",
      "[3330]\ttrain-auc:0.89092\ttest-auc:0.87484\n",
      "[3340]\ttrain-auc:0.89098\ttest-auc:0.87489\n",
      "[3350]\ttrain-auc:0.89104\ttest-auc:0.87490\n",
      "[3360]\ttrain-auc:0.89109\ttest-auc:0.87492\n",
      "[3370]\ttrain-auc:0.89114\ttest-auc:0.87494\n",
      "[3380]\ttrain-auc:0.89119\ttest-auc:0.87493\n",
      "[3390]\ttrain-auc:0.89124\ttest-auc:0.87494\n",
      "[3400]\ttrain-auc:0.89131\ttest-auc:0.87496\n",
      "[3410]\ttrain-auc:0.89135\ttest-auc:0.87501\n",
      "[3420]\ttrain-auc:0.89141\ttest-auc:0.87503\n",
      "[3430]\ttrain-auc:0.89147\ttest-auc:0.87508\n",
      "[3440]\ttrain-auc:0.89153\ttest-auc:0.87509\n",
      "[3450]\ttrain-auc:0.89158\ttest-auc:0.87510\n",
      "[3460]\ttrain-auc:0.89164\ttest-auc:0.87514\n",
      "[3470]\ttrain-auc:0.89170\ttest-auc:0.87514\n",
      "[3480]\ttrain-auc:0.89175\ttest-auc:0.87517\n",
      "[3490]\ttrain-auc:0.89182\ttest-auc:0.87522\n",
      "[3500]\ttrain-auc:0.89187\ttest-auc:0.87525\n",
      "[3510]\ttrain-auc:0.89192\ttest-auc:0.87528\n",
      "[3520]\ttrain-auc:0.89199\ttest-auc:0.87532\n",
      "[3530]\ttrain-auc:0.89204\ttest-auc:0.87533\n",
      "[3540]\ttrain-auc:0.89210\ttest-auc:0.87536\n",
      "[3550]\ttrain-auc:0.89216\ttest-auc:0.87539\n",
      "[3560]\ttrain-auc:0.89223\ttest-auc:0.87545\n",
      "[3570]\ttrain-auc:0.89229\ttest-auc:0.87547\n",
      "[3580]\ttrain-auc:0.89235\ttest-auc:0.87549\n",
      "[3590]\ttrain-auc:0.89239\ttest-auc:0.87550\n",
      "[3600]\ttrain-auc:0.89244\ttest-auc:0.87552\n",
      "[3610]\ttrain-auc:0.89250\ttest-auc:0.87557\n",
      "[3620]\ttrain-auc:0.89256\ttest-auc:0.87562\n",
      "[3630]\ttrain-auc:0.89260\ttest-auc:0.87562\n",
      "[3640]\ttrain-auc:0.89267\ttest-auc:0.87566\n",
      "[3650]\ttrain-auc:0.89271\ttest-auc:0.87568\n",
      "[3660]\ttrain-auc:0.89276\ttest-auc:0.87569\n",
      "[3670]\ttrain-auc:0.89280\ttest-auc:0.87572\n",
      "[3680]\ttrain-auc:0.89285\ttest-auc:0.87574\n",
      "[3690]\ttrain-auc:0.89291\ttest-auc:0.87578\n",
      "[3700]\ttrain-auc:0.89295\ttest-auc:0.87579\n",
      "[3710]\ttrain-auc:0.89298\ttest-auc:0.87579\n",
      "[3720]\ttrain-auc:0.89303\ttest-auc:0.87580\n",
      "[3730]\ttrain-auc:0.89309\ttest-auc:0.87582\n",
      "[3740]\ttrain-auc:0.89315\ttest-auc:0.87588\n",
      "[3750]\ttrain-auc:0.89320\ttest-auc:0.87590\n",
      "[3760]\ttrain-auc:0.89326\ttest-auc:0.87594\n",
      "[3770]\ttrain-auc:0.89331\ttest-auc:0.87596\n",
      "[3780]\ttrain-auc:0.89336\ttest-auc:0.87599\n",
      "[3790]\ttrain-auc:0.89341\ttest-auc:0.87602\n",
      "[3800]\ttrain-auc:0.89346\ttest-auc:0.87603\n",
      "[3810]\ttrain-auc:0.89350\ttest-auc:0.87604\n",
      "[3820]\ttrain-auc:0.89355\ttest-auc:0.87607\n",
      "[3830]\ttrain-auc:0.89361\ttest-auc:0.87608\n",
      "[3840]\ttrain-auc:0.89366\ttest-auc:0.87610\n",
      "[3850]\ttrain-auc:0.89373\ttest-auc:0.87613\n",
      "[3860]\ttrain-auc:0.89379\ttest-auc:0.87615\n",
      "[3870]\ttrain-auc:0.89382\ttest-auc:0.87617\n",
      "[3880]\ttrain-auc:0.89388\ttest-auc:0.87619\n",
      "[3890]\ttrain-auc:0.89394\ttest-auc:0.87620\n",
      "[3900]\ttrain-auc:0.89398\ttest-auc:0.87622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3910]\ttrain-auc:0.89403\ttest-auc:0.87626\n",
      "[3920]\ttrain-auc:0.89408\ttest-auc:0.87627\n",
      "[3930]\ttrain-auc:0.89412\ttest-auc:0.87629\n",
      "[3940]\ttrain-auc:0.89416\ttest-auc:0.87629\n",
      "[3950]\ttrain-auc:0.89421\ttest-auc:0.87629\n",
      "[3960]\ttrain-auc:0.89424\ttest-auc:0.87630\n",
      "[3970]\ttrain-auc:0.89428\ttest-auc:0.87631\n",
      "[3980]\ttrain-auc:0.89433\ttest-auc:0.87633\n",
      "[3990]\ttrain-auc:0.89439\ttest-auc:0.87638\n",
      "[4000]\ttrain-auc:0.89444\ttest-auc:0.87641\n",
      "[4010]\ttrain-auc:0.89449\ttest-auc:0.87643\n",
      "[4020]\ttrain-auc:0.89453\ttest-auc:0.87645\n",
      "[4030]\ttrain-auc:0.89458\ttest-auc:0.87647\n",
      "[4040]\ttrain-auc:0.89463\ttest-auc:0.87647\n",
      "[4050]\ttrain-auc:0.89467\ttest-auc:0.87648\n",
      "[4060]\ttrain-auc:0.89472\ttest-auc:0.87651\n",
      "[4070]\ttrain-auc:0.89477\ttest-auc:0.87654\n",
      "[4080]\ttrain-auc:0.89482\ttest-auc:0.87655\n",
      "[4090]\ttrain-auc:0.89485\ttest-auc:0.87655\n",
      "[4100]\ttrain-auc:0.89492\ttest-auc:0.87658\n",
      "[4110]\ttrain-auc:0.89496\ttest-auc:0.87661\n",
      "[4120]\ttrain-auc:0.89501\ttest-auc:0.87663\n",
      "[4130]\ttrain-auc:0.89506\ttest-auc:0.87666\n",
      "[4140]\ttrain-auc:0.89512\ttest-auc:0.87669\n",
      "[4150]\ttrain-auc:0.89515\ttest-auc:0.87670\n",
      "[4160]\ttrain-auc:0.89520\ttest-auc:0.87672\n",
      "[4170]\ttrain-auc:0.89527\ttest-auc:0.87677\n",
      "[4180]\ttrain-auc:0.89531\ttest-auc:0.87678\n",
      "[4190]\ttrain-auc:0.89536\ttest-auc:0.87680\n",
      "[4200]\ttrain-auc:0.89540\ttest-auc:0.87681\n",
      "[4210]\ttrain-auc:0.89543\ttest-auc:0.87681\n",
      "[4220]\ttrain-auc:0.89549\ttest-auc:0.87683\n",
      "[4230]\ttrain-auc:0.89553\ttest-auc:0.87685\n",
      "[4240]\ttrain-auc:0.89558\ttest-auc:0.87687\n",
      "[4250]\ttrain-auc:0.89562\ttest-auc:0.87688\n",
      "[4260]\ttrain-auc:0.89567\ttest-auc:0.87690\n",
      "[4270]\ttrain-auc:0.89571\ttest-auc:0.87691\n",
      "[4280]\ttrain-auc:0.89575\ttest-auc:0.87692\n",
      "[4290]\ttrain-auc:0.89579\ttest-auc:0.87694\n",
      "[4300]\ttrain-auc:0.89582\ttest-auc:0.87695\n",
      "[4310]\ttrain-auc:0.89586\ttest-auc:0.87696\n",
      "[4320]\ttrain-auc:0.89590\ttest-auc:0.87697\n",
      "[4330]\ttrain-auc:0.89595\ttest-auc:0.87700\n",
      "[4340]\ttrain-auc:0.89599\ttest-auc:0.87704\n",
      "[4350]\ttrain-auc:0.89604\ttest-auc:0.87705\n",
      "[4360]\ttrain-auc:0.89608\ttest-auc:0.87707\n",
      "[4370]\ttrain-auc:0.89612\ttest-auc:0.87708\n",
      "[4380]\ttrain-auc:0.89616\ttest-auc:0.87710\n",
      "[4390]\ttrain-auc:0.89622\ttest-auc:0.87711\n",
      "[4400]\ttrain-auc:0.89627\ttest-auc:0.87713\n",
      "[4410]\ttrain-auc:0.89631\ttest-auc:0.87717\n",
      "[4420]\ttrain-auc:0.89636\ttest-auc:0.87720\n",
      "[4430]\ttrain-auc:0.89639\ttest-auc:0.87721\n",
      "[4440]\ttrain-auc:0.89643\ttest-auc:0.87723\n",
      "[4450]\ttrain-auc:0.89648\ttest-auc:0.87725\n",
      "[4460]\ttrain-auc:0.89653\ttest-auc:0.87726\n",
      "[4470]\ttrain-auc:0.89657\ttest-auc:0.87727\n",
      "[4480]\ttrain-auc:0.89661\ttest-auc:0.87728\n",
      "[4490]\ttrain-auc:0.89663\ttest-auc:0.87730\n",
      "[4500]\ttrain-auc:0.89667\ttest-auc:0.87731\n",
      "[4510]\ttrain-auc:0.89672\ttest-auc:0.87731\n",
      "[4520]\ttrain-auc:0.89677\ttest-auc:0.87732\n",
      "[4530]\ttrain-auc:0.89680\ttest-auc:0.87733\n",
      "[4540]\ttrain-auc:0.89686\ttest-auc:0.87738\n",
      "[4550]\ttrain-auc:0.89690\ttest-auc:0.87739\n",
      "[4560]\ttrain-auc:0.89695\ttest-auc:0.87742\n",
      "[4570]\ttrain-auc:0.89699\ttest-auc:0.87743\n",
      "[4580]\ttrain-auc:0.89704\ttest-auc:0.87747\n",
      "[4590]\ttrain-auc:0.89708\ttest-auc:0.87747\n",
      "[4600]\ttrain-auc:0.89713\ttest-auc:0.87748\n",
      "[4610]\ttrain-auc:0.89718\ttest-auc:0.87751\n",
      "[4620]\ttrain-auc:0.89723\ttest-auc:0.87753\n",
      "[4630]\ttrain-auc:0.89727\ttest-auc:0.87755\n",
      "[4640]\ttrain-auc:0.89730\ttest-auc:0.87754\n",
      "[4650]\ttrain-auc:0.89735\ttest-auc:0.87756\n",
      "[4660]\ttrain-auc:0.89740\ttest-auc:0.87760\n",
      "[4670]\ttrain-auc:0.89745\ttest-auc:0.87762\n",
      "[4680]\ttrain-auc:0.89749\ttest-auc:0.87764\n",
      "[4690]\ttrain-auc:0.89753\ttest-auc:0.87765\n",
      "[4700]\ttrain-auc:0.89757\ttest-auc:0.87766\n",
      "[4710]\ttrain-auc:0.89763\ttest-auc:0.87771\n",
      "[4720]\ttrain-auc:0.89766\ttest-auc:0.87772\n",
      "[4730]\ttrain-auc:0.89769\ttest-auc:0.87773\n",
      "[4740]\ttrain-auc:0.89775\ttest-auc:0.87777\n",
      "[4750]\ttrain-auc:0.89779\ttest-auc:0.87778\n",
      "[4760]\ttrain-auc:0.89783\ttest-auc:0.87780\n",
      "[4770]\ttrain-auc:0.89787\ttest-auc:0.87780\n",
      "[4780]\ttrain-auc:0.89791\ttest-auc:0.87782\n",
      "[4790]\ttrain-auc:0.89796\ttest-auc:0.87783\n",
      "[4800]\ttrain-auc:0.89800\ttest-auc:0.87784\n",
      "[4810]\ttrain-auc:0.89804\ttest-auc:0.87784\n",
      "[4820]\ttrain-auc:0.89808\ttest-auc:0.87786\n",
      "[4830]\ttrain-auc:0.89813\ttest-auc:0.87787\n",
      "[4840]\ttrain-auc:0.89816\ttest-auc:0.87788\n",
      "[4850]\ttrain-auc:0.89821\ttest-auc:0.87790\n",
      "[4860]\ttrain-auc:0.89826\ttest-auc:0.87792\n",
      "[4870]\ttrain-auc:0.89831\ttest-auc:0.87794\n",
      "[4880]\ttrain-auc:0.89835\ttest-auc:0.87795\n",
      "[4890]\ttrain-auc:0.89839\ttest-auc:0.87796\n",
      "[4900]\ttrain-auc:0.89842\ttest-auc:0.87797\n",
      "[4910]\ttrain-auc:0.89847\ttest-auc:0.87800\n",
      "[4920]\ttrain-auc:0.89851\ttest-auc:0.87801\n",
      "[4930]\ttrain-auc:0.89855\ttest-auc:0.87804\n",
      "[4940]\ttrain-auc:0.89860\ttest-auc:0.87806\n",
      "[4950]\ttrain-auc:0.89865\ttest-auc:0.87809\n",
      "[4960]\ttrain-auc:0.89869\ttest-auc:0.87810\n",
      "[4970]\ttrain-auc:0.89873\ttest-auc:0.87812\n",
      "[4980]\ttrain-auc:0.89877\ttest-auc:0.87813\n",
      "[4990]\ttrain-auc:0.89881\ttest-auc:0.87812\n",
      "[5000]\ttrain-auc:0.89885\ttest-auc:0.87813\n",
      "[5010]\ttrain-auc:0.89888\ttest-auc:0.87812\n",
      "[5020]\ttrain-auc:0.89893\ttest-auc:0.87815\n",
      "[5030]\ttrain-auc:0.89897\ttest-auc:0.87816\n",
      "[5040]\ttrain-auc:0.89902\ttest-auc:0.87817\n",
      "[5050]\ttrain-auc:0.89907\ttest-auc:0.87819\n",
      "[5060]\ttrain-auc:0.89911\ttest-auc:0.87820\n",
      "[5070]\ttrain-auc:0.89915\ttest-auc:0.87821\n",
      "[5080]\ttrain-auc:0.89919\ttest-auc:0.87822\n",
      "[5090]\ttrain-auc:0.89923\ttest-auc:0.87826\n",
      "[5100]\ttrain-auc:0.89926\ttest-auc:0.87826\n",
      "[5110]\ttrain-auc:0.89930\ttest-auc:0.87829\n",
      "[5120]\ttrain-auc:0.89934\ttest-auc:0.87831\n",
      "[5130]\ttrain-auc:0.89938\ttest-auc:0.87833\n",
      "[5140]\ttrain-auc:0.89940\ttest-auc:0.87834\n",
      "[5150]\ttrain-auc:0.89945\ttest-auc:0.87836\n",
      "[5160]\ttrain-auc:0.89948\ttest-auc:0.87835\n",
      "[5170]\ttrain-auc:0.89952\ttest-auc:0.87837\n",
      "[5180]\ttrain-auc:0.89956\ttest-auc:0.87838\n",
      "[5190]\ttrain-auc:0.89960\ttest-auc:0.87839\n",
      "[5200]\ttrain-auc:0.89963\ttest-auc:0.87841\n",
      "[5210]\ttrain-auc:0.89967\ttest-auc:0.87843\n",
      "[5220]\ttrain-auc:0.89971\ttest-auc:0.87844\n",
      "[5230]\ttrain-auc:0.89975\ttest-auc:0.87844\n",
      "[5240]\ttrain-auc:0.89979\ttest-auc:0.87846\n",
      "[5250]\ttrain-auc:0.89983\ttest-auc:0.87848\n",
      "[5260]\ttrain-auc:0.89986\ttest-auc:0.87847\n",
      "[5270]\ttrain-auc:0.89990\ttest-auc:0.87848\n",
      "[5280]\ttrain-auc:0.89994\ttest-auc:0.87850\n",
      "[5290]\ttrain-auc:0.89998\ttest-auc:0.87852\n",
      "[5300]\ttrain-auc:0.90001\ttest-auc:0.87854\n",
      "[5310]\ttrain-auc:0.90004\ttest-auc:0.87855\n",
      "[5320]\ttrain-auc:0.90009\ttest-auc:0.87856\n",
      "[5330]\ttrain-auc:0.90012\ttest-auc:0.87856\n",
      "[5340]\ttrain-auc:0.90015\ttest-auc:0.87856\n",
      "[5350]\ttrain-auc:0.90019\ttest-auc:0.87858\n",
      "[5360]\ttrain-auc:0.90023\ttest-auc:0.87858\n",
      "[5370]\ttrain-auc:0.90027\ttest-auc:0.87860\n",
      "[5380]\ttrain-auc:0.90032\ttest-auc:0.87861\n",
      "[5390]\ttrain-auc:0.90037\ttest-auc:0.87862\n",
      "[5400]\ttrain-auc:0.90039\ttest-auc:0.87862\n",
      "[5410]\ttrain-auc:0.90043\ttest-auc:0.87864\n",
      "[5420]\ttrain-auc:0.90047\ttest-auc:0.87865\n",
      "[5430]\ttrain-auc:0.90050\ttest-auc:0.87866\n",
      "[5440]\ttrain-auc:0.90054\ttest-auc:0.87867\n",
      "[5450]\ttrain-auc:0.90058\ttest-auc:0.87870\n",
      "[5460]\ttrain-auc:0.90062\ttest-auc:0.87872\n",
      "[5470]\ttrain-auc:0.90066\ttest-auc:0.87874\n",
      "[5480]\ttrain-auc:0.90069\ttest-auc:0.87876\n",
      "[5490]\ttrain-auc:0.90072\ttest-auc:0.87877\n",
      "[5500]\ttrain-auc:0.90078\ttest-auc:0.87880\n",
      "[5510]\ttrain-auc:0.90080\ttest-auc:0.87882\n",
      "[5520]\ttrain-auc:0.90083\ttest-auc:0.87883\n",
      "[5530]\ttrain-auc:0.90087\ttest-auc:0.87884\n",
      "[5540]\ttrain-auc:0.90090\ttest-auc:0.87885\n",
      "[5550]\ttrain-auc:0.90093\ttest-auc:0.87886\n",
      "[5560]\ttrain-auc:0.90097\ttest-auc:0.87885\n",
      "[5570]\ttrain-auc:0.90101\ttest-auc:0.87887\n",
      "[5580]\ttrain-auc:0.90105\ttest-auc:0.87889\n",
      "[5590]\ttrain-auc:0.90107\ttest-auc:0.87889\n",
      "[5600]\ttrain-auc:0.90111\ttest-auc:0.87889\n",
      "[5610]\ttrain-auc:0.90116\ttest-auc:0.87890\n",
      "[5620]\ttrain-auc:0.90119\ttest-auc:0.87890\n",
      "[5630]\ttrain-auc:0.90123\ttest-auc:0.87891\n",
      "[5640]\ttrain-auc:0.90126\ttest-auc:0.87892\n",
      "[5650]\ttrain-auc:0.90129\ttest-auc:0.87893\n",
      "[5660]\ttrain-auc:0.90133\ttest-auc:0.87894\n",
      "[5670]\ttrain-auc:0.90136\ttest-auc:0.87894\n",
      "[5680]\ttrain-auc:0.90140\ttest-auc:0.87896\n",
      "[5690]\ttrain-auc:0.90143\ttest-auc:0.87898\n",
      "[5700]\ttrain-auc:0.90147\ttest-auc:0.87900\n",
      "[5710]\ttrain-auc:0.90149\ttest-auc:0.87901\n",
      "[5720]\ttrain-auc:0.90153\ttest-auc:0.87901\n",
      "[5730]\ttrain-auc:0.90157\ttest-auc:0.87902\n",
      "[5740]\ttrain-auc:0.90160\ttest-auc:0.87904\n",
      "[5750]\ttrain-auc:0.90164\ttest-auc:0.87904\n",
      "[5760]\ttrain-auc:0.90169\ttest-auc:0.87907\n",
      "[5770]\ttrain-auc:0.90172\ttest-auc:0.87909\n",
      "[5780]\ttrain-auc:0.90176\ttest-auc:0.87912\n",
      "[5790]\ttrain-auc:0.90179\ttest-auc:0.87913\n",
      "[5800]\ttrain-auc:0.90183\ttest-auc:0.87914\n",
      "[5810]\ttrain-auc:0.90186\ttest-auc:0.87914\n",
      "[5820]\ttrain-auc:0.90190\ttest-auc:0.87917\n",
      "[5830]\ttrain-auc:0.90195\ttest-auc:0.87921\n",
      "[5840]\ttrain-auc:0.90198\ttest-auc:0.87921\n",
      "[5850]\ttrain-auc:0.90202\ttest-auc:0.87922\n",
      "[5860]\ttrain-auc:0.90205\ttest-auc:0.87923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5870]\ttrain-auc:0.90208\ttest-auc:0.87925\n",
      "[5880]\ttrain-auc:0.90212\ttest-auc:0.87927\n",
      "[5890]\ttrain-auc:0.90216\ttest-auc:0.87928\n",
      "[5900]\ttrain-auc:0.90220\ttest-auc:0.87929\n",
      "[5910]\ttrain-auc:0.90223\ttest-auc:0.87931\n",
      "[5920]\ttrain-auc:0.90227\ttest-auc:0.87933\n",
      "[5930]\ttrain-auc:0.90230\ttest-auc:0.87934\n",
      "[5940]\ttrain-auc:0.90234\ttest-auc:0.87934\n",
      "[5950]\ttrain-auc:0.90237\ttest-auc:0.87935\n",
      "[5960]\ttrain-auc:0.90241\ttest-auc:0.87937\n",
      "[5970]\ttrain-auc:0.90244\ttest-auc:0.87938\n",
      "[5980]\ttrain-auc:0.90247\ttest-auc:0.87939\n",
      "[5990]\ttrain-auc:0.90250\ttest-auc:0.87940\n",
      "[6000]\ttrain-auc:0.90255\ttest-auc:0.87943\n",
      "[6010]\ttrain-auc:0.90259\ttest-auc:0.87944\n",
      "[6020]\ttrain-auc:0.90262\ttest-auc:0.87945\n",
      "[6030]\ttrain-auc:0.90266\ttest-auc:0.87945\n",
      "[6040]\ttrain-auc:0.90269\ttest-auc:0.87948\n",
      "[6050]\ttrain-auc:0.90272\ttest-auc:0.87949\n",
      "[6060]\ttrain-auc:0.90275\ttest-auc:0.87949\n",
      "[6070]\ttrain-auc:0.90277\ttest-auc:0.87949\n",
      "[6080]\ttrain-auc:0.90280\ttest-auc:0.87950\n",
      "[6090]\ttrain-auc:0.90284\ttest-auc:0.87951\n",
      "[6100]\ttrain-auc:0.90287\ttest-auc:0.87952\n",
      "[6110]\ttrain-auc:0.90291\ttest-auc:0.87952\n",
      "[6120]\ttrain-auc:0.90295\ttest-auc:0.87954\n",
      "[6130]\ttrain-auc:0.90298\ttest-auc:0.87957\n",
      "[6140]\ttrain-auc:0.90302\ttest-auc:0.87957\n",
      "[6150]\ttrain-auc:0.90306\ttest-auc:0.87958\n",
      "[6160]\ttrain-auc:0.90309\ttest-auc:0.87960\n",
      "[6170]\ttrain-auc:0.90313\ttest-auc:0.87961\n",
      "[6180]\ttrain-auc:0.90317\ttest-auc:0.87962\n",
      "[6190]\ttrain-auc:0.90321\ttest-auc:0.87963\n",
      "[6200]\ttrain-auc:0.90325\ttest-auc:0.87964\n",
      "[6210]\ttrain-auc:0.90328\ttest-auc:0.87965\n",
      "[6220]\ttrain-auc:0.90332\ttest-auc:0.87966\n",
      "[6230]\ttrain-auc:0.90335\ttest-auc:0.87968\n",
      "[6240]\ttrain-auc:0.90339\ttest-auc:0.87969\n",
      "[6250]\ttrain-auc:0.90342\ttest-auc:0.87971\n",
      "[6260]\ttrain-auc:0.90346\ttest-auc:0.87971\n",
      "[6270]\ttrain-auc:0.90350\ttest-auc:0.87972\n",
      "[6280]\ttrain-auc:0.90353\ttest-auc:0.87972\n",
      "[6290]\ttrain-auc:0.90356\ttest-auc:0.87974\n",
      "[6300]\ttrain-auc:0.90360\ttest-auc:0.87975\n",
      "[6310]\ttrain-auc:0.90362\ttest-auc:0.87975\n",
      "[6320]\ttrain-auc:0.90366\ttest-auc:0.87976\n",
      "[6330]\ttrain-auc:0.90370\ttest-auc:0.87976\n",
      "[6340]\ttrain-auc:0.90373\ttest-auc:0.87978\n",
      "[6350]\ttrain-auc:0.90376\ttest-auc:0.87978\n",
      "[6360]\ttrain-auc:0.90379\ttest-auc:0.87980\n",
      "[6370]\ttrain-auc:0.90382\ttest-auc:0.87981\n",
      "[6380]\ttrain-auc:0.90385\ttest-auc:0.87983\n",
      "[6390]\ttrain-auc:0.90388\ttest-auc:0.87983\n",
      "[6400]\ttrain-auc:0.90392\ttest-auc:0.87985\n",
      "[6410]\ttrain-auc:0.90395\ttest-auc:0.87986\n",
      "[6420]\ttrain-auc:0.90398\ttest-auc:0.87985\n",
      "[6430]\ttrain-auc:0.90402\ttest-auc:0.87986\n",
      "[6440]\ttrain-auc:0.90405\ttest-auc:0.87987\n",
      "[6450]\ttrain-auc:0.90409\ttest-auc:0.87989\n",
      "[6460]\ttrain-auc:0.90411\ttest-auc:0.87990\n",
      "[6470]\ttrain-auc:0.90414\ttest-auc:0.87990\n",
      "[6480]\ttrain-auc:0.90418\ttest-auc:0.87992\n",
      "[6490]\ttrain-auc:0.90421\ttest-auc:0.87994\n",
      "[6500]\ttrain-auc:0.90425\ttest-auc:0.87994\n",
      "[6510]\ttrain-auc:0.90428\ttest-auc:0.87995\n",
      "[6520]\ttrain-auc:0.90431\ttest-auc:0.87996\n",
      "[6530]\ttrain-auc:0.90436\ttest-auc:0.87999\n",
      "[6540]\ttrain-auc:0.90441\ttest-auc:0.88002\n",
      "[6550]\ttrain-auc:0.90444\ttest-auc:0.88002\n",
      "[6560]\ttrain-auc:0.90447\ttest-auc:0.88002\n",
      "[6570]\ttrain-auc:0.90450\ttest-auc:0.88002\n",
      "[6580]\ttrain-auc:0.90454\ttest-auc:0.88004\n",
      "[6590]\ttrain-auc:0.90457\ttest-auc:0.88005\n",
      "[6600]\ttrain-auc:0.90460\ttest-auc:0.88007\n",
      "[6610]\ttrain-auc:0.90464\ttest-auc:0.88008\n",
      "[6620]\ttrain-auc:0.90468\ttest-auc:0.88009\n",
      "[6630]\ttrain-auc:0.90471\ttest-auc:0.88010\n",
      "[6640]\ttrain-auc:0.90475\ttest-auc:0.88011\n",
      "[6650]\ttrain-auc:0.90478\ttest-auc:0.88012\n",
      "[6660]\ttrain-auc:0.90482\ttest-auc:0.88013\n",
      "[6670]\ttrain-auc:0.90484\ttest-auc:0.88014\n",
      "[6680]\ttrain-auc:0.90487\ttest-auc:0.88015\n",
      "[6690]\ttrain-auc:0.90494\ttest-auc:0.88018\n",
      "[6700]\ttrain-auc:0.90497\ttest-auc:0.88020\n",
      "[6710]\ttrain-auc:0.90501\ttest-auc:0.88022\n",
      "[6720]\ttrain-auc:0.90505\ttest-auc:0.88023\n",
      "[6730]\ttrain-auc:0.90510\ttest-auc:0.88027\n",
      "[6740]\ttrain-auc:0.90513\ttest-auc:0.88028\n",
      "[6750]\ttrain-auc:0.90517\ttest-auc:0.88030\n",
      "[6760]\ttrain-auc:0.90521\ttest-auc:0.88031\n",
      "[6770]\ttrain-auc:0.90524\ttest-auc:0.88032\n",
      "[6780]\ttrain-auc:0.90527\ttest-auc:0.88032\n",
      "[6790]\ttrain-auc:0.90530\ttest-auc:0.88035\n",
      "[6800]\ttrain-auc:0.90534\ttest-auc:0.88036\n",
      "[6810]\ttrain-auc:0.90538\ttest-auc:0.88039\n",
      "[6820]\ttrain-auc:0.90541\ttest-auc:0.88041\n",
      "[6830]\ttrain-auc:0.90545\ttest-auc:0.88042\n",
      "[6840]\ttrain-auc:0.90549\ttest-auc:0.88043\n",
      "[6850]\ttrain-auc:0.90552\ttest-auc:0.88042\n",
      "[6860]\ttrain-auc:0.90555\ttest-auc:0.88042\n",
      "[6870]\ttrain-auc:0.90559\ttest-auc:0.88045\n",
      "[6880]\ttrain-auc:0.90562\ttest-auc:0.88047\n",
      "[6890]\ttrain-auc:0.90564\ttest-auc:0.88048\n",
      "[6900]\ttrain-auc:0.90567\ttest-auc:0.88049\n",
      "[6910]\ttrain-auc:0.90571\ttest-auc:0.88050\n",
      "[6920]\ttrain-auc:0.90573\ttest-auc:0.88050\n",
      "[6930]\ttrain-auc:0.90578\ttest-auc:0.88051\n",
      "[6940]\ttrain-auc:0.90582\ttest-auc:0.88053\n",
      "[6950]\ttrain-auc:0.90587\ttest-auc:0.88057\n",
      "[6960]\ttrain-auc:0.90590\ttest-auc:0.88058\n",
      "[6970]\ttrain-auc:0.90593\ttest-auc:0.88058\n",
      "[6980]\ttrain-auc:0.90596\ttest-auc:0.88060\n",
      "[6990]\ttrain-auc:0.90599\ttest-auc:0.88061\n",
      "[7000]\ttrain-auc:0.90603\ttest-auc:0.88062\n",
      "[7010]\ttrain-auc:0.90607\ttest-auc:0.88066\n",
      "[7020]\ttrain-auc:0.90610\ttest-auc:0.88067\n",
      "[7030]\ttrain-auc:0.90613\ttest-auc:0.88067\n",
      "[7040]\ttrain-auc:0.90616\ttest-auc:0.88068\n",
      "[7050]\ttrain-auc:0.90619\ttest-auc:0.88069\n",
      "[7060]\ttrain-auc:0.90622\ttest-auc:0.88070\n",
      "[7070]\ttrain-auc:0.90626\ttest-auc:0.88070\n",
      "[7080]\ttrain-auc:0.90629\ttest-auc:0.88071\n",
      "[7090]\ttrain-auc:0.90632\ttest-auc:0.88071\n",
      "[7100]\ttrain-auc:0.90635\ttest-auc:0.88072\n",
      "[7110]\ttrain-auc:0.90638\ttest-auc:0.88073\n",
      "[7120]\ttrain-auc:0.90641\ttest-auc:0.88074\n",
      "[7130]\ttrain-auc:0.90644\ttest-auc:0.88075\n",
      "[7140]\ttrain-auc:0.90649\ttest-auc:0.88078\n",
      "[7150]\ttrain-auc:0.90652\ttest-auc:0.88080\n",
      "[7160]\ttrain-auc:0.90655\ttest-auc:0.88082\n",
      "[7170]\ttrain-auc:0.90658\ttest-auc:0.88082\n",
      "[7180]\ttrain-auc:0.90662\ttest-auc:0.88083\n",
      "[7190]\ttrain-auc:0.90664\ttest-auc:0.88085\n",
      "[7200]\ttrain-auc:0.90667\ttest-auc:0.88086\n",
      "[7210]\ttrain-auc:0.90671\ttest-auc:0.88086\n",
      "[7220]\ttrain-auc:0.90674\ttest-auc:0.88088\n",
      "[7230]\ttrain-auc:0.90677\ttest-auc:0.88090\n",
      "[7240]\ttrain-auc:0.90680\ttest-auc:0.88091\n",
      "[7250]\ttrain-auc:0.90682\ttest-auc:0.88092\n",
      "[7260]\ttrain-auc:0.90685\ttest-auc:0.88093\n",
      "[7270]\ttrain-auc:0.90688\ttest-auc:0.88094\n",
      "[7280]\ttrain-auc:0.90691\ttest-auc:0.88094\n",
      "[7290]\ttrain-auc:0.90695\ttest-auc:0.88096\n",
      "[7300]\ttrain-auc:0.90698\ttest-auc:0.88097\n",
      "[7310]\ttrain-auc:0.90701\ttest-auc:0.88098\n",
      "[7320]\ttrain-auc:0.90704\ttest-auc:0.88098\n",
      "[7330]\ttrain-auc:0.90707\ttest-auc:0.88100\n",
      "[7340]\ttrain-auc:0.90710\ttest-auc:0.88101\n",
      "[7350]\ttrain-auc:0.90713\ttest-auc:0.88103\n",
      "[7360]\ttrain-auc:0.90716\ttest-auc:0.88104\n",
      "[7370]\ttrain-auc:0.90719\ttest-auc:0.88105\n",
      "[7380]\ttrain-auc:0.90722\ttest-auc:0.88106\n",
      "[7390]\ttrain-auc:0.90725\ttest-auc:0.88109\n",
      "[7400]\ttrain-auc:0.90729\ttest-auc:0.88109\n",
      "[7410]\ttrain-auc:0.90732\ttest-auc:0.88110\n",
      "[7420]\ttrain-auc:0.90736\ttest-auc:0.88111\n",
      "[7430]\ttrain-auc:0.90739\ttest-auc:0.88111\n",
      "[7440]\ttrain-auc:0.90742\ttest-auc:0.88113\n",
      "[7450]\ttrain-auc:0.90745\ttest-auc:0.88114\n",
      "[7460]\ttrain-auc:0.90748\ttest-auc:0.88114\n",
      "[7470]\ttrain-auc:0.90750\ttest-auc:0.88116\n",
      "[7480]\ttrain-auc:0.90753\ttest-auc:0.88116\n",
      "[7490]\ttrain-auc:0.90756\ttest-auc:0.88116\n",
      "[7500]\ttrain-auc:0.90760\ttest-auc:0.88116\n",
      "[7510]\ttrain-auc:0.90763\ttest-auc:0.88117\n",
      "[7520]\ttrain-auc:0.90766\ttest-auc:0.88119\n",
      "[7530]\ttrain-auc:0.90768\ttest-auc:0.88120\n",
      "[7540]\ttrain-auc:0.90771\ttest-auc:0.88122\n",
      "[7550]\ttrain-auc:0.90773\ttest-auc:0.88123\n",
      "[7560]\ttrain-auc:0.90777\ttest-auc:0.88124\n",
      "[7570]\ttrain-auc:0.90780\ttest-auc:0.88125\n",
      "[7580]\ttrain-auc:0.90783\ttest-auc:0.88127\n",
      "[7590]\ttrain-auc:0.90786\ttest-auc:0.88128\n",
      "[7600]\ttrain-auc:0.90788\ttest-auc:0.88129\n",
      "[7610]\ttrain-auc:0.90791\ttest-auc:0.88130\n",
      "[7620]\ttrain-auc:0.90793\ttest-auc:0.88130\n",
      "[7630]\ttrain-auc:0.90796\ttest-auc:0.88131\n",
      "[7640]\ttrain-auc:0.90799\ttest-auc:0.88131\n",
      "[7650]\ttrain-auc:0.90802\ttest-auc:0.88131\n",
      "[7660]\ttrain-auc:0.90804\ttest-auc:0.88131\n",
      "[7670]\ttrain-auc:0.90806\ttest-auc:0.88131\n",
      "[7680]\ttrain-auc:0.90808\ttest-auc:0.88132\n",
      "[7690]\ttrain-auc:0.90812\ttest-auc:0.88134\n",
      "[7700]\ttrain-auc:0.90815\ttest-auc:0.88135\n",
      "[7710]\ttrain-auc:0.90817\ttest-auc:0.88136\n",
      "[7720]\ttrain-auc:0.90820\ttest-auc:0.88136\n",
      "[7730]\ttrain-auc:0.90823\ttest-auc:0.88138\n",
      "[7740]\ttrain-auc:0.90825\ttest-auc:0.88137\n",
      "[7750]\ttrain-auc:0.90828\ttest-auc:0.88138\n",
      "[7760]\ttrain-auc:0.90831\ttest-auc:0.88139\n",
      "[7770]\ttrain-auc:0.90833\ttest-auc:0.88139\n",
      "[7780]\ttrain-auc:0.90836\ttest-auc:0.88140\n",
      "[7790]\ttrain-auc:0.90840\ttest-auc:0.88142\n",
      "[7800]\ttrain-auc:0.90843\ttest-auc:0.88143\n",
      "[7810]\ttrain-auc:0.90846\ttest-auc:0.88143\n",
      "[7820]\ttrain-auc:0.90849\ttest-auc:0.88144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7830]\ttrain-auc:0.90852\ttest-auc:0.88146\n",
      "[7840]\ttrain-auc:0.90855\ttest-auc:0.88147\n",
      "[7850]\ttrain-auc:0.90858\ttest-auc:0.88148\n",
      "[7860]\ttrain-auc:0.90860\ttest-auc:0.88149\n",
      "[7870]\ttrain-auc:0.90862\ttest-auc:0.88149\n",
      "[7880]\ttrain-auc:0.90865\ttest-auc:0.88150\n",
      "[7890]\ttrain-auc:0.90869\ttest-auc:0.88152\n",
      "[7900]\ttrain-auc:0.90872\ttest-auc:0.88153\n",
      "[7910]\ttrain-auc:0.90875\ttest-auc:0.88153\n",
      "[7920]\ttrain-auc:0.90878\ttest-auc:0.88156\n",
      "[7930]\ttrain-auc:0.90881\ttest-auc:0.88157\n",
      "[7940]\ttrain-auc:0.90883\ttest-auc:0.88158\n",
      "[7950]\ttrain-auc:0.90886\ttest-auc:0.88158\n",
      "[7960]\ttrain-auc:0.90889\ttest-auc:0.88159\n",
      "[7970]\ttrain-auc:0.90892\ttest-auc:0.88161\n",
      "[7980]\ttrain-auc:0.90895\ttest-auc:0.88163\n",
      "[7990]\ttrain-auc:0.90898\ttest-auc:0.88164\n",
      "[8000]\ttrain-auc:0.90901\ttest-auc:0.88164\n",
      "[8010]\ttrain-auc:0.90903\ttest-auc:0.88165\n",
      "[8020]\ttrain-auc:0.90906\ttest-auc:0.88167\n",
      "[8030]\ttrain-auc:0.90909\ttest-auc:0.88169\n",
      "[8040]\ttrain-auc:0.90911\ttest-auc:0.88170\n",
      "[8050]\ttrain-auc:0.90914\ttest-auc:0.88169\n",
      "[8060]\ttrain-auc:0.90916\ttest-auc:0.88169\n",
      "[8070]\ttrain-auc:0.90919\ttest-auc:0.88169\n",
      "[8080]\ttrain-auc:0.90921\ttest-auc:0.88170\n",
      "[8090]\ttrain-auc:0.90924\ttest-auc:0.88171\n",
      "[8100]\ttrain-auc:0.90928\ttest-auc:0.88172\n",
      "[8110]\ttrain-auc:0.90930\ttest-auc:0.88172\n",
      "[8120]\ttrain-auc:0.90933\ttest-auc:0.88172\n",
      "[8130]\ttrain-auc:0.90936\ttest-auc:0.88174\n",
      "[8140]\ttrain-auc:0.90939\ttest-auc:0.88174\n",
      "[8150]\ttrain-auc:0.90941\ttest-auc:0.88174\n",
      "[8160]\ttrain-auc:0.90944\ttest-auc:0.88175\n",
      "[8170]\ttrain-auc:0.90947\ttest-auc:0.88177\n",
      "[8180]\ttrain-auc:0.90950\ttest-auc:0.88177\n",
      "[8190]\ttrain-auc:0.90953\ttest-auc:0.88179\n",
      "[8200]\ttrain-auc:0.90955\ttest-auc:0.88179\n",
      "[8210]\ttrain-auc:0.90957\ttest-auc:0.88180\n",
      "[8220]\ttrain-auc:0.90960\ttest-auc:0.88181\n",
      "[8230]\ttrain-auc:0.90963\ttest-auc:0.88182\n",
      "[8240]\ttrain-auc:0.90966\ttest-auc:0.88184\n",
      "[8250]\ttrain-auc:0.90969\ttest-auc:0.88186\n",
      "[8260]\ttrain-auc:0.90972\ttest-auc:0.88187\n",
      "[8270]\ttrain-auc:0.90975\ttest-auc:0.88187\n",
      "[8280]\ttrain-auc:0.90978\ttest-auc:0.88187\n",
      "[8290]\ttrain-auc:0.90981\ttest-auc:0.88188\n",
      "[8300]\ttrain-auc:0.90983\ttest-auc:0.88188\n",
      "[8310]\ttrain-auc:0.90986\ttest-auc:0.88189\n",
      "[8320]\ttrain-auc:0.90988\ttest-auc:0.88190\n",
      "[8330]\ttrain-auc:0.90991\ttest-auc:0.88191\n",
      "[8340]\ttrain-auc:0.90993\ttest-auc:0.88192\n",
      "[8350]\ttrain-auc:0.90997\ttest-auc:0.88194\n",
      "[8360]\ttrain-auc:0.91000\ttest-auc:0.88194\n",
      "[8370]\ttrain-auc:0.91002\ttest-auc:0.88195\n",
      "[8380]\ttrain-auc:0.91005\ttest-auc:0.88195\n",
      "[8390]\ttrain-auc:0.91008\ttest-auc:0.88196\n",
      "[8400]\ttrain-auc:0.91011\ttest-auc:0.88197\n",
      "[8410]\ttrain-auc:0.91014\ttest-auc:0.88199\n",
      "[8420]\ttrain-auc:0.91017\ttest-auc:0.88199\n",
      "[8430]\ttrain-auc:0.91019\ttest-auc:0.88200\n",
      "[8440]\ttrain-auc:0.91021\ttest-auc:0.88201\n",
      "[8450]\ttrain-auc:0.91024\ttest-auc:0.88201\n",
      "[8460]\ttrain-auc:0.91026\ttest-auc:0.88203\n",
      "[8470]\ttrain-auc:0.91029\ttest-auc:0.88204\n",
      "[8480]\ttrain-auc:0.91033\ttest-auc:0.88205\n",
      "[8490]\ttrain-auc:0.91035\ttest-auc:0.88206\n",
      "[8500]\ttrain-auc:0.91038\ttest-auc:0.88207\n",
      "[8510]\ttrain-auc:0.91041\ttest-auc:0.88207\n",
      "[8520]\ttrain-auc:0.91043\ttest-auc:0.88208\n",
      "[8530]\ttrain-auc:0.91046\ttest-auc:0.88207\n",
      "[8540]\ttrain-auc:0.91048\ttest-auc:0.88208\n",
      "[8550]\ttrain-auc:0.91051\ttest-auc:0.88208\n",
      "[8560]\ttrain-auc:0.91053\ttest-auc:0.88209\n",
      "[8570]\ttrain-auc:0.91056\ttest-auc:0.88209\n",
      "[8580]\ttrain-auc:0.91058\ttest-auc:0.88210\n",
      "[8590]\ttrain-auc:0.91061\ttest-auc:0.88212\n",
      "[8600]\ttrain-auc:0.91063\ttest-auc:0.88212\n",
      "[8610]\ttrain-auc:0.91065\ttest-auc:0.88213\n",
      "[8620]\ttrain-auc:0.91068\ttest-auc:0.88214\n",
      "[8630]\ttrain-auc:0.91071\ttest-auc:0.88215\n",
      "[8640]\ttrain-auc:0.91073\ttest-auc:0.88216\n",
      "[8650]\ttrain-auc:0.91077\ttest-auc:0.88218\n",
      "[8660]\ttrain-auc:0.91079\ttest-auc:0.88219\n",
      "[8670]\ttrain-auc:0.91081\ttest-auc:0.88219\n",
      "[8680]\ttrain-auc:0.91084\ttest-auc:0.88221\n",
      "[8690]\ttrain-auc:0.91086\ttest-auc:0.88221\n",
      "[8700]\ttrain-auc:0.91089\ttest-auc:0.88221\n",
      "[8710]\ttrain-auc:0.91091\ttest-auc:0.88222\n",
      "[8720]\ttrain-auc:0.91094\ttest-auc:0.88222\n",
      "[8730]\ttrain-auc:0.91097\ttest-auc:0.88222\n",
      "[8740]\ttrain-auc:0.91099\ttest-auc:0.88224\n",
      "[8750]\ttrain-auc:0.91102\ttest-auc:0.88224\n",
      "[8760]\ttrain-auc:0.91105\ttest-auc:0.88226\n",
      "[8770]\ttrain-auc:0.91107\ttest-auc:0.88226\n",
      "[8780]\ttrain-auc:0.91110\ttest-auc:0.88227\n",
      "[8790]\ttrain-auc:0.91113\ttest-auc:0.88228\n",
      "[8800]\ttrain-auc:0.91116\ttest-auc:0.88229\n",
      "[8810]\ttrain-auc:0.91119\ttest-auc:0.88229\n",
      "[8820]\ttrain-auc:0.91122\ttest-auc:0.88231\n",
      "[8830]\ttrain-auc:0.91126\ttest-auc:0.88233\n",
      "[8840]\ttrain-auc:0.91129\ttest-auc:0.88233\n",
      "[8850]\ttrain-auc:0.91131\ttest-auc:0.88234\n",
      "[8860]\ttrain-auc:0.91134\ttest-auc:0.88234\n",
      "[8870]\ttrain-auc:0.91136\ttest-auc:0.88235\n",
      "[8880]\ttrain-auc:0.91139\ttest-auc:0.88235\n",
      "[8890]\ttrain-auc:0.91142\ttest-auc:0.88236\n",
      "[8900]\ttrain-auc:0.91144\ttest-auc:0.88235\n",
      "[8910]\ttrain-auc:0.91147\ttest-auc:0.88235\n",
      "[8920]\ttrain-auc:0.91150\ttest-auc:0.88237\n",
      "[8930]\ttrain-auc:0.91153\ttest-auc:0.88238\n",
      "[8940]\ttrain-auc:0.91155\ttest-auc:0.88239\n",
      "[8950]\ttrain-auc:0.91159\ttest-auc:0.88241\n",
      "[8960]\ttrain-auc:0.91161\ttest-auc:0.88241\n",
      "[8970]\ttrain-auc:0.91164\ttest-auc:0.88242\n",
      "[8980]\ttrain-auc:0.91167\ttest-auc:0.88244\n",
      "[8990]\ttrain-auc:0.91169\ttest-auc:0.88245\n",
      "[9000]\ttrain-auc:0.91172\ttest-auc:0.88245\n",
      "[9010]\ttrain-auc:0.91174\ttest-auc:0.88246\n",
      "[9020]\ttrain-auc:0.91177\ttest-auc:0.88248\n",
      "[9030]\ttrain-auc:0.91179\ttest-auc:0.88248\n",
      "[9040]\ttrain-auc:0.91182\ttest-auc:0.88248\n",
      "[9050]\ttrain-auc:0.91184\ttest-auc:0.88249\n",
      "[9060]\ttrain-auc:0.91187\ttest-auc:0.88250\n",
      "[9070]\ttrain-auc:0.91189\ttest-auc:0.88250\n",
      "[9080]\ttrain-auc:0.91192\ttest-auc:0.88252\n",
      "[9090]\ttrain-auc:0.91195\ttest-auc:0.88253\n",
      "[9100]\ttrain-auc:0.91198\ttest-auc:0.88255\n",
      "[9110]\ttrain-auc:0.91200\ttest-auc:0.88256\n",
      "[9120]\ttrain-auc:0.91203\ttest-auc:0.88257\n",
      "[9130]\ttrain-auc:0.91205\ttest-auc:0.88257\n",
      "[9140]\ttrain-auc:0.91207\ttest-auc:0.88257\n",
      "[9150]\ttrain-auc:0.91210\ttest-auc:0.88258\n",
      "[9160]\ttrain-auc:0.91214\ttest-auc:0.88260\n",
      "[9170]\ttrain-auc:0.91217\ttest-auc:0.88260\n",
      "[9180]\ttrain-auc:0.91219\ttest-auc:0.88261\n",
      "[9190]\ttrain-auc:0.91222\ttest-auc:0.88261\n",
      "[9200]\ttrain-auc:0.91224\ttest-auc:0.88262\n",
      "[9210]\ttrain-auc:0.91227\ttest-auc:0.88264\n",
      "[9220]\ttrain-auc:0.91230\ttest-auc:0.88265\n",
      "[9230]\ttrain-auc:0.91232\ttest-auc:0.88267\n",
      "[9240]\ttrain-auc:0.91234\ttest-auc:0.88267\n",
      "[9250]\ttrain-auc:0.91238\ttest-auc:0.88268\n",
      "[9260]\ttrain-auc:0.91239\ttest-auc:0.88269\n",
      "[9270]\ttrain-auc:0.91242\ttest-auc:0.88270\n",
      "[9280]\ttrain-auc:0.91244\ttest-auc:0.88270\n",
      "[9290]\ttrain-auc:0.91246\ttest-auc:0.88271\n",
      "[9300]\ttrain-auc:0.91248\ttest-auc:0.88271\n",
      "[9310]\ttrain-auc:0.91251\ttest-auc:0.88272\n",
      "[9320]\ttrain-auc:0.91253\ttest-auc:0.88272\n",
      "[9330]\ttrain-auc:0.91256\ttest-auc:0.88275\n",
      "[9340]\ttrain-auc:0.91258\ttest-auc:0.88276\n",
      "[9350]\ttrain-auc:0.91260\ttest-auc:0.88276\n",
      "[9360]\ttrain-auc:0.91263\ttest-auc:0.88275\n",
      "[9370]\ttrain-auc:0.91265\ttest-auc:0.88275\n",
      "[9380]\ttrain-auc:0.91267\ttest-auc:0.88275\n",
      "[9390]\ttrain-auc:0.91269\ttest-auc:0.88275\n",
      "[9400]\ttrain-auc:0.91272\ttest-auc:0.88274\n",
      "Stopping. Best iteration:\n",
      "[9351]\ttrain-auc:0.91261\ttest-auc:0.88276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "params = {}\n",
    "params['objective'] = 'binary:logistic'\n",
    "params['eval_metric'] = 'auc'\n",
    "params['eta'] = 0.02\n",
    "params['max_depth'] = 4\n",
    "\n",
    "d_train = xgb.DMatrix(new_X_tr_q1q2, label=train_labels)\n",
    "d_test = xgb.DMatrix(new_X_te_q1q2, label=test_labels)\n",
    "\n",
    "evallist = [(d_train, 'train'), (d_test, 'test')]\n",
    "\n",
    "num_iters = 50000\n",
    "\n",
    "xgb_tfidf = xgb.train(params, d_train, num_iters, evallist, early_stopping_rounds=50, verbose_eval=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#store xgboost\n",
    "# open a file, where you ant to store the data\n",
    "file = open('xgb_tfidf', 'wb')\n",
    "# dump information to that file\n",
    "pickle.dump(xgb_tfidf, file)\n",
    "# close the file\n",
    "file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to load xgboost\n",
    "\n",
    "# open a file, where you stored the pickled data\n",
    "file = open('xgb_tfidf', 'rb')\n",
    "# dump information to that file\n",
    "xgb_tfidf = pickle.load(file)\n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training:  0.8425562029351948\n",
      "Accuracy on test:  0.832148157308929\n",
      "Neuroscience: Which regions of the brain are responsible for pain?\n",
      "Neuroscience: Which regions of the brain are responsible for sadness?\n",
      "true class: 0\n",
      "prediction: 1\n"
     ]
    }
   ],
   "source": [
    "d_train = xgb.DMatrix(new_X_tr_q1q2, label=train_labels)\n",
    "d_test = xgb.DMatrix(new_X_te_q1q2, label=test_labels)\n",
    "\n",
    "pred_test = xgb_tfidf.predict(d_test).round(0).astype(int)\n",
    "pred_train = xgb_tfidf.predict(d_train).round(0).astype(int)\n",
    "\n",
    "print(\"Accuracy on training: \", np.sum(train_labels==pred_train)/len(train_labels))\n",
    "print(\"Accuracy on test: \", np.sum(test_labels ==pred_test)/len(test_labels))\n",
    "\n",
    "mistake_indices, predictions = get_mistakes(xgb_tfidf, d_train, train_labels)\n",
    "print_mistake_k(4, mistake_indices, predictions)      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOURTH MODEL: DIFFERENT APPROACH WITH DEEP LEARNING\n",
    "\n",
    "Our main objective for this deliverable was to work with a more classic approach for natural language processing, mainly to implement and understand the CountVectorizer and TfIdfVectorizer. Additionally, we tried to work on the mistakes and limitations that this approach had, hence having to do a bit of feature engeenireing to tackle those problems.\n",
    "\n",
    "However, nowadays deep learning is used practically to solve anything, so, how well could it work to solve this problem? In this section we explore a completely different approach using deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAST BUT NOT LEAST: LET'S DO PIPELINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To pass data from CountVectorizer to model automatically, we need to transform the data first. This is just a hacky way to do it. \n",
    "\n",
    "Note that the correct way is to modify the CountVectorized that we implemented so that the output of the  transform is already the desired matrix (i.e. doing the hstack inside). We tried to implement the most general CountVectorized that we could, so we have to resort to this way. It is in no way slower in terms of speed. It is just ugly in the sense that is doing something hack-ish. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiddleTransformer(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        nexamples, nvars = X.shape\n",
    "        split = (int)(nexamples/2)\n",
    "        XX1 = X[:split,:]\n",
    "        XX2 = X[split:,:]\n",
    "        XX = sparse.hstack([XX1, XX2], format='csr')\n",
    "        return XX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cv = Pipeline([\n",
    "    ('countVectorizer', cv(#token_cleaner_func = lambda doc: WordNetLemmatizer().lemmatize(doc,pos=\"v\"),\n",
    "                     stop_words = set(stopwords.words('english')),\n",
    "                     ngram_range=(1,3))),\n",
    "    ('middleTransformer', MiddleTransformer()),\n",
    "    ('model', sklearn.linear_model.LogisticRegression(solver=\"liblinear\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('countVectorizer', CountVectorizer(doc_cleaner_pattern=\"('\\\\w+)\", document_cleaner_func=None,\n",
       "        dtype=<class 'numpy.float32'>, max_df=1.0, min_df=1,\n",
       "        min_word_counts=1, ngram_range=(1, 3),\n",
       "        stop_words={'them', 'an', 'herself', 'but', 'd', 'some', 'had', 'yours', \"isn't\", ...ty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cv.fit(all_questions, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_questions_test = q1_test+q2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7778368046218165"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.roc_auc_score(test_labels, model_cv.predict(all_questions_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Pipeline Great Again: GridSearch Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select samples to cross validate, we need the samples to be in pair with the labels. Right now we dont have that, so we are going to (once again) hack our way through it.\n",
    "\n",
    "Again note that the correct way to do it is to modify the CountVectorizer so that it automatically does this process inside the fit and transform functions. But following our filosophy of having a general CountVectorizer, this is a good way to solve the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndocs = (int)(len(all_questions)/2)\n",
    "all_questions_tuples = [(q1_train[i], q2_train[i]) for i in range(ndocs)]\n",
    "\n",
    "class CrossValidationTransformer(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        XX = [x[0] for x in X]\n",
    "        for x in X:\n",
    "            XX.append(x[1])\n",
    "        return XX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "model_cv = Pipeline([\n",
    "    ('crossValidationTransformer', CrossValidationTransformer()),\n",
    "    ('countVectorizer', tf(#token_cleaner_func = lambda doc: WordNetLemmatizer().lemmatize(doc,pos=\"v\"),\n",
    "                     stop_words = set(stopwords.words('english')))),\n",
    "    ('middleTransformer', MiddleTransformer()),\n",
    "    ('model', MultinomialNB())\n",
    "])\n",
    "\n",
    "params = {'countVectorizer__ngram_range':[(1,3)], \n",
    "         'countVectorizer__min_df':[1,5,10,15,],\n",
    "         'countVectorizer__max_df':[.4,.3],\n",
    "         }\n",
    "\n",
    "gs = GridSearchCV(model_cv, params, scoring='roc_auc', cv=5, n_jobs=-1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed: 12.1min finished\n"
     ]
    }
   ],
   "source": [
    "results = gs.fit(all_questions_tuples, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'countVectorizer__max_df': 0.4,\n",
       " 'countVectorizer__min_df': 1,\n",
       " 'countVectorizer__ngram_range': (1, 3)}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8436795654397367"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
